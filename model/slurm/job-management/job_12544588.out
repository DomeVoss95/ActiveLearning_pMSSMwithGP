Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: uproot in /raven/u/dvoss/.local/lib/python3.9/site-packages (5.3.10)
Requirement already satisfied: fsspec in /raven/u/dvoss/.local/lib/python3.9/site-packages (from uproot) (2024.6.1)
Requirement already satisfied: awkward>=2.4.6 in /raven/u/dvoss/.local/lib/python3.9/site-packages (from uproot) (2.6.6)
Requirement already satisfied: cramjam>=2.5.0 in /raven/u/dvoss/.local/lib/python3.9/site-packages (from uproot) (2.8.3)
Requirement already satisfied: typing-extensions>=4.1.0 in /raven/u/dvoss/.local/lib/python3.9/site-packages (from uproot) (4.12.2)
Requirement already satisfied: numpy in /raven/u/system/soft/SLE_15/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages (from uproot) (1.20.3)
Requirement already satisfied: packaging in /raven/u/system/soft/SLE_15/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages (from uproot) (21.0)
Requirement already satisfied: importlib-metadata>=4.13.0 in /raven/u/dvoss/.local/lib/python3.9/site-packages (from awkward>=2.4.6->uproot) (8.0.0)
Requirement already satisfied: awkward-cpp==35 in /raven/u/dvoss/.local/lib/python3.9/site-packages (from awkward>=2.4.6->uproot) (35)
Requirement already satisfied: zipp>=0.5 in /raven/u/system/soft/SLE_15/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages (from importlib-metadata>=4.13.0->awkward>=2.4.6->uproot) (3.6.0)
Requirement already satisfied: pyparsing>=2.0.2 in /raven/u/system/soft/SLE_15/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages (from packaging->uproot) (3.0.4)
Defaulting to user installation because normal site-packages is not writeable
Collecting argparse
  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)
Installing collected packages: argparse
Successfully installed argparse-1.4.0
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: pyslha in /raven/u/dvoss/.local/lib/python3.9/site-packages (3.2.6)
Requirement already satisfied: tex2pix>=0.1.5 in /raven/u/dvoss/.local/lib/python3.9/site-packages (from pyslha) (0.3.1)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: structlog in /raven/u/dvoss/.local/lib/python3.9/site-packages (24.4.0)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: imageio[ffmpeg] in /raven/u/system/soft/SLE_15/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages (2.9.0)
Requirement already satisfied: Pillow in /raven/u/system/soft/SLE_15/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages (8.4.0)
Requirement already satisfied: numpy in /raven/u/system/soft/SLE_15/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages (from imageio[ffmpeg]) (1.20.3)
Requirement already satisfied: imageio-ffmpeg in /raven/u/dvoss/.local/lib/python3.9/site-packages (from imageio[ffmpeg]) (0.5.1)
Requirement already satisfied: setuptools in /raven/u/system/soft/SLE_15/packages/x86_64/anaconda/3/2021.11/lib/python3.9/site-packages (from imageio-ffmpeg->imageio[ffmpeg]) (58.0.4)
Starting iteration 1
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
These training_points are used in the GP tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[0.0116],
        [0.0116],
        [0.0116],
        [0.0116],
        [0.0116],
        [0.0339],
        [0.0116],
        [0.0116],
        [0.0242],
        [0.0611],
        [0.0116],
        [0.0143],
        [0.0516],
        [0.0282],
        [0.0650],
        [0.1004],
        [0.0782],
        [0.1131],
        [0.1467],
        [0.1257],
        [0.1587],
        [0.1906],
        [0.2213],
        [0.2021],
        [0.2323],
        [0.2614],
        [0.2893],
        [0.1808],
        [0.2118],
        [0.1923],
        [0.2229],
        [0.2523],
        [0.2807],
        [0.3079],
        [0.3341],
        [0.3594],
        [0.3836],
        [0.4070],
        [0.4295],
        [0.4511],
        [0.4719],
        [0.4919],
        [0.5112],
        [0.5585],
        [0.5753],
        [0.5914],
        [0.6068],
        [0.6217],
        [0.6584],
        [0.6713],
        [0.6837],
        [0.6956],
        [0.7251],
        [0.7354],
        [0.7453],
        [0.7547],
        [0.7784],
        [0.7866],
        [0.8071],
        [0.8141],
        [0.8207],
        [0.8051],
        [0.8118],
        [0.8295],
        [0.8352],
        [0.8504],
        [0.8550],
        [0.8682],
        [0.8718],
        [0.8831],
        [0.8858],
        [0.8954],
        [0.9038],
        [0.9052],
        [0.9123],
        [0.9184],
        [0.9185],
        [0.9235],
        [0.9277],
        [0.9312],
        [0.9295],
        [0.9320],
        [0.9339],
        [0.9352],
        [0.9360],
        [0.9319],
        [0.9317],
        [0.9309],
        [0.9297],
        [0.9280],
        [0.9258],
        [0.9231],
        [0.9200],
        [0.9163],
        [0.8991],
        [0.8938],
        [0.8880],
        [0.8815],
        [0.8743],
        [0.8665],
        [0.8579],
        [0.8485],
        [0.8384],
        [0.8382],
        [0.8270],
        [0.8149],
        [0.8018],
        [0.7878],
        [0.7868],
        [0.7714],
        [0.7550],
        [0.7535],
        [0.7357],
        [0.7164],
        [0.7146],
        [0.6938],
        [0.6715],
        [0.6692],
        [0.6450],
        [0.6425],
        [0.6164],
        [0.5883],
        [0.5854],
        [0.5550],
        [0.5518],
        [0.5190],
        [0.5155],
        [0.5120],
        [0.4072],
        [0.4029],
        [0.3593],
        [0.3546],
        [0.3498],
        [0.3024],
        [0.2973],
        [0.2921],
        [0.2869],
        [0.2349],
        [0.2292],
        [0.2235],
        [0.2178],
        [0.1608],
        [0.1546],
        [0.1483],
        [0.1420],
        [0.1357],
        [0.1293],
        [0.1229],
        [0.1164],
        [0.1098],
        [0.1032],
        [0.0380],
        [0.0899],
        [0.0832],
        [0.0764],
        [0.0116],
        [0.0116],
        [0.0116],
        [0.0116],
        [0.0116],
        [0.0116],
        [0.0116],
        [0.0116],
        [0.0116],
        [0.0116],
        [0.0116],
        [0.0235],
        [0.0162],
        [0.0396],
        [0.0325],
        [0.0116],
        [0.0194],
        [0.0121],
        [0.0356],
        [0.0585],
        [0.0809],
        [0.0741],
        [0.0962],
        [0.1177],
        [0.1387],
        [0.1592],
        [0.1792],
        [0.1987],
        [0.2178],
        [0.2364],
        [0.2777],
        [0.2950],
        [0.2679],
        [0.2853],
        [0.3024],
        [0.3401],
        [0.3559],
        [0.3712],
        [0.4053],
        [0.4195],
        [0.4510],
        [0.4641],
        [0.4932],
        [0.5207],
        [0.5322],
        [0.5576],
        [0.5817],
        [0.5917],
        [0.6139],
        [0.6115],
        [0.6327],
        [0.6415],
        [0.6611],
        [0.6796],
        [0.6971],
        [0.7137],
        [0.7293],
        [0.7442],
        [0.7659],
        [0.7787],
        [0.7909],
        [0.8025],
        [0.8134],
        [0.8293],
        [0.8388],
        [0.8478],
        [0.8517],
        [0.8600],
        [0.8720],
        [0.8792],
        [0.8897],
        [0.8959],
        [0.9050],
        [0.9104],
        [0.9183],
        [0.9256],
        [0.9299],
        [0.9362],
        [0.9419],
        [0.9472],
        [0.9521],
        [0.9565],
        [0.9592],
        [0.9603],
        [0.9641],
        [0.9676],
        [0.9718],
        [0.9746],
        [0.9772],
        [0.9796],
        [0.9818],
        [0.9837],
        [0.9862],
        [0.9878],
        [0.9893],
        [0.9911],
        [0.9924],
        [0.9939],
        [0.9949],
        [0.9961],
        [0.9963],
        [0.9974],
        [0.9982],
        [0.9989],
        [0.9997],
        [1.0003],
        [1.0009],
        [1.0014],
        [1.0019],
        [1.0023],
        [1.0027],
        [1.0030],
        [1.0033],
        [1.0036],
        [1.0038],
        [1.0041],
        [1.0043],
        [1.0044],
        [1.0045],
        [1.0047],
        [1.0048],
        [1.0049],
        [1.0050],
        [1.0051],
        [1.0052],
        [1.0053],
        [1.0054],
        [1.0054],
        [1.0055],
        [1.0055],
        [1.0056],
        [1.0056],
        [1.0056],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0056],
        [1.0056],
        [1.0056],
        [1.0055],
        [1.0055],
        [1.0054],
        [1.0054],
        [1.0053],
        [1.0053],
        [1.0052],
        [1.0051],
        [1.0050],
        [1.0049],
        [1.0048],
        [1.0046],
        [1.0045],
        [1.0043],
        [1.0041],
        [1.0039],
        [1.0037],
        [1.0034],
        [1.0031],
        [1.0028],
        [1.0024],
        [1.0020],
        [1.0016],
        [1.0011],
        [1.0006],
        [1.0000],
        [0.9993],
        [0.9986],
        [0.9979],
        [0.9970],
        [0.9961],
        [0.9951],
        [0.9939],
        [0.9927],
        [0.9914],
        [0.9900],
        [0.9884],
        [0.9867],
        [0.9849],
        [0.9829],
        [0.9807],
        [0.9784],
        [0.9759],
        [0.9732],
        [0.9703],
        [0.9672],
        [0.9638],
        [0.9602],
        [0.9564],
        [0.9523],
        [0.9479],
        [0.9432],
        [0.9382],
        [0.9329],
        [0.9273],
        [0.9213],
        [0.9150],
        [0.9083],
        [0.9012],
        [0.8937],
        [0.8858],
        [0.8774],
        [0.8686],
        [0.8594],
        [0.8500],
        [0.8397],
        [0.8294],
        [0.8182],
        [0.8069],
        [0.7947],
        [0.7821],
        [0.7694],
        [0.7558],
        [0.7421],
        [0.7276],
        [0.7131],
        [0.6976],
        [0.6821],
        [0.6656],
        [0.6495],
        [0.6322],
        [0.6152],
        [0.5971],
        [0.5793],
        [0.5607],
        [0.5414],
        [0.5240],
        [0.5046],
        [0.4844],
        [0.4644],
        [0.4443],
        [0.4261],
        [0.4057],
        [0.3858],
        [0.3652],
        [0.3470],
        [0.3272],
        [0.3074],
        [0.2870],
        [0.2702],
        [0.2510],
        [0.2320],
        [0.2134],
        [0.1988],
        [0.1809],
        [0.1643],
        [0.1474],
        [0.1350],
        [0.1192],
        [0.1048],
        [0.0921],
        [0.0791],
        [0.0694],
        [0.0598],
        [0.0483],
        [0.0404],
        [0.0341],
        [0.0280],
        [0.0218],
        [0.0156],
        [0.0150],
        [0.0126],
        [0.0116],
        [0.0116],
        [0.0131],
        [0.0127],
        [0.0162],
        [0.0196],
        [0.0250],
        [0.0303],
        [0.0356],
        [0.0480],
        [0.0569],
        [0.0657],
        [0.0781],
        [0.0867],
        [0.0988],
        [0.1108],
        [0.1260],
        [0.1473],
        [0.1620],
        [0.1763],
        [0.1904],
        [0.2074],
        [0.2241],
        [0.2434],
        [0.2622],
        [0.2777],
        [0.3036],
        [0.3209],
        [0.3404],
        [0.3594],
        [0.3778],
        [0.3980],
        [0.4176],
        [0.4366],
        [0.4590],
        [0.4787],
        [0.4977],
        [0.5160],
        [0.5355],
        [0.5542],
        [0.5722],
        [0.5895],
        [0.6060],
        [0.6262],
        [0.6428],
        [0.6613],
        [0.6763],
        [0.6931],
        [0.7067],
        [0.7219],
        [0.7364],
        [0.7520],
        [0.7650],
        [0.7790],
        [0.7906],
        [0.8031],
        [0.8135],
        [0.8247],
        [0.8353],
        [0.8464],
        [0.8569],
        [0.8656],
        [0.8748],
        [0.8824],
        [0.8905],
        [0.8981],
        [0.9052],
        [0.9125],
        [0.9193],
        [0.9256],
        [0.9309],
        [0.9363],
        [0.9414],
        [0.9461],
        [0.9505],
        [0.9549],
        [0.9590],
        [0.9627],
        [0.9662],
        [0.9694],
        [0.9723],
        [0.9750],
        [0.9775],
        [0.9799],
        [0.9820],
        [0.9842],
        [0.9861],
        [0.9879],
        [0.9894],
        [0.9909],
        [0.9923],
        [0.9935],
        [0.9947],
        [0.9958],
        [0.9967],
        [0.9976],
        [0.9984],
        [0.9992],
        [0.9998],
        [1.0004],
        [1.0010],
        [1.0014],
        [1.0019],
        [1.0023],
        [1.0027],
        [1.0030],
        [1.0033],
        [1.0036],
        [1.0038],
        [1.0040],
        [1.0042],
        [1.0044],
        [1.0046],
        [1.0047],
        [1.0049],
        [1.0050],
        [1.0051],
        [1.0051],
        [1.0052],
        [1.0053],
        [1.0054],
        [1.0054],
        [1.0055],
        [1.0055],
        [1.0055],
        [1.0056],
        [1.0056],
        [1.0056],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0056],
        [1.0056],
        [1.0056],
        [1.0055],
        [1.0055],
        [1.0055],
        [1.0054],
        [1.0054],
        [1.0053],
        [1.0052],
        [1.0051],
        [1.0050],
        [1.0049],
        [1.0048],
        [1.0047],
        [1.0045],
        [1.0044],
        [1.0042],
        [1.0040],
        [1.0039],
        [1.0036],
        [1.0034],
        [1.0030],
        [1.0027],
        [1.0023],
        [1.0019],
        [1.0015],
        [1.0008],
        [1.0003],
        [0.9997],
        [0.9990],
        [0.9983],
        [0.9975],
        [0.9963],
        [0.9953],
        [0.9941],
        [0.9937],
        [0.9928],
        [0.9914],
        [0.9898],
        [0.9881],
        [0.9862],
        [0.9841],
        [0.9825],
        [0.9800],
        [0.9772],
        [0.9751],
        [0.9718],
        [0.9693],
        [0.9654],
        [0.9624],
        [0.9577],
        [0.9542],
        [0.9522],
        [0.9483],
        [0.9440],
        [0.9374],
        [0.9323],
        [0.9269],
        [0.9211],
        [0.9149],
        [0.9051],
        [0.8977],
        [0.8898],
        [0.8813],
        [0.8721],
        [0.8623],
        [0.8517],
        [0.8455],
        [0.8337],
        [0.8325],
        [0.8197],
        [0.8122],
        [0.7980],
        [0.7827],
        [0.7737],
        [0.7566],
        [0.7383],
        [0.7275],
        [0.7070],
        [0.6949],
        [0.6721],
        [0.6586],
        [0.6445],
        [0.6179],
        [0.6022],
        [0.5859],
        [0.5960],
        [0.5794],
        [0.5480],
        [0.5295],
        [0.5102],
        [0.4902],
        [0.4693],
        [0.4476],
        [0.4250],
        [0.4015],
        [0.3770],
        [0.3717],
        [0.3461],
        [0.3193],
        [0.2916],
        [0.2855],
        [0.2564],
        [0.2743],
        [0.2681],
        [0.2383],
        [0.2318],
        [0.2005],
        [0.1936],
        [0.1608],
        [0.1536],
        [0.1464],
        [0.1116],
        [0.1041],
        [0.0964],
        [0.0888],
        [0.0516],
        [0.0436],
        [0.1235],
        [0.1160],
        [0.1085],
        [0.0426],
        [0.0933],
        [0.0856],
        [0.0778],
        [0.0699],
        [0.0620],
        [0.0540],
        [0.0460],
        [0.0379],
        [0.0297],
        [0.0214],
        [0.0732],
        [0.0653],
        [0.0574],
        [0.0494],
        [0.0997],
        [0.0920],
        [0.0843],
        [0.0765],
        [0.1254],
        [0.1180],
        [0.1105],
        [0.1576],
        [0.1504],
        [0.2927],
        [0.2867],
        [0.2806],
        [0.3188],
        [0.3130],
        [0.3494],
        [0.3439],
        [0.3787],
        [0.4117],
        [0.4067],
        [0.4382],
        [0.4334],
        [0.4636],
        [0.4921],
        [0.4878],
        [0.5150],
        [0.5409],
        [0.5369],
        [0.5616],
        [0.5850],
        [0.5815],
        [0.6038],
        [0.6250],
        [0.6450],
        [0.6640],
        [0.6611],
        [0.6793],
        [0.6964],
        [0.7127],
        [0.7282],
        [0.7428],
        [0.7566],
        [0.7697],
        [0.7822],
        [0.8194],
        [0.8292],
        [0.8385],
        [0.8473],
        [0.8556],
        [0.8635],
        [0.8710],
        [0.8781],
        [0.8849],
        [0.8982],
        [0.9038],
        [0.9092],
        [0.9143],
        [0.9191],
        [0.9286],
        [0.9327],
        [0.9366],
        [0.9402],
        [0.9474],
        [0.9505],
        [0.9534],
        [0.9592],
        [0.9616],
        [0.9640],
        [0.9686],
        [0.9705],
        [0.9744],
        [0.9761],
        [0.9793],
        [0.9807],
        [0.9835],
        [0.9847],
        [0.9870],
        [0.9901],
        [0.9919],
        [0.9934],
        [0.9941],
        [0.9953],
        [0.9959],
        [0.9970],
        [0.9980],
        [0.9988],
        [0.9992],
        [0.9999],
        [1.0006],
        [1.0012],
        [1.0014],
        [1.0019],
        [1.0023],
        [1.0027],
        [1.0031],
        [1.0032],
        [1.0035],
        [1.0037],
        [1.0040],
        [1.0042],
        [1.0044],
        [1.0045],
        [1.0047],
        [1.0048],
        [1.0049],
        [1.0050],
        [1.0051],
        [1.0052],
        [1.0053],
        [1.0053],
        [1.0054],
        [1.0055],
        [1.0055],
        [1.0056],
        [1.0056],
        [1.0056],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0057],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058],
        [1.0058]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([0.0030, 0.0030, 0.0030, 0.0030, 0.0030, 0.0084, 0.0030, 0.0030, 0.0060,
        0.0147, 0.0029, 0.0036, 0.0124, 0.0069, 0.0153, 0.0228, 0.0180, 0.0252,
        0.0315, 0.0275, 0.0337, 0.0390, 0.0440, 0.0408, 0.0456, 0.0498, 0.0536,
        0.0367, 0.0418, 0.0385, 0.0433, 0.0476, 0.0515, 0.0550, 0.0582, 0.0611,
        0.0637, 0.0660, 0.0681, 0.0701, 0.0717, 0.0733, 0.0746, 0.0780, 0.0789,
        0.0798, 0.0805, 0.0811, 0.0829, 0.0832, 0.0835, 0.0838, 0.0847, 0.0847,
        0.0848, 0.0848, 0.0852, 0.0850, 0.0851, 0.0849, 0.0847, 0.0842, 0.0839,
        0.0838, 0.0835, 0.0833, 0.0829, 0.0826, 0.0822, 0.0817, 0.0813, 0.0808,
        0.0803, 0.0797, 0.0791, 0.0786, 0.0779, 0.0773, 0.0767, 0.0761, 0.0754,
        0.0747, 0.0740, 0.0734, 0.0727, 0.0718, 0.0711, 0.0704, 0.0697, 0.0689,
        0.0682, 0.0674, 0.0666, 0.0658, 0.0644, 0.0635, 0.0626, 0.0617, 0.0607,
        0.0597, 0.0587, 0.0577, 0.0566, 0.0562, 0.0551, 0.0539, 0.0527, 0.0515,
        0.0512, 0.0499, 0.0485, 0.0482, 0.0468, 0.0453, 0.0450, 0.0434, 0.0418,
        0.0415, 0.0398, 0.0395, 0.0377, 0.0358, 0.0355, 0.0335, 0.0332, 0.0310,
        0.0307, 0.0304, 0.0240, 0.0236, 0.0210, 0.0206, 0.0203, 0.0175, 0.0171,
        0.0168, 0.0165, 0.0134, 0.0131, 0.0127, 0.0123, 0.0091, 0.0087, 0.0083,
        0.0080, 0.0076, 0.0072, 0.0068, 0.0065, 0.0061, 0.0057, 0.0021, 0.0050,
        0.0046, 0.0042, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006, 0.0006,
        0.0006, 0.0006, 0.0006, 0.0006, 0.0013, 0.0009, 0.0021, 0.0017, 0.0006,
        0.0010, 0.0006, 0.0019, 0.0031, 0.0043, 0.0039, 0.0051, 0.0063, 0.0073,
        0.0084, 0.0095, 0.0105, 0.0116, 0.0125, 0.0147, 0.0156, 0.0142, 0.0151,
        0.0160, 0.0180, 0.0188, 0.0196, 0.0215, 0.0222, 0.0239, 0.0246, 0.0262,
        0.0277, 0.0283, 0.0296, 0.0309, 0.0315, 0.0327, 0.0325, 0.0337, 0.0341,
        0.0352, 0.0362, 0.0372, 0.0381, 0.0389, 0.0397, 0.0410, 0.0417, 0.0424,
        0.0430, 0.0436, 0.0445, 0.0451, 0.0456, 0.0458, 0.0462, 0.0469, 0.0473,
        0.0479, 0.0483, 0.0488, 0.0491, 0.0496, 0.0500, 0.0502, 0.0506, 0.0509,
        0.0513, 0.0515, 0.0518, 0.0519, 0.0519, 0.0522, 0.0524, 0.0526, 0.0528,
        0.0529, 0.0530, 0.0531, 0.0532, 0.0534, 0.0535, 0.0535, 0.0536, 0.0537,
        0.0537, 0.0538, 0.0538, 0.0538, 0.0538, 0.0538, 0.0538, 0.0538, 0.0538,
        0.0538, 0.0538, 0.0538, 0.0538, 0.0538, 0.0538, 0.0537, 0.0537, 0.0537,
        0.0536, 0.0536, 0.0536, 0.0535, 0.0535, 0.0534, 0.0534, 0.0533, 0.0533,
        0.0532, 0.0532, 0.0531, 0.0531, 0.0530, 0.0529, 0.0529, 0.0528, 0.0528,
        0.0527, 0.0526, 0.0526, 0.0525, 0.0525, 0.0524, 0.0523, 0.0523, 0.0522,
        0.0521, 0.0521, 0.0520, 0.0519, 0.0519, 0.0518, 0.0517, 0.0517, 0.0516,
        0.0515, 0.0515, 0.0514, 0.0513, 0.0513, 0.0512, 0.0511, 0.0511, 0.0510,
        0.0509, 0.0509, 0.0508, 0.0507, 0.0507, 0.0506, 0.0505, 0.0505, 0.0504,
        0.0503, 0.0503, 0.0502, 0.0501, 0.0501, 0.0500, 0.0499, 0.0499, 0.0498,
        0.0497, 0.0497, 0.0496, 0.0495, 0.0495, 0.0494, 0.0493, 0.0493, 0.0492,
        0.0491, 0.0491, 0.0490, 0.0489, 0.0489, 0.0488, 0.0488, 0.0487, 0.0486,
        0.0486, 0.0485, 0.0484, 0.0484, 0.0483, 0.0482, 0.0482, 0.0481, 0.0481,
        0.0480, 0.0479, 0.0479, 0.0478, 0.0477, 0.0477, 0.0476, 0.0475, 0.0475,
        0.0474, 0.0474, 0.0473, 0.0472, 0.0472, 0.0471, 0.0471, 0.0470, 0.0469,
        0.0469, 0.0468, 0.0468, 0.0467, 0.0466, 0.0466, 0.0465, 0.0464, 0.0464,
        0.0463, 0.0463, 0.0462, 0.0461, 0.0461, 0.0460, 0.0460, 0.0459, 0.0459,
        0.0458, 0.0457, 0.0457, 0.0456, 0.0456, 0.0455, 0.0454, 0.0454, 0.0453,
        0.0453, 0.0452, 0.0451, 0.0451, 0.0450, 0.0450, 0.0449, 0.0448, 0.0448,
        0.0447, 0.0447, 0.0446, 0.0445, 0.0445, 0.0444, 0.0444, 0.0443, 0.0442,
        0.0442, 0.0441, 0.0441, 0.0440, 0.0439, 0.0439, 0.0438, 0.0438, 0.0437,
        0.0436, 0.0436, 0.0435, 0.0434, 0.0434, 0.0433, 0.0432, 0.0431, 0.0431,
        0.0430, 0.0429, 0.0429, 0.0428, 0.0427, 0.0426, 0.0425, 0.0425, 0.0424,
        0.0423, 0.0422, 0.0421, 0.0420, 0.0419, 0.0418, 0.0417, 0.0416, 0.0415,
        0.0414, 0.0413, 0.0412, 0.0411, 0.0410, 0.0409, 0.0407, 0.0406, 0.0405,
        0.0403, 0.0402, 0.0400, 0.0399, 0.0397, 0.0396, 0.0394, 0.0392, 0.0390,
        0.0389, 0.0387, 0.0385, 0.0383, 0.0381, 0.0378, 0.0376, 0.0374, 0.0372,
        0.0369, 0.0367, 0.0364, 0.0361, 0.0359, 0.0356, 0.0353, 0.0350, 0.0347,
        0.0344, 0.0340, 0.0337, 0.0334, 0.0330, 0.0262, 0.0257, 0.0252, 0.0247,
        0.0242, 0.0237, 0.0231, 0.0226, 0.0221, 0.0216, 0.0210, 0.0205, 0.0199,
        0.0194, 0.0188, 0.0183, 0.0177, 0.0172, 0.0166, 0.0161, 0.0155, 0.0149,
        0.0144, 0.0139, 0.0133, 0.0128, 0.0123, 0.0117, 0.0112, 0.0107, 0.0102,
        0.0097, 0.0092, 0.0087, 0.0082, 0.0078, 0.0073, 0.0069, 0.0065, 0.0060,
        0.0056, 0.0052, 0.0048, 0.0045, 0.0041, 0.0037, 0.0035, 0.0031, 0.0028,
        0.0025, 0.0023, 0.0020, 0.0018, 0.0015, 0.0013, 0.0011, 0.0010, 0.0008,
        0.0007, 0.0006, 0.0005, 0.0004, 0.0003, 0.0002, 0.0002, 0.0002, 0.0002,
        0.0002, 0.0002, 0.0003, 0.0003, 0.0004, 0.0005, 0.0006, 0.0008, 0.0009,
        0.0011, 0.0013, 0.0014, 0.0016, 0.0018, 0.0021, 0.0024, 0.0027, 0.0029,
        0.0032, 0.0035, 0.0038, 0.0042, 0.0045, 0.0048, 0.0053, 0.0056, 0.0060,
        0.0064, 0.0068, 0.0072, 0.0076, 0.0080, 0.0085, 0.0090, 0.0094, 0.0099,
        0.0103, 0.0108, 0.0112, 0.0117, 0.0121, 0.0127, 0.0131, 0.0137, 0.0141,
        0.0146, 0.0150, 0.0155, 0.0160, 0.0165, 0.0169, 0.0174, 0.0179, 0.0183,
        0.0187, 0.0192, 0.0196, 0.0201, 0.0205, 0.0209, 0.0213, 0.0217, 0.0221,
        0.0225, 0.0228, 0.0232, 0.0236, 0.0240, 0.0243, 0.0246, 0.0249, 0.0252,
        0.0255, 0.0258, 0.0261, 0.0264, 0.0267, 0.0269, 0.0272, 0.0274, 0.0276,
        0.0279, 0.0281, 0.0283, 0.0285, 0.0287, 0.0289, 0.0290, 0.0292, 0.0293,
        0.0295, 0.0296, 0.0298, 0.0299, 0.0300, 0.0302, 0.0303, 0.0304, 0.0304,
        0.0305, 0.0306, 0.0307, 0.0308, 0.0308, 0.0309, 0.0310, 0.0310, 0.0311,
        0.0311, 0.0311, 0.0312, 0.0312, 0.0313, 0.0313, 0.0313, 0.0313, 0.0314,
        0.0314, 0.0314, 0.0314, 0.0314, 0.0314, 0.0314, 0.0314, 0.0314, 0.0314,
        0.0314, 0.0314, 0.0314, 0.0314, 0.0314, 0.0314, 0.0314, 0.0314, 0.0314,
        0.0314, 0.0314, 0.0314, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313,
        0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0312, 0.0312, 0.0312,
        0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0313, 0.0313, 0.0313,
        0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0313, 0.0314, 0.0314,
        0.0314, 0.0314, 0.0315, 0.0315, 0.0315, 0.0315, 0.0316, 0.0316, 0.0317,
        0.0317, 0.0317, 0.0317, 0.0318, 0.0318, 0.0318, 0.0319, 0.0319, 0.0320,
        0.0320, 0.0320, 0.0321, 0.0321, 0.0321, 0.0321, 0.0322, 0.0322, 0.0322,
        0.0322, 0.0322, 0.0322, 0.0322, 0.0322, 0.0321, 0.0321, 0.0321, 0.0320,
        0.0320, 0.0319, 0.0318, 0.0317, 0.0315, 0.0315, 0.0313, 0.0312, 0.0311,
        0.0309, 0.0307, 0.0304, 0.0302, 0.0299, 0.0295, 0.0293, 0.0288, 0.0285,
        0.0280, 0.0276, 0.0273, 0.0265, 0.0261, 0.0256, 0.0258, 0.0253, 0.0244,
        0.0238, 0.0231, 0.0225, 0.0217, 0.0209, 0.0201, 0.0192, 0.0183, 0.0180,
        0.0170, 0.0159, 0.0147, 0.0144, 0.0131, 0.0139, 0.0136, 0.0123, 0.0119,
        0.0105, 0.0101, 0.0085, 0.0082, 0.0078, 0.0061, 0.0057, 0.0052, 0.0048,
        0.0029, 0.0024, 0.0066, 0.0062, 0.0058, 0.0024, 0.0050, 0.0046, 0.0042,
        0.0038, 0.0034, 0.0029, 0.0025, 0.0021, 0.0016, 0.0012, 0.0039, 0.0035,
        0.0031, 0.0027, 0.0053, 0.0049, 0.0045, 0.0040, 0.0065, 0.0061, 0.0057,
        0.0080, 0.0076, 0.0139, 0.0136, 0.0133, 0.0148, 0.0146, 0.0160, 0.0158,
        0.0170, 0.0182, 0.0180, 0.0190, 0.0188, 0.0198, 0.0207, 0.0205, 0.0213,
        0.0220, 0.0219, 0.0226, 0.0232, 0.0231, 0.0236, 0.0241, 0.0245, 0.0250,
        0.0249, 0.0252, 0.0256, 0.0259, 0.0261, 0.0264, 0.0266, 0.0268, 0.0269,
        0.0274, 0.0275, 0.0276, 0.0276, 0.0277, 0.0277, 0.0278, 0.0278, 0.0278,
        0.0278, 0.0278, 0.0278, 0.0278, 0.0278, 0.0277, 0.0277, 0.0277, 0.0276,
        0.0276, 0.0275, 0.0275, 0.0274, 0.0273, 0.0273, 0.0272, 0.0272, 0.0271,
        0.0270, 0.0269, 0.0269, 0.0268, 0.0267, 0.0266, 0.0265, 0.0264, 0.0263,
        0.0263, 0.0262, 0.0261, 0.0261, 0.0260, 0.0259, 0.0259, 0.0258, 0.0257,
        0.0256, 0.0256, 0.0255, 0.0255, 0.0254, 0.0253, 0.0253, 0.0252, 0.0252,
        0.0251, 0.0251, 0.0250, 0.0250, 0.0249, 0.0249, 0.0248, 0.0248, 0.0248,
        0.0247, 0.0247, 0.0246, 0.0246, 0.0245, 0.0245, 0.0245, 0.0244, 0.0244,
        0.0244, 0.0243, 0.0243, 0.0243, 0.0242, 0.0242, 0.0242, 0.0241, 0.0241,
        0.0241, 0.0240, 0.0240, 0.0240, 0.0240, 0.0239, 0.0239, 0.0239, 0.0239,
        0.0238, 0.0238, 0.0238, 0.0237], device='cuda:0')
Selected points (indices): {56}
Selected new x values (normalized): tensor([0.0561], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-1775.7758], device='cuda:0')
No root_file_path provided; skipping ROOT file data plotting.
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter1/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:32:22 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_1 [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		M_1: [-1775.78]              [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:32:22 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:32:23 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:32:23 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:32:29 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_1, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:32:29 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:32:29 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_1/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 1
Starting iteration 2
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.1617, 0.0046, 0.0561, 0.5812, 0.8528], device='cuda:0') torch.Size([5])
These training_points are used in the GP tensor([0.1617, 0.0046, 0.0561, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[2.0644e-01],
        [5.0617e-02],
        [1.1284e-02],
        [1.1404e-02],
        [2.5407e-01],
        [1.0744e-01],
        [1.1318e-02],
        [1.0893e-02],
        [7.5286e-02],
        [4.9255e-01],
        [3.9194e-01],
        [2.7134e-01],
        [1.2665e-01],
        [3.8958e-03],
        [4.2293e-01],
        [3.0613e-01],
        [1.6474e-01],
        [3.9143e-01],
        [6.6239e-01],
        [5.8961e-01],
        [4.9942e-01],
        [3.8667e-01],
        [5.4390e-01],
        [7.3819e-01],
        [6.7039e-01],
        [5.8100e-01],
        [4.6136e-01],
        [5.7695e-01],
        [7.3579e-01],
        [6.4305e-01],
        [7.0569e-01],
        [5.9043e-01],
        [4.2284e-01],
        [5.9972e-01],
        [6.5035e-01],
        [4.8793e-01],
        [5.4438e-01],
        [3.2338e-01],
        [5.0168e-01],
        [5.4830e-01],
        [3.1894e-01],
        [1.0000e-06],
        [5.9508e-02],
        [2.9225e-01],
        [3.5057e-01],
        [1.2908e-02],
        [9.2522e-02],
        [6.4836e-03],
        [1.8743e-01],
        [3.7911e-02],
        [1.0790e-02],
        [1.0909e-02],
        [1.1011e-02],
        [5.7874e-02],
        [1.1401e-02],
        [1.1387e-02],
        [1.1370e-02],
        [1.1349e-02],
        [1.0971e-02],
        [1.0804e-02],
        [1.0767e-02],
        [1.0730e-02],
        [1.0694e-02],
        [2.3125e-01],
        [8.9063e-02],
        [1.0155e-02],
        [1.0130e-02],
        [1.0024e-02],
        [3.0575e-01],
        [1.7727e-01],
        [2.4210e-01],
        [1.0196e-01],
        [1.7269e-01],
        [5.1311e-01],
        [4.2270e-01],
        [4.6834e-01],
        [3.6973e-01],
        [7.1282e-01],
        [7.3576e-01],
        [6.8622e-01],
        [7.1123e-01],
        [6.5719e-01],
        [8.4522e-01],
        [8.5778e-01],
        [8.3064e-01],
        [8.4435e-01],
        [8.5698e-01],
        [9.1777e-01],
        [9.2465e-01],
        [9.3100e-01],
        [9.3685e-01],
        [9.2421e-01],
        [9.6818e-01],
        [9.7112e-01],
        [9.7383e-01],
        [9.7632e-01],
        [9.7861e-01],
        [9.9323e-01],
        [9.9419e-01],
        [9.9507e-01],
        [9.9587e-01],
        [9.9659e-01],
        [1.0015e+00],
        [1.0017e+00],
        [1.0019e+00],
        [1.0021e+00],
        [1.0021e+00],
        [1.0038e+00],
        [1.0037e+00],
        [1.0033e+00],
        [1.0028e+00],
        [1.0028e+00],
        [1.0034e+00],
        [1.0025e+00],
        [1.0010e+00],
        [1.0003e+00],
        [9.9770e-01],
        [9.9866e-01],
        [9.9744e-01],
        [9.9324e-01],
        [9.8688e-01],
        [9.8356e-01],
        [9.8599e-01],
        [9.8249e-01],
        [9.7059e-01],
        [9.6435e-01],
        [9.4317e-01],
        [9.6231e-01],
        [9.4008e-01],
        [9.2841e-01],
        [8.8881e-01],
        [9.2458e-01],
        [9.1016e-01],
        [8.6122e-01],
        [8.3554e-01],
        [8.0529e-01],
        [8.2711e-01],
        [7.9536e-01],
        [7.5798e-01],
        [6.3108e-01],
        [5.6450e-01],
        [6.9950e-01],
        [6.4508e-01],
        [5.8099e-01],
        [5.0551e-01],
        [2.4930e-01],
        [4.8074e-01],
        [3.8744e-01],
        [2.7756e-01],
        [1.4816e-01],
        [1.1417e-02],
        [3.0477e-01],
        [1.8021e-01],
        [3.3502e-02],
        [1.1417e-02],
        [1.1417e-02],
        [2.7685e-01],
        [1.4732e-01],
        [1.1417e-02],
        [1.1417e-02],
        [1.1417e-02],
        [3.2552e-02],
        [1.1313e-01],
        [1.1417e-02],
        [1.1417e-02],
        [1.1417e-02],
        [2.1763e-01],
        [7.7570e-02],
        [1.1417e-02],
        [1.1417e-02],
        [1.1417e-02],
        [1.8623e-01],
        [2.5408e-01],
        [1.2051e-01],
        [1.9380e-01],
        [4.9509e-02],
        [4.8888e-01],
        [3.9703e-01],
        [4.4742e-01],
        [3.4821e-01],
        [5.4276e-01],
        [5.2456e-01],
        [6.6693e-01],
        [6.5361e-01],
        [7.2479e-01],
        [7.4805e-01],
        [7.3791e-01],
        [7.9205e-01],
        [8.0974e-01],
        [8.4936e-01],
        [8.6231e-01],
        [8.7418e-01],
        [9.0077e-01],
        [9.0946e-01],
        [9.3795e-01],
        [9.3528e-01],
        [9.4111e-01],
        [9.6023e-01],
        [9.6400e-01],
        [9.7634e-01],
        [9.7878e-01],
        [9.8675e-01],
        [9.8832e-01],
        [9.8976e-01],
        [9.9449e-01],
        [9.9542e-01],
        [9.9932e-01],
        [9.9985e-01],
        [1.0003e+00],
        [1.0024e+00],
        [1.0027e+00],
        [1.0036e+00],
        [1.0040e+00],
        [1.0041e+00],
        [1.0047e+00],
        [1.0048e+00],
        [1.0052e+00],
        [1.0053e+00],
        [1.0053e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0054e+00],
        [1.0053e+00],
        [1.0052e+00],
        [1.0050e+00],
        [1.0048e+00],
        [1.0045e+00],
        [1.0041e+00],
        [1.0036e+00],
        [1.0031e+00],
        [1.0024e+00],
        [1.0015e+00],
        [1.0003e+00],
        [9.9897e-01],
        [9.9732e-01],
        [9.9530e-01],
        [9.9277e-01],
        [9.8985e-01],
        [9.8623e-01],
        [9.8224e-01],
        [9.7711e-01],
        [9.7154e-01],
        [9.6454e-01],
        [9.5632e-01],
        [9.4761e-01],
        [9.3681e-01],
        [9.2433e-01],
        [9.1146e-01],
        [8.9525e-01],
        [8.7928e-01],
        [8.5926e-01],
        [8.3674e-01],
        [8.1531e-01],
        [7.8858e-01],
        [7.5810e-01],
        [7.3210e-01],
        [6.9612e-01],
        [6.6627e-01],
        [6.2759e-01],
        [5.8778e-01],
        [5.5105e-01],
        [5.0710e-01],
        [4.6315e-01],
        [4.2462e-01],
        [3.7832e-01],
        [3.3360e-01],
        [2.9703e-01],
        [2.5243e-01],
        [2.2376e-01],
        [1.8101e-01],
        [1.4270e-01],
        [1.1682e-01],
        [8.2767e-02],
        [5.4863e-02],
        [4.1538e-02],
        [2.0118e-02],
        [2.1801e-02],
        [1.1417e-02],
        [1.7226e-02],
        [1.1417e-02],
        [2.0118e-02],
        [2.9220e-02],
        [3.8237e-02],
        [9.1513e-02],
        [1.1400e-01],
        [1.3593e-01],
        [1.5732e-01],
        [1.9102e-01],
        [2.4782e-01],
        [2.8920e-01],
        [3.2833e-01],
        [3.6532e-01],
        [4.0029e-01],
        [4.4222e-01],
        [4.9763e-01],
        [5.4016e-01],
        [5.7912e-01],
        [6.1482e-01],
        [6.4754e-01],
        [6.9270e-01],
        [7.2334e-01],
        [7.5099e-01],
        [7.7949e-01],
        [8.0480e-01],
        [8.2728e-01],
        [8.5458e-01],
        [8.7357e-01],
        [8.9018e-01],
        [9.0626e-01],
        [9.1876e-01],
        [9.3433e-01],
        [9.4427e-01],
        [9.5445e-01],
        [9.6159e-01],
        [9.6890e-01],
        [9.7596e-01],
        [9.8089e-01],
        [9.8501e-01],
        [9.8897e-01],
        [9.9175e-01],
        [9.9442e-01],
        [9.9687e-01],
        [9.9857e-01],
        [9.9994e-01],
        [1.0010e+00],
        [1.0021e+00],
        [1.0029e+00],
        [1.0035e+00],
        [1.0040e+00],
        [1.0044e+00],
        [1.0047e+00],
        [1.0049e+00],
        [1.0051e+00],
        [1.0053e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0053e+00],
        [1.0052e+00],
        [1.0052e+00],
        [1.0049e+00],
        [1.0047e+00],
        [1.0042e+00],
        [1.0039e+00],
        [1.0030e+00],
        [1.0025e+00],
        [1.0024e+00],
        [1.0007e+00],
        [9.9981e-01],
        [9.9770e-01],
        [9.9637e-01],
        [9.9482e-01],
        [9.9093e-01],
        [9.8847e-01],
        [9.8234e-01],
        [9.8165e-01],
        [9.7765e-01],
        [9.6766e-01],
        [9.6655e-01],
        [9.4553e-01],
        [9.4377e-01],
        [9.1054e-01],
        [9.1927e-01],
        [9.0489e-01],
        [9.1414e-01],
        [8.2035e-01],
        [8.3735e-01],
        [8.0936e-01],
        [8.2737e-01],
        [7.9771e-01],
        [6.7784e-01],
        [7.0791e-01],
        [6.5839e-01],
        [6.9024e-01],
        [7.1918e-01],
        [4.2575e-01],
        [4.7894e-01],
        [5.2725e-01],
        [5.7113e-01],
        [4.9887e-01],
        [2.0678e-01],
        [2.8005e-01],
        [3.4660e-01],
        [4.0705e-01],
        [4.6195e-01],
        [1.1417e-02],
        [1.1417e-02],
        [9.7741e-02],
        [1.8101e-01],
        [2.5665e-01],
        [1.1417e-02],
        [1.1417e-02],
        [3.1601e-02],
        [1.2094e-01],
        [2.0208e-01],
        [1.1417e-02],
        [1.0963e-01],
        [1.9181e-01],
        [2.6646e-01],
        [3.3426e-01],
        [1.1417e-02],
        [4.4359e-02],
        [3.2568e-01],
        [3.8804e-01],
        [4.4469e-01],
        [3.1699e-01],
        [3.8015e-01],
        [4.3752e-01],
        [6.0379e-01],
        [6.4065e-01],
        [4.3026e-01],
        [5.9866e-01],
        [6.3599e-01],
        [7.4418e-01],
        [5.9346e-01],
        [7.1410e-01],
        [7.4084e-01],
        [8.1835e-01],
        [8.3554e-01],
        [7.9680e-01],
        [8.1596e-01],
        [8.7149e-01],
        [9.1077e-01],
        [9.1948e-01],
        [8.9985e-01],
        [9.3083e-01],
        [9.3770e-01],
        [9.5760e-01],
        [9.7169e-01],
        [9.6394e-01],
        [9.6777e-01],
        [9.7888e-01],
        [9.8673e-01],
        [9.9229e-01],
        [9.8923e-01],
        [9.9406e-01],
        [9.9747e-01],
        [9.9989e-01],
        [1.0016e+00],
        [1.0007e+00],
        [1.0021e+00],
        [1.0032e+00],
        [1.0039e+00],
        [1.0045e+00],
        [1.0042e+00],
        [1.0046e+00],
        [1.0049e+00],
        [1.0052e+00],
        [1.0053e+00],
        [1.0052e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([ 0.0439,  0.0126,  0.0030,  0.0029,  0.0507,  0.0247,  0.0029,  0.0028,
         0.0176,  0.0764,  0.0666,  0.0514,  0.0273,  0.0010,  0.0679,  0.0542,
         0.0328,  0.0628,  0.0819,  0.0771,  0.0695,  0.0579,  0.0704,  0.0793,
         0.0747,  0.0674,  0.0561,  0.0631,  0.0702,  0.0627,  0.0646,  0.0551,
         0.0402,  0.0516,  0.0535,  0.0404,  0.0434,  0.0259,  0.0380,  0.0405,
         0.0235, -0.0012,  0.0043,  0.0203,  0.0240,  0.0009,  0.0062,  0.0004,
         0.0123,  0.0024,  0.0007,  0.0007,  0.0007,  0.0036,  0.0007,  0.0007,
         0.0007,  0.0007,  0.0007,  0.0007,  0.0007,  0.0006,  0.0006,  0.0141,
         0.0054,  0.0006,  0.0006,  0.0006,  0.0185,  0.0107,  0.0146,  0.0061,
         0.0103,  0.0312,  0.0255,  0.0283,  0.0222,  0.0439,  0.0453,  0.0420,
         0.0436,  0.0400,  0.0525,  0.0534,  0.0514,  0.0523,  0.0531,  0.0575,
         0.0580,  0.0584,  0.0588,  0.0577,  0.0612,  0.0614,  0.0615,  0.0617,
         0.0618,  0.0632,  0.0632,  0.0632,  0.0632,  0.0632,  0.0638,  0.0637,
         0.0636,  0.0635,  0.0634,  0.0637,  0.0635,  0.0634,  0.0632,  0.0631,
         0.0632,  0.0630,  0.0627,  0.0625,  0.0621,  0.0622,  0.0620,  0.0615,
         0.0608,  0.0604,  0.0606,  0.0602,  0.0591,  0.0585,  0.0568,  0.0582,
         0.0564,  0.0555,  0.0527,  0.0551,  0.0540,  0.0506,  0.0489,  0.0469,
         0.0482,  0.0461,  0.0437,  0.0360,  0.0321,  0.0400,  0.0367,  0.0329,
         0.0284,  0.0139,  0.0269,  0.0216,  0.0154,  0.0082,  0.0006,  0.0168,
         0.0099,  0.0018,  0.0006,  0.0006,  0.0152,  0.0080,  0.0006,  0.0006,
         0.0006,  0.0018,  0.0062,  0.0006,  0.0006,  0.0006,  0.0118,  0.0042,
         0.0006,  0.0006,  0.0006,  0.0100,  0.0136,  0.0065,  0.0104,  0.0026,
         0.0263,  0.0213,  0.0240,  0.0186,  0.0292,  0.0281,  0.0360,  0.0352,
         0.0392,  0.0405,  0.0399,  0.0430,  0.0440,  0.0463,  0.0470,  0.0477,
         0.0492,  0.0497,  0.0515,  0.0513,  0.0516,  0.0528,  0.0530,  0.0539,
         0.0540,  0.0545,  0.0546,  0.0546,  0.0550,  0.0550,  0.0553,  0.0553,
         0.0553,  0.0554,  0.0554,  0.0554,  0.0554,  0.0554,  0.0554,  0.0553,
         0.0553,  0.0553,  0.0552,  0.0552,  0.0551,  0.0551,  0.0550,  0.0550,
         0.0549,  0.0549,  0.0548,  0.0547,  0.0547,  0.0546,  0.0545,  0.0545,
         0.0544,  0.0543,  0.0543,  0.0542,  0.0541,  0.0541,  0.0540,  0.0539,
         0.0539,  0.0538,  0.0537,  0.0536,  0.0536,  0.0535,  0.0534,  0.0534,
         0.0533,  0.0532,  0.0532,  0.0531,  0.0530,  0.0530,  0.0529,  0.0528,
         0.0528,  0.0527,  0.0526,  0.0526,  0.0525,  0.0524,  0.0524,  0.0523,
         0.0522,  0.0522,  0.0521,  0.0520,  0.0520,  0.0519,  0.0518,  0.0518,
         0.0517,  0.0516,  0.0516,  0.0515,  0.0514,  0.0514,  0.0513,  0.0512,
         0.0512,  0.0511,  0.0510,  0.0510,  0.0509,  0.0508,  0.0508,  0.0507,
         0.0507,  0.0506,  0.0505,  0.0505,  0.0504,  0.0503,  0.0503,  0.0502,
         0.0501,  0.0501,  0.0500,  0.0500,  0.0499,  0.0498,  0.0498,  0.0497,
         0.0496,  0.0496,  0.0495,  0.0495,  0.0494,  0.0493,  0.0493,  0.0492,
         0.0492,  0.0491,  0.0490,  0.0490,  0.0489,  0.0488,  0.0488,  0.0487,
         0.0487,  0.0486,  0.0485,  0.0485,  0.0484,  0.0484,  0.0483,  0.0482,
         0.0482,  0.0481,  0.0481,  0.0480,  0.0480,  0.0479,  0.0478,  0.0478,
         0.0477,  0.0477,  0.0476,  0.0475,  0.0475,  0.0474,  0.0474,  0.0473,
         0.0473,  0.0472,  0.0471,  0.0471,  0.0470,  0.0470,  0.0469,  0.0469,
         0.0468,  0.0467,  0.0467,  0.0466,  0.0466,  0.0465,  0.0465,  0.0464,
         0.0463,  0.0463,  0.0462,  0.0462,  0.0461,  0.0461,  0.0460,  0.0460,
         0.0459,  0.0458,  0.0458,  0.0457,  0.0457,  0.0456,  0.0456,  0.0455,
         0.0455,  0.0454,  0.0454,  0.0453,  0.0452,  0.0452,  0.0451,  0.0451,
         0.0450,  0.0450,  0.0449,  0.0449,  0.0448,  0.0448,  0.0447,  0.0447,
         0.0446,  0.0446,  0.0445,  0.0444,  0.0444,  0.0443,  0.0443,  0.0442,
         0.0442,  0.0441,  0.0441,  0.0440,  0.0440,  0.0439,  0.0439,  0.0438,
         0.0438,  0.0437,  0.0437,  0.0436,  0.0436,  0.0435,  0.0435,  0.0434,
         0.0434,  0.0433,  0.0433,  0.0432,  0.0432,  0.0431,  0.0431,  0.0430,
         0.0430,  0.0429,  0.0429,  0.0428,  0.0428,  0.0427,  0.0427,  0.0426,
         0.0426,  0.0425,  0.0425,  0.0424,  0.0424,  0.0423,  0.0423,  0.0422,
         0.0422,  0.0421,  0.0421,  0.0420,  0.0420,  0.0419,  0.0419,  0.0418,
         0.0418,  0.0417,  0.0417,  0.0416,  0.0416,  0.0415,  0.0415,  0.0414,
         0.0414,  0.0414,  0.0413,  0.0413,  0.0412,  0.0412,  0.0411,  0.0411,
         0.0410,  0.0410,  0.0409,  0.0409,  0.0408,  0.0408,  0.0407,  0.0407,
         0.0407,  0.0406,  0.0406,  0.0405,  0.0405,  0.0404,  0.0404,  0.0403,
         0.0403,  0.0402,  0.0402,  0.0401,  0.0401,  0.0401,  0.0400,  0.0400,
         0.0399,  0.0399,  0.0398,  0.0398,  0.0397,  0.0397,  0.0397,  0.0396,
         0.0396,  0.0395,  0.0395,  0.0394,  0.0386,  0.0385,  0.0384,  0.0383,
         0.0382,  0.0381,  0.0380,  0.0379,  0.0378,  0.0376,  0.0375,  0.0373,
         0.0371,  0.0369,  0.0367,  0.0365,  0.0362,  0.0360,  0.0357,  0.0353,
         0.0350,  0.0346,  0.0342,  0.0337,  0.0332,  0.0327,  0.0321,  0.0315,
         0.0309,  0.0302,  0.0295,  0.0287,  0.0279,  0.0270,  0.0261,  0.0252,
         0.0242,  0.0233,  0.0222,  0.0211,  0.0201,  0.0190,  0.0178,  0.0168,
         0.0155,  0.0146,  0.0134,  0.0122,  0.0112,  0.0101,  0.0090,  0.0081,
         0.0070,  0.0061,  0.0053,  0.0044,  0.0039,  0.0031,  0.0024,  0.0020,
         0.0014,  0.0009,  0.0007,  0.0003,  0.0003,  0.0002,  0.0003,  0.0002,
         0.0003,  0.0005,  0.0006,  0.0015,  0.0019,  0.0023,  0.0026,  0.0032,
         0.0043,  0.0051,  0.0059,  0.0066,  0.0074,  0.0083,  0.0096,  0.0106,
         0.0116,  0.0126,  0.0135,  0.0149,  0.0159,  0.0168,  0.0178,  0.0188,
         0.0197,  0.0209,  0.0218,  0.0227,  0.0235,  0.0243,  0.0252,  0.0259,
         0.0267,  0.0272,  0.0279,  0.0285,  0.0291,  0.0295,  0.0300,  0.0304,
         0.0308,  0.0312,  0.0315,  0.0317,  0.0320,  0.0322,  0.0325,  0.0326,
         0.0328,  0.0329,  0.0330,  0.0331,  0.0332,  0.0333,  0.0333,  0.0334,
         0.0334,  0.0335,  0.0335,  0.0335,  0.0335,  0.0335,  0.0335,  0.0335,
         0.0335,  0.0335,  0.0335,  0.0334,  0.0334,  0.0334,  0.0334,  0.0333,
         0.0333,  0.0333,  0.0333,  0.0332,  0.0332,  0.0332,  0.0331,  0.0331,
         0.0331,  0.0330,  0.0330,  0.0330,  0.0329,  0.0329,  0.0329,  0.0328,
         0.0328,  0.0328,  0.0327,  0.0327,  0.0327,  0.0326,  0.0326,  0.0326,
         0.0325,  0.0325,  0.0325,  0.0324,  0.0324,  0.0324,  0.0323,  0.0323,
         0.0323,  0.0322,  0.0322,  0.0322,  0.0321,  0.0321,  0.0321,  0.0320,
         0.0320,  0.0320,  0.0320,  0.0319,  0.0319,  0.0319,  0.0318,  0.0318,
         0.0318,  0.0317,  0.0317,  0.0317,  0.0316,  0.0316,  0.0316,  0.0315,
         0.0315,  0.0315,  0.0314,  0.0314,  0.0314,  0.0313,  0.0313,  0.0313,
         0.0313,  0.0312,  0.0312,  0.0312,  0.0311,  0.0311,  0.0311,  0.0310,
         0.0310,  0.0310,  0.0309,  0.0309,  0.0309,  0.0309,  0.0308,  0.0308,
         0.0308,  0.0307,  0.0307,  0.0307,  0.0306,  0.0306,  0.0306,  0.0305,
         0.0305,  0.0305,  0.0305,  0.0304,  0.0304,  0.0304,  0.0303,  0.0303,
         0.0303,  0.0302,  0.0302,  0.0302,  0.0302,  0.0301,  0.0301,  0.0301,
         0.0300,  0.0300,  0.0300,  0.0300,  0.0299,  0.0299,  0.0299,  0.0298,
         0.0298,  0.0298,  0.0297,  0.0297,  0.0297,  0.0297,  0.0296,  0.0296,
         0.0296,  0.0296,  0.0295,  0.0295,  0.0295,  0.0295,  0.0294,  0.0294,
         0.0294,  0.0294,  0.0293,  0.0293,  0.0293,  0.0293,  0.0293,  0.0293,
         0.0293,  0.0293,  0.0293,  0.0293,  0.0293,  0.0293,  0.0293,  0.0293,
         0.0294,  0.0294,  0.0295,  0.0295,  0.0296,  0.0296,  0.0296,  0.0298,
         0.0298,  0.0300,  0.0300,  0.0301,  0.0302,  0.0303,  0.0305,  0.0305,
         0.0306,  0.0307,  0.0307,  0.0309,  0.0309,  0.0310,  0.0309,  0.0309,
         0.0309,  0.0301,  0.0303,  0.0299,  0.0301,  0.0297,  0.0274,  0.0280,
         0.0269,  0.0276,  0.0282,  0.0198,  0.0216,  0.0231,  0.0244,  0.0222,
         0.0107,  0.0139,  0.0167,  0.0189,  0.0208,  0.0007,  0.0007,  0.0053,
         0.0094,  0.0128,  0.0006,  0.0006,  0.0017,  0.0064,  0.0103,  0.0006,
         0.0058,  0.0098,  0.0131,  0.0158,  0.0006,  0.0024,  0.0154,  0.0178,
         0.0198,  0.0150,  0.0174,  0.0195,  0.0244,  0.0253,  0.0191,  0.0242,
         0.0251,  0.0274,  0.0240,  0.0268,  0.0273,  0.0285,  0.0286,  0.0281,
         0.0284,  0.0289,  0.0291,  0.0291,  0.0290,  0.0290,  0.0289,  0.0288,
         0.0286,  0.0287,  0.0286,  0.0284,  0.0281,  0.0279,  0.0280,  0.0278,
         0.0276,  0.0274,  0.0272,  0.0273,  0.0271,  0.0270,  0.0268,  0.0267,
         0.0267,  0.0266,  0.0265,  0.0265,  0.0264,  0.0264,  0.0263,  0.0262,
         0.0262,  0.0261,  0.0261,  0.0261,  0.0260,  0.0260,  0.0259,  0.0259,
         0.0259,  0.0258,  0.0258,  0.0258,  0.0258,  0.0257,  0.0257,  0.0257,
         0.0256,  0.0256,  0.0256,  0.0256,  0.0255,  0.0255,  0.0255,  0.0255,
         0.0255,  0.0254,  0.0254,  0.0254,  0.0254,  0.0253,  0.0253,  0.0253,
         0.0253,  0.0252,  0.0252,  0.0252,  0.0252,  0.0252,  0.0251,  0.0251,
         0.0251,  0.0251,  0.0250,  0.0250,  0.0250,  0.0250,  0.0250,  0.0249,
         0.0249,  0.0249,  0.0249,  0.0248,  0.0248,  0.0248,  0.0248,  0.0248,
         0.0247,  0.0247,  0.0247,  0.0247,  0.0246,  0.0246,  0.0246,  0.0246,
         0.0246,  0.0245,  0.0245,  0.0245,  0.0245,  0.0244,  0.0244,  0.0244,
         0.0244,  0.0244,  0.0243,  0.0243,  0.0243,  0.0243,  0.0242,  0.0242,
         0.0242,  0.0242,  0.0242,  0.0241,  0.0241,  0.0241,  0.0241,  0.0241,
         0.0240], device='cuda:0')
Selected points (indices): {18}
Selected new x values (normalized): tensor([0.0180], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-1927.9280], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter2/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:33:16 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_2 [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		M_1: [-1927.93]              [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:33:16 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:33:18 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_2, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:33:18 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:33:18 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_2/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 2
Starting iteration 3
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.1617, 0.0046, 0.0561, 0.0180, 0.5812, 0.8528], device='cuda:0') torch.Size([6])
These training_points are used in the GP tensor([0.1617, 0.0046, 0.0561, 0.0180, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[1.8651e-01],
        [1.0000e-06],
        [1.5036e-01],
        [3.4945e-01],
        [9.5744e-02],
        [3.0089e-01],
        [1.0000e-06],
        [2.1237e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [9.2694e-02],
        [1.0000e-06],
        [1.9941e-01],
        [1.0000e-06],
        [2.7982e-01],
        [1.0000e-06],
        [3.3770e-01],
        [3.5307e-02],
        [3.7636e-01],
        [8.2780e-02],
        [3.9874e-01],
        [1.0754e-01],
        [4.0738e-01],
        [1.1317e-01],
        [4.0447e-01],
        [1.0277e-01],
        [3.9192e-01],
        [7.8987e-02],
        [3.7134e-01],
        [2.5684e-01],
        [3.4411e-01],
        [2.2249e-01],
        [4.6501e-01],
        [1.8224e-01],
        [4.3599e-01],
        [3.2929e-01],
        [4.0407e-01],
        [2.9103e-01],
        [5.1048e-01],
        [2.5022e-01],
        [4.8224e-01],
        [3.8395e-01],
        [5.7510e-01],
        [4.9443e-01],
        [5.5131e-01],
        [4.6645e-01],
        [6.3279e-01],
        [5.6339e-01],
        [7.0010e-01],
        [7.3470e-01],
        [6.8455e-01],
        [7.8413e-01],
        [7.4327e-01],
        [8.2479e-01],
        [7.9152e-01],
        [8.5816e-01],
        [8.3108e-01],
        [8.8546e-01],
        [8.6340e-01],
        [8.6011e-01],
        [8.7424e-01],
        [8.8695e-01],
        [9.1099e-01],
        [9.1999e-01],
        [9.2801e-01],
        [9.3512e-01],
        [9.4138e-01],
        [9.4682e-01],
        [9.5149e-01],
        [9.6710e-01],
        [9.7371e-01],
        [9.7523e-01],
        [9.7618e-01],
        [9.7998e-01],
        [9.7970e-01],
        [9.7876e-01],
        [9.8044e-01],
        [9.7815e-01],
        [9.7493e-01],
        [9.7475e-01],
        [9.6975e-01],
        [9.6831e-01],
        [9.6107e-01],
        [9.5828e-01],
        [9.5494e-01],
        [9.4377e-01],
        [9.3878e-01],
        [9.2349e-01],
        [9.1639e-01],
        [9.0853e-01],
        [8.9985e-01],
        [8.7489e-01],
        [8.6299e-01],
        [8.4994e-01],
        [8.3564e-01],
        [8.1998e-01],
        [7.7581e-01],
        [7.5457e-01],
        [7.3135e-01],
        [7.0596e-01],
        [6.7821e-01],
        [6.4787e-01],
        [6.1472e-01],
        [5.7849e-01],
        [5.3890e-01],
        [4.9563e-01],
        [5.1387e-01],
        [4.6828e-01],
        [5.2844e-01],
        [4.8420e-01],
        [4.3585e-01],
        [4.5622e-01],
        [4.0528e-01],
        [3.4962e-01],
        [2.8881e-01],
        [3.1443e-01],
        [2.5035e-01],
        [2.7734e-01],
        [2.0982e-01],
        [1.3605e-01],
        [1.6713e-01],
        [8.9398e-02],
        [1.2214e-01],
        [4.0241e-02],
        [7.4738e-02],
        [1.0800e-01],
        [2.4795e-02],
        [5.9843e-02],
        [1.1774e-02],
        [1.1774e-02],
        [4.4710e-02],
        [7.9047e-02],
        [1.1774e-02],
        [2.9335e-02],
        [6.4221e-02],
        [9.7861e-02],
        [1.3030e-01],
        [1.6158e-01],
        [8.3336e-02],
        [1.1629e-01],
        [1.4807e-01],
        [1.7872e-01],
        [2.0827e-01],
        [2.3676e-01],
        [2.6424e-01],
        [3.7477e-01],
        [3.9731e-01],
        [4.1905e-01],
        [5.4596e-01],
        [5.6239e-01],
        [5.7823e-01],
        [6.4197e-01],
        [6.5497e-01],
        [6.6750e-01],
        [6.7959e-01],
        [7.2822e-01],
        [7.3814e-01],
        [7.4771e-01],
        [7.8619e-01],
        [7.9404e-01],
        [8.2561e-01],
        [8.3205e-01],
        [8.5796e-01],
        [8.6324e-01],
        [8.8451e-01],
        [8.8884e-01],
        [9.0629e-01],
        [9.2113e-01],
        [9.2416e-01],
        [9.3634e-01],
        [9.4671e-01],
        [9.4883e-01],
        [9.5733e-01],
        [9.6457e-01],
        [9.7073e-01],
        [9.7597e-01],
        [9.7704e-01],
        [9.8134e-01],
        [9.8500e-01],
        [9.8812e-01],
        [9.9077e-01],
        [9.9302e-01],
        [9.9494e-01],
        [9.9658e-01],
        [9.9797e-01],
        [9.9915e-01],
        [1.0002e+00],
        [1.0013e+00],
        [1.0027e+00],
        [1.0032e+00],
        [1.0037e+00],
        [1.0041e+00],
        [1.0044e+00],
        [1.0047e+00],
        [1.0049e+00],
        [1.0051e+00],
        [1.0052e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0053e+00],
        [1.0052e+00],
        [1.0050e+00],
        [1.0048e+00],
        [1.0046e+00],
        [1.0043e+00],
        [1.0040e+00],
        [1.0036e+00],
        [1.0031e+00],
        [1.0025e+00],
        [1.0018e+00],
        [1.0009e+00],
        [9.9998e-01],
        [9.9883e-01],
        [9.9750e-01],
        [9.9595e-01],
        [9.9410e-01],
        [9.9201e-01],
        [9.8960e-01],
        [9.8684e-01],
        [9.8369e-01],
        [9.7992e-01],
        [9.7580e-01],
        [9.7116e-01],
        [9.6588e-01],
        [9.5993e-01],
        [9.5303e-01],
        [9.4559e-01],
        [9.3723e-01],
        [9.2803e-01],
        [9.1793e-01],
        [9.0610e-01],
        [8.9382e-01],
        [8.8051e-01],
        [8.6590e-01],
        [8.4990e-01],
        [8.3166e-01],
        [8.1325e-01],
        [7.9373e-01],
        [7.7223e-01],
        [7.4955e-01],
        [7.2686e-01],
        [7.0097e-01],
        [6.7528e-01],
        [6.4293e-01],
        [6.1541e-01],
        [5.8580e-01],
        [5.5394e-01],
        [5.2346e-01],
        [4.9091e-01],
        [4.5832e-01],
        [4.2593e-01],
        [3.9402e-01],
        [3.6287e-01],
        [3.2167e-01],
        [2.8965e-01],
        [2.5904e-01],
        [2.2713e-01],
        [2.0018e-01],
        [1.7229e-01],
        [1.4680e-01],
        [1.2398e-01],
        [1.0408e-01],
        [7.2191e-02],
        [5.8558e-02],
        [4.4725e-02],
        [3.0690e-02],
        [2.4151e-02],
        [1.7567e-02],
        [1.1774e-02],
        [1.2063e-02],
        [2.0910e-02],
        [2.9678e-02],
        [2.6253e-02],
        [3.4974e-02],
        [5.1105e-02],
        [6.6969e-02],
        [8.9754e-02],
        [1.1199e-01],
        [1.4047e-01],
        [1.6804e-01],
        [1.9474e-01],
        [2.2669e-01],
        [2.4802e-01],
        [2.7787e-01],
        [3.1200e-01],
        [3.4452e-01],
        [3.8042e-01],
        [4.1438e-01],
        [4.5085e-01],
        [4.8098e-01],
        [5.1334e-01],
        [5.5087e-01],
        [5.7892e-01],
        [6.1146e-01],
        [6.4151e-01],
        [6.6928e-01],
        [6.9492e-01],
        [7.1595e-01],
        [7.3804e-01],
        [7.6229e-01],
        [7.8434e-01],
        [8.0752e-01],
        [8.2548e-01],
        [8.4435e-01],
        [8.6125e-01],
        [8.7639e-01],
        [8.8994e-01],
        [9.0368e-01],
        [9.1437e-01],
        [9.2522e-01],
        [9.3478e-01],
        [9.4418e-01],
        [9.5149e-01],
        [9.5869e-01],
        [9.6428e-01],
        [9.7034e-01],
        [9.7504e-01],
        [9.7845e-01],
        [9.8244e-01],
        [9.8586e-01],
        [9.8878e-01],
        [9.9127e-01],
        [9.9340e-01],
        [9.9539e-01],
        [9.9706e-01],
        [9.9847e-01],
        [9.9965e-01],
        [1.0007e+00],
        [1.0015e+00],
        [1.0023e+00],
        [1.0029e+00],
        [1.0034e+00],
        [1.0039e+00],
        [1.0042e+00],
        [1.0046e+00],
        [1.0048e+00],
        [1.0050e+00],
        [1.0051e+00],
        [1.0053e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0054e+00],
        [1.0052e+00],
        [1.0051e+00],
        [1.0049e+00],
        [1.0047e+00],
        [1.0044e+00],
        [1.0040e+00],
        [1.0036e+00],
        [1.0034e+00],
        [1.0029e+00],
        [1.0022e+00],
        [1.0013e+00],
        [1.0002e+00],
        [9.9977e-01],
        [9.9837e-01],
        [9.9664e-01],
        [9.9586e-01],
        [9.9357e-01],
        [9.9075e-01],
        [9.8947e-01],
        [9.8571e-01],
        [9.8401e-01],
        [9.7900e-01],
        [9.7673e-01],
        [9.7006e-01],
        [9.6704e-01],
        [9.5815e-01],
        [9.5413e-01],
        [9.4976e-01],
        [9.3693e-01],
        [9.3111e-01],
        [9.2481e-01],
        [9.1797e-01],
        [8.9786e-01],
        [8.8876e-01],
        [8.7888e-01],
        [8.3493e-01],
        [8.2052e-01],
        [8.0489e-01],
        [7.5893e-01],
        [7.3811e-01],
        [7.1553e-01],
        [6.9106e-01],
        [6.6452e-01],
        [6.3574e-01],
        [6.0453e-01],
        [6.2184e-01],
        [5.8946e-01],
        [5.5436e-01],
        [5.1629e-01],
        [4.7502e-01],
        [4.3027e-01],
        [4.5508e-01],
        [4.0865e-01],
        [3.5830e-01],
        [3.0371e-01],
        [3.3398e-01],
        [2.7734e-01],
        [3.0875e-01],
        [2.4998e-01],
        [1.8626e-01],
        [2.2159e-01],
        [1.5548e-01],
        [1.9214e-01],
        [1.2354e-01],
        [1.6158e-01],
        [1.9798e-01],
        [1.2987e-01],
        [1.6764e-01],
        [9.6974e-02],
        [1.3616e-01],
        [1.7365e-01],
        [2.0953e-01],
        [1.4240e-01],
        [1.7963e-01],
        [2.1525e-01],
        [6.6747e-02],
        [1.0723e-01],
        [3.1479e-02],
        [7.3487e-02],
        [1.1368e-01],
        [1.5215e-01],
        [1.8895e-01],
        [2.2417e-01],
        [2.5787e-01],
        [2.9012e-01],
        [3.2098e-01],
        [3.5051e-01],
        [4.5245e-01],
        [4.7631e-01],
        [4.9914e-01],
        [5.2099e-01],
        [5.4189e-01],
        [6.1407e-01],
        [6.3096e-01],
        [6.4713e-01],
        [6.6259e-01],
        [7.1600e-01],
        [7.2849e-01],
        [7.7164e-01],
        [7.8174e-01],
        [7.9141e-01],
        [8.2477e-01],
        [8.3258e-01],
        [8.5954e-01],
        [8.6585e-01],
        [8.8764e-01],
        [9.0603e-01],
        [9.1034e-01],
        [9.2520e-01],
        [9.3776e-01],
        [9.4069e-01],
        [9.5084e-01],
        [9.5940e-01],
        [9.6141e-01],
        [9.5926e-01],
        [9.6652e-01],
        [9.7264e-01],
        [9.7782e-01],
        [9.8219e-01],
        [9.8588e-01],
        [9.8899e-01],
        [9.8972e-01],
        [9.9224e-01],
        [9.9436e-01],
        [9.9730e-01],
        [1.0001e+00],
        [9.9977e-01],
        [1.0017e+00],
        [1.0015e+00],
        [1.0029e+00],
        [1.0028e+00],
        [1.0038e+00],
        [1.0037e+00],
        [1.0044e+00],
        [1.0047e+00],
        [1.0046e+00],
        [1.0050e+00],
        [1.0050e+00],
        [1.0053e+00],
        [1.0054e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([ 2.6879e-02, -1.1467e-02,  1.9109e-02,  3.8010e-02,  1.0745e-02,
         2.9763e-02, -6.8690e-03,  2.0513e-03, -6.3599e-03, -6.2976e-03,
        -5.9274e-03, -1.4561e-02, -5.6935e-03, -2.2300e-02, -5.5570e-03,
        -2.5288e-02, -5.5659e-03, -2.5244e-02, -5.5558e-03, -2.5162e-02,
        -5.8270e-03, -2.8482e-02, -2.1517e-02, -3.4457e-02, -2.1413e-02,
        -3.9004e-02, -2.1614e-02, -3.8261e-02, -3.5429e-02, -3.1550e-02,
        -3.5142e-02, -3.6384e-02, -3.5306e-02, -2.4224e-02, -4.5856e-02,
        -2.8892e-02, -4.6191e-02, -1.8299e-02, -3.9309e-02, -2.3079e-02,
        -2.8343e-02, -1.4037e-02, -3.4594e-02, -6.4630e-03,  4.2878e-03,
        -7.3781e-05,  9.5700e-03, -6.5776e-03,  1.3882e-02, -1.8416e-03,
         1.7315e-02,  1.7338e-03,  1.9971e-02,  4.2371e-03,  2.1896e-02,
         5.7312e-03,  2.3141e-02,  6.3270e-03,  2.3753e-02,  5.9601e-03,
         2.3789e-02,  4.7950e-03,  2.3243e-02,  1.6208e-02,  2.2211e-02,
         1.4518e-02,  3.0903e-02,  1.2265e-02,  2.9701e-02,  2.2742e-02,
         2.8174e-02,  2.0611e-02,  3.6036e-02,  1.8138e-02,  3.4671e-02,
         2.8038e-02,  4.1506e-02,  3.6176e-02,  4.0341e-02,  3.4622e-02,
         4.6201e-02,  4.1654e-02,  5.0876e-02,  5.3221e-02,  5.0105e-02,
         5.6454e-02,  5.3987e-02,  5.8952e-02,  5.7008e-02,  6.0874e-02,
         5.9333e-02,  6.2323e-02,  6.1088e-02,  6.0867e-02,  6.1569e-02,
         6.2159e-02,  6.3288e-02,  6.3616e-02,  6.3877e-02,  6.4069e-02,
         6.4197e-02,  6.4268e-02,  6.4282e-02,  6.4737e-02,  6.4798e-02,
         6.4622e-02,  6.4406e-02,  6.4316e-02,  6.4019e-02,  6.3673e-02,
         6.3476e-02,  6.3040e-02,  6.2538e-02,  6.2244e-02,  6.1624e-02,
         6.1267e-02,  6.0500e-02,  6.0073e-02,  5.9619e-02,  5.8603e-02,
         5.8061e-02,  5.6791e-02,  5.6126e-02,  5.5424e-02,  5.4679e-02,
         5.2829e-02,  5.1902e-02,  5.0914e-02,  4.9861e-02,  4.8733e-02,
         4.5789e-02,  4.4362e-02,  4.2808e-02,  4.1157e-02,  3.9373e-02,
         3.7462e-02,  3.5400e-02,  3.3179e-02,  3.0788e-02,  2.8198e-02,
         2.9226e-02,  2.6530e-02,  2.9992e-02,  2.7358e-02,  2.4529e-02,
         2.5670e-02,  2.2705e-02,  1.9526e-02,  1.6075e-02,  1.7482e-02,
         1.3873e-02,  1.5358e-02,  1.1562e-02,  7.4795e-03,  9.1865e-03,
         4.8988e-03,  6.6705e-03,  2.1949e-03,  4.0844e-03,  5.8875e-03,
         1.3228e-03,  3.2454e-03,  6.3625e-04,  6.3522e-04,  2.4073e-03,
         4.2748e-03,  6.3272e-04,  1.5699e-03,  3.4446e-03,  5.2585e-03,
         6.9891e-03,  8.6871e-03,  4.4611e-03,  6.2228e-03,  7.9268e-03,
         9.5512e-03,  1.1122e-02,  1.2640e-02,  1.4085e-02,  2.0059e-02,
         2.1267e-02,  2.2412e-02,  2.9368e-02,  3.0242e-02,  3.1098e-02,
         3.4625e-02,  3.5307e-02,  3.5975e-02,  3.6630e-02,  3.9363e-02,
         3.9873e-02,  4.0372e-02,  4.2577e-02,  4.2983e-02,  4.4812e-02,
         4.5137e-02,  4.6654e-02,  4.6913e-02,  4.8177e-02,  4.8384e-02,
         4.9427e-02,  5.0326e-02,  5.0454e-02,  5.1202e-02,  5.1837e-02,
         5.1915e-02,  5.2439e-02,  5.2888e-02,  5.3270e-02,  5.3596e-02,
         5.3606e-02,  5.3871e-02,  5.4094e-02,  5.4281e-02,  5.4435e-02,
         5.4563e-02,  5.4667e-02,  5.4750e-02,  5.4815e-02,  5.4864e-02,
         5.4899e-02,  5.4956e-02,  5.5057e-02,  5.5047e-02,  5.5050e-02,
         5.5026e-02,  5.5012e-02,  5.4977e-02,  5.4950e-02,  5.4906e-02,
         5.4870e-02,  5.4828e-02,  5.4783e-02,  5.4728e-02,  5.4678e-02,
         5.4625e-02,  5.4569e-02,  5.4512e-02,  5.4453e-02,  5.4393e-02,
         5.4334e-02,  5.4271e-02,  5.4208e-02,  5.4144e-02,  5.4080e-02,
         5.4014e-02,  5.3949e-02,  5.3883e-02,  5.3816e-02,  5.3749e-02,
         5.3682e-02,  5.3615e-02,  5.3548e-02,  5.3480e-02,  5.3412e-02,
         5.3344e-02,  5.3276e-02,  5.3208e-02,  5.3140e-02,  5.3072e-02,
         5.3004e-02,  5.2936e-02,  5.2868e-02,  5.2800e-02,  5.2732e-02,
         5.2665e-02,  5.2597e-02,  5.2529e-02,  5.2462e-02,  5.2394e-02,
         5.2327e-02,  5.2259e-02,  5.2192e-02,  5.2125e-02,  5.2058e-02,
         5.1991e-02,  5.1925e-02,  5.1858e-02,  5.1792e-02,  5.1725e-02,
         5.1659e-02,  5.1593e-02,  5.1527e-02,  5.1461e-02,  5.1395e-02,
         5.1329e-02,  5.1264e-02,  5.1199e-02,  5.1133e-02,  5.1068e-02,
         5.1003e-02,  5.0938e-02,  5.0873e-02,  5.0809e-02,  5.0744e-02,
         5.0680e-02,  5.0616e-02,  5.0551e-02,  5.0487e-02,  5.0423e-02,
         5.0360e-02,  5.0296e-02,  5.0232e-02,  5.0168e-02,  5.0105e-02,
         5.0042e-02,  4.9979e-02,  4.9916e-02,  4.9853e-02,  4.9790e-02,
         4.9727e-02,  4.9665e-02,  4.9603e-02,  4.9540e-02,  4.9478e-02,
         4.9416e-02,  4.9354e-02,  4.9292e-02,  4.9230e-02,  4.9169e-02,
         4.9107e-02,  4.9046e-02,  4.8984e-02,  4.8923e-02,  4.8862e-02,
         4.8801e-02,  4.8740e-02,  4.8680e-02,  4.8619e-02,  4.8559e-02,
         4.8498e-02,  4.8438e-02,  4.8378e-02,  4.8318e-02,  4.8258e-02,
         4.8198e-02,  4.8138e-02,  4.8079e-02,  4.8019e-02,  4.7960e-02,
         4.7901e-02,  4.7841e-02,  4.7782e-02,  4.7723e-02,  4.7664e-02,
         4.7606e-02,  4.7547e-02,  4.7488e-02,  4.7430e-02,  4.7371e-02,
         4.7313e-02,  4.7255e-02,  4.7197e-02,  4.7139e-02,  4.7081e-02,
         4.7024e-02,  4.6966e-02,  4.6909e-02,  4.6851e-02,  4.6794e-02,
         4.6737e-02,  4.6680e-02,  4.6623e-02,  4.6566e-02,  4.6509e-02,
         4.6452e-02,  4.6396e-02,  4.6339e-02,  4.6283e-02,  4.6227e-02,
         4.6170e-02,  4.6114e-02,  4.6058e-02,  4.6003e-02,  4.5947e-02,
         4.5891e-02,  4.5836e-02,  4.5780e-02,  4.5725e-02,  4.5669e-02,
         4.5614e-02,  4.5559e-02,  4.5504e-02,  4.5449e-02,  4.5395e-02,
         4.5340e-02,  4.5285e-02,  4.5231e-02,  4.5177e-02,  4.5122e-02,
         4.5068e-02,  4.5014e-02,  4.4960e-02,  4.4906e-02,  4.4852e-02,
         4.4798e-02,  4.4745e-02,  4.4691e-02,  4.4638e-02,  4.4585e-02,
         4.4531e-02,  4.4478e-02,  4.4425e-02,  4.4372e-02,  4.4319e-02,
         4.4267e-02,  4.4214e-02,  4.4161e-02,  4.4109e-02,  4.4056e-02,
         4.4004e-02,  4.3952e-02,  4.3900e-02,  4.3847e-02,  4.3795e-02,
         4.3744e-02,  4.3692e-02,  4.3640e-02,  4.3589e-02,  4.3537e-02,
         4.3486e-02,  4.3434e-02,  4.3383e-02,  4.3332e-02,  4.3281e-02,
         4.3230e-02,  4.3179e-02,  4.3128e-02,  4.3078e-02,  4.3027e-02,
         4.2977e-02,  4.2926e-02,  4.2876e-02,  4.2826e-02,  4.2775e-02,
         4.2725e-02,  4.2675e-02,  4.2625e-02,  4.2575e-02,  4.2526e-02,
         4.2476e-02,  4.2426e-02,  4.2377e-02,  4.2327e-02,  4.2278e-02,
         4.2229e-02,  4.2180e-02,  4.2131e-02,  4.2082e-02,  4.2033e-02,
         4.1984e-02,  4.1935e-02,  4.1887e-02,  4.1838e-02,  4.1789e-02,
         4.1741e-02,  4.1693e-02,  4.1644e-02,  4.1596e-02,  4.1548e-02,
         4.1500e-02,  4.1452e-02,  4.1404e-02,  4.1356e-02,  4.1308e-02,
         4.1260e-02,  4.1213e-02,  4.1165e-02,  4.1117e-02,  4.1069e-02,
         4.1022e-02,  4.0974e-02,  4.0926e-02,  4.0878e-02,  4.0830e-02,
         4.0782e-02,  4.0734e-02,  4.0686e-02,  4.0638e-02,  4.0589e-02,
         4.0540e-02,  4.0491e-02,  4.0441e-02,  4.0391e-02,  4.0341e-02,
         4.0290e-02,  4.0238e-02,  4.0185e-02,  4.0132e-02,  4.0077e-02,
         4.0022e-02,  3.9965e-02,  3.9907e-02,  3.9847e-02,  3.9786e-02,
         3.9722e-02,  3.9656e-02,  3.9588e-02,  3.9517e-02,  3.9443e-02,
         3.7490e-02,  3.7290e-02,  3.7078e-02,  3.6852e-02,  3.6608e-02,
         3.6352e-02,  3.6075e-02,  3.5784e-02,  3.5475e-02,  3.5142e-02,
         3.4793e-02,  3.4423e-02,  3.4020e-02,  3.3606e-02,  3.3168e-02,
         3.2708e-02,  3.2224e-02,  3.1695e-02,  3.1159e-02,  3.0601e-02,
         3.0015e-02,  2.9402e-02,  2.8745e-02,  2.8083e-02,  2.7393e-02,
         2.6683e-02,  2.5957e-02,  2.5160e-02,  2.4388e-02,  2.3599e-02,
         2.2788e-02,  2.1951e-02,  2.1055e-02,  2.0203e-02,  1.9351e-02,
         1.8460e-02,  1.7571e-02,  1.6725e-02,  1.5811e-02,  1.4950e-02,
         1.3917e-02,  1.3081e-02,  1.2223e-02,  1.1339e-02,  1.0531e-02,
         9.7033e-03,  8.9014e-03,  8.1393e-03,  7.4098e-03,  6.7272e-03,
         5.8500e-03,  5.1961e-03,  4.5808e-03,  3.9614e-03,  3.4521e-03,
         2.9456e-03,  2.4757e-03,  2.0720e-03,  1.7265e-03,  1.1840e-03,
         9.6130e-04,  7.2387e-04,  4.9488e-04,  3.9238e-04,  2.8231e-04,
         1.8824e-04,  1.8824e-04,  3.2866e-04,  4.7699e-04,  4.2187e-04,
         5.6238e-04,  8.2810e-04,  1.0864e-03,  1.4706e-03,  1.8403e-03,
         2.3295e-03,  2.8199e-03,  3.2962e-03,  3.8785e-03,  4.2772e-03,
         4.8468e-03,  5.5157e-03,  6.1712e-03,  6.9195e-03,  7.6474e-03,
         8.4608e-03,  9.1533e-03,  9.9176e-03,  1.0852e-02,  1.1578e-02,
         1.2453e-02,  1.3291e-02,  1.4105e-02,  1.4893e-02,  1.5557e-02,
         1.6290e-02,  1.7131e-02,  1.7937e-02,  1.8829e-02,  1.9556e-02,
         2.0366e-02,  2.1129e-02,  2.1850e-02,  2.2531e-02,  2.3267e-02,
         2.3867e-02,  2.4518e-02,  2.5124e-02,  2.5763e-02,  2.6289e-02,
         2.6841e-02,  2.7295e-02,  2.7825e-02,  2.8261e-02,  2.8592e-02,
         2.9012e-02,  2.9397e-02,  2.9749e-02,  3.0070e-02,  3.0364e-02,
         3.0660e-02,  3.0928e-02,  3.1170e-02,  3.1387e-02,  3.1603e-02,
         3.1778e-02,  3.1951e-02,  3.2104e-02,  3.2241e-02,  3.2373e-02,
         3.2478e-02,  3.2589e-02,  3.2667e-02,  3.2751e-02,  3.2796e-02,
         3.2859e-02,  3.2911e-02,  3.2954e-02,  3.2989e-02,  3.3016e-02,
         3.3044e-02,  3.3059e-02,  3.3068e-02,  3.3077e-02,  3.3081e-02,
         3.3081e-02,  3.3073e-02,  3.3066e-02,  3.3055e-02,  3.3044e-02,
         3.3028e-02,  3.3009e-02,  3.2991e-02,  3.2969e-02,  3.2945e-02,
         3.2922e-02,  3.2897e-02,  3.2871e-02,  3.2843e-02,  3.2815e-02,
         3.2787e-02,  3.2757e-02,  3.2728e-02,  3.2697e-02,  3.2667e-02,
         3.2636e-02,  3.2604e-02,  3.2573e-02,  3.2541e-02,  3.2509e-02,
         3.2477e-02,  3.2445e-02,  3.2412e-02,  3.2380e-02,  3.2347e-02,
         3.2315e-02,  3.2282e-02,  3.2250e-02,  3.2217e-02,  3.2184e-02,
         3.2152e-02,  3.2119e-02,  3.2086e-02,  3.2054e-02,  3.2021e-02,
         3.1989e-02,  3.1956e-02,  3.1924e-02,  3.1891e-02,  3.1859e-02,
         3.1827e-02,  3.1794e-02,  3.1762e-02,  3.1730e-02,  3.1698e-02,
         3.1666e-02,  3.1634e-02,  3.1601e-02,  3.1569e-02,  3.1537e-02,
         3.1505e-02,  3.1474e-02,  3.1442e-02,  3.1410e-02,  3.1378e-02,
         3.1347e-02,  3.1315e-02,  3.1284e-02,  3.1252e-02,  3.1221e-02,
         3.1189e-02,  3.1158e-02,  3.1127e-02,  3.1095e-02,  3.1064e-02,
         3.1033e-02,  3.1002e-02,  3.0971e-02,  3.0940e-02,  3.0909e-02,
         3.0878e-02,  3.0847e-02,  3.0816e-02,  3.0786e-02,  3.0755e-02,
         3.0725e-02,  3.0694e-02,  3.0664e-02,  3.0633e-02,  3.0603e-02,
         3.0573e-02,  3.0543e-02,  3.0513e-02,  3.0483e-02,  3.0454e-02,
         3.0424e-02,  3.0395e-02,  3.0366e-02,  3.0337e-02,  3.0309e-02,
         3.0280e-02,  3.0252e-02,  3.0224e-02,  3.0197e-02,  3.0169e-02,
         3.0143e-02,  3.0117e-02,  3.0092e-02,  3.0067e-02,  3.0043e-02,
         3.0019e-02,  2.9996e-02,  2.9973e-02,  2.9952e-02,  2.9933e-02,
         2.9915e-02,  2.9895e-02,  2.9880e-02,  2.9864e-02,  2.9853e-02,
         2.9839e-02,  2.9833e-02,  2.9823e-02,  2.9841e-02,  2.9847e-02,
         2.9848e-02,  2.9853e-02,  2.9860e-02,  2.9871e-02,  2.9886e-02,
         2.9906e-02,  2.9930e-02,  2.9959e-02,  2.9994e-02,  3.0035e-02,
         3.0034e-02,  3.0084e-02,  3.0140e-02,  3.0203e-02,  3.0274e-02,
         3.0285e-02,  3.0366e-02,  3.0455e-02,  3.0473e-02,  3.0572e-02,
         3.0677e-02,  3.0702e-02,  3.0813e-02,  3.0839e-02,  3.0954e-02,
         3.0981e-02,  3.1093e-02,  3.1114e-02,  3.1211e-02,  3.1224e-02,
         3.1235e-02,  3.1286e-02,  3.1278e-02,  3.1259e-02,  3.1232e-02,
         3.1164e-02,  3.1090e-02,  3.1000e-02,  3.0568e-02,  3.0364e-02,
         3.0118e-02,  2.9347e-02,  2.8929e-02,  2.8452e-02,  2.7886e-02,
         2.7254e-02,  2.6513e-02,  2.5662e-02,  2.6098e-02,  2.5178e-02,
         2.4154e-02,  2.2955e-02,  2.1572e-02,  2.0013e-02,  2.0848e-02,
         1.9176e-02,  1.7236e-02,  1.5007e-02,  1.6214e-02,  1.3850e-02,
         1.5153e-02,  1.2623e-02,  9.6723e-03,  1.1324e-02,  8.1939e-03,
         9.9257e-03,  6.6019e-03,  8.4662e-03,  1.0174e-02,  6.8710e-03,
         8.6876e-03,  5.2038e-03,  7.1591e-03,  8.9504e-03,  1.0614e-02,
         7.4179e-03,  9.2084e-03,  1.0828e-02,  3.5843e-03,  5.6629e-03,
         1.7022e-03,  3.9377e-03,  5.9625e-03,  7.8182e-03,  9.5192e-03,
         1.1121e-02,  1.2548e-02,  1.3875e-02,  1.5109e-02,  1.6239e-02,
         1.9870e-02,  2.0624e-02,  2.1324e-02,  2.1975e-02,  2.2566e-02,
         2.4511e-02,  2.4909e-02,  2.5276e-02,  2.5604e-02,  2.6727e-02,
         2.6932e-02,  2.7677e-02,  2.7807e-02,  2.7927e-02,  2.8356e-02,
         2.8419e-02,  2.8669e-02,  2.8696e-02,  2.8820e-02,  2.8873e-02,
         2.8854e-02,  2.8844e-02,  2.8795e-02,  2.8755e-02,  2.8672e-02,
         2.8573e-02,  2.8524e-02,  2.8518e-02,  2.8406e-02,  2.8287e-02,
         2.8163e-02,  2.8038e-02,  2.7912e-02,  2.7788e-02,  2.7736e-02,
         2.7616e-02,  2.7499e-02,  2.7323e-02,  2.7122e-02,  2.7117e-02,
         2.6935e-02,  2.6928e-02,  2.6765e-02,  2.6756e-02,  2.6612e-02,
         2.6600e-02,  2.6472e-02,  2.6400e-02,  2.6386e-02,  2.6281e-02,
         2.6266e-02,  2.6172e-02,  2.6116e-02,  2.6039e-02,  2.6021e-02,
         2.5953e-02,  2.5934e-02,  2.5851e-02,  2.5831e-02,  2.5779e-02,
         2.5742e-02,  2.5697e-02,  2.5676e-02,  2.5624e-02,  2.5603e-02,
         2.5566e-02,  2.5536e-02,  2.5503e-02,  2.5481e-02,  2.5444e-02,
         2.5422e-02,  2.5389e-02,  2.5366e-02,  2.5336e-02,  2.5313e-02,
         2.5285e-02,  2.5262e-02,  2.5235e-02,  2.5213e-02,  2.5187e-02,
         2.5164e-02,  2.5139e-02,  2.5116e-02,  2.5092e-02,  2.5069e-02,
         2.5045e-02,  2.5022e-02,  2.5000e-02,  2.4976e-02,  2.4953e-02,
         2.4931e-02,  2.4908e-02,  2.4885e-02,  2.4863e-02,  2.4840e-02,
         2.4818e-02,  2.4795e-02,  2.4773e-02,  2.4750e-02,  2.4728e-02,
         2.4706e-02,  2.4684e-02,  2.4661e-02,  2.4639e-02,  2.4617e-02,
         2.4595e-02,  2.4573e-02,  2.4551e-02,  2.4529e-02,  2.4507e-02,
         2.4485e-02,  2.4463e-02,  2.4441e-02,  2.4419e-02,  2.4397e-02,
         2.4375e-02,  2.4354e-02,  2.4332e-02,  2.4310e-02,  2.4289e-02,
         2.4267e-02,  2.4245e-02,  2.4224e-02,  2.4202e-02,  2.4181e-02,
         2.4159e-02,  2.4138e-02,  2.4116e-02,  2.4095e-02,  2.4073e-02],
       device='cuda:0')
Selected points (indices): {104}
Selected new x values (normalized): tensor([0.1041], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-1583.5835], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter3/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:34:03 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_3 [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		M_1: [-1583.58]              [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:34:03 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:34:04 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_3, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:34:04 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:34:04 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_3/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 3
Starting iteration 4
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.1617, 0.0046, 0.0561, 0.0180, 0.1041, 0.5812, 0.8528],
       device='cuda:0') torch.Size([7])
These training_points are used in the GP tensor([0.1617, 0.0046, 0.0561, 0.0180, 0.1041, 0.5812, 0.8528],
       device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[1.0000e-06],
        [3.0962e-01],
        [2.3091e-02],
        [2.2438e-01],
        [1.0000e-06],
        [3.1449e-01],
        [2.0791e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [6.9999e-02],
        [9.1683e-04],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [3.8143e-03],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.1614e-01],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.3088e-01],
        [1.0000e-06],
        [7.4129e-02],
        [1.0000e-06],
        [2.2158e-01],
        [6.2298e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0587e-01],
        [1.9942e-03],
        [2.1820e-01],
        [4.4565e-02],
        [1.0000e-06],
        [1.5397e-01],
        [1.0000e-06],
        [2.4422e-01],
        [6.8298e-02],
        [3.1840e-01],
        [1.5611e-01],
        [1.0000e-06],
        [2.2678e-01],
        [3.6092e-02],
        [2.8179e-01],
        [9.9051e-02],
        [3.2205e-01],
        [1.4334e-01],
        [3.4798e-01],
        [1.6933e-01],
        [1.0000e-06],
        [1.7694e-01],
        [2.7150e-01],
        [5.6093e-02],
        [4.2564e-02],
        [1.3879e-01],
        [1.1664e-01],
        [1.9685e-01],
        [1.6765e-01],
        [1.3333e-01],
        [2.0084e-01],
        [1.0000e-06],
        [7.9015e-03],
        [1.0000e-06],
        [2.0382e-02],
        [1.0000e-06],
        [2.2336e-02],
        [7.9883e-02],
        [1.6238e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.2256e-03],
        [6.1688e-03],
        [9.2648e-03],
        [1.0917e-02],
        [1.1426e-02],
        [1.1215e-02],
        [1.1557e-02],
        [1.0979e-02],
        [9.6823e-03],
        [7.8217e-03],
        [5.5137e-03],
        [2.2452e-02],
        [6.8828e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [2.4013e-02],
        [6.7213e-02],
        [1.0751e-01],
        [1.4494e-01],
        [1.7950e-01],
        [1.2085e-01],
        [1.5328e-01],
        [1.8245e-01],
        [2.0826e-01],
        [3.2171e-01],
        [3.3827e-01],
        [3.5151e-01],
        [4.3699e-01],
        [2.9911e-01],
        [3.0226e-01],
        [3.8362e-01],
        [3.7786e-01],
        [4.4232e-01],
        [4.2835e-01],
        [4.7940e-01],
        [3.2532e-01],
        [3.7650e-01],
        [3.4119e-01],
        [3.8174e-01],
        [4.1567e-01],
        [3.6929e-01],
        [3.9626e-01],
        [4.1890e-01],
        [2.1491e-01],
        [2.3784e-01],
        [2.5719e-01],
        [2.7356e-01],
        [2.8746e-01],
        [2.0524e-01],
        [2.1675e-01],
        [2.2669e-01],
        [6.2717e-02],
        [7.2180e-02],
        [8.0518e-02],
        [8.7935e-02],
        [9.4596e-02],
        [1.0064e-01],
        [1.0618e-01],
        [1.1132e-01],
        [1.0353e-02],
        [1.1027e-02],
        [5.5456e-02],
        [5.9964e-02],
        [6.4319e-02],
        [6.8553e-02],
        [7.2691e-02],
        [1.1092e-02],
        [1.0776e-02],
        [1.2129e-02],
        [1.3264e-01],
        [1.3635e-01],
        [1.4005e-01],
        [2.4504e-01],
        [2.4828e-01],
        [1.9207e-01],
        [1.9555e-01],
        [1.9903e-01],
        [2.9690e-01],
        [3.8291e-01],
        [3.8562e-01],
        [4.6088e-01],
        [4.6326e-01],
        [4.2306e-01],
        [4.9380e-01],
        [4.9606e-01],
        [5.5796e-01],
        [6.1234e-01],
        [6.1410e-01],
        [6.6167e-01],
        [7.0348e-01],
        [6.8110e-01],
        [7.2055e-01],
        [7.5521e-01],
        [7.5634e-01],
        [7.8665e-01],
        [8.1329e-01],
        [8.3669e-01],
        [8.2417e-01],
        [8.4625e-01],
        [8.6565e-01],
        [8.8269e-01],
        [8.9765e-01],
        [9.1080e-01],
        [9.2742e-01],
        [9.3695e-01],
        [9.3634e-01],
        [9.4479e-01],
        [9.5221e-01],
        [9.6159e-01],
        [9.6697e-01],
        [9.7376e-01],
        [9.7937e-01],
        [9.8259e-01],
        [9.8238e-01],
        [9.8649e-01],
        [9.8987e-01],
        [9.9181e-01],
        [9.9427e-01],
        [9.9629e-01],
        [9.9796e-01],
        [9.9934e-01],
        [9.9928e-01],
        [1.0004e+00],
        [1.0017e+00],
        [1.0024e+00],
        [1.0030e+00],
        [1.0035e+00],
        [1.0040e+00],
        [1.0040e+00],
        [1.0043e+00],
        [1.0047e+00],
        [1.0049e+00],
        [1.0051e+00],
        [1.0053e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0054e+00],
        [1.0053e+00],
        [1.0051e+00],
        [1.0050e+00],
        [1.0048e+00],
        [1.0045e+00],
        [1.0043e+00],
        [1.0039e+00],
        [1.0035e+00],
        [1.0030e+00],
        [1.0025e+00],
        [1.0018e+00],
        [1.0010e+00],
        [1.0001e+00],
        [9.9904e-01],
        [9.9779e-01],
        [9.9636e-01],
        [9.9469e-01],
        [9.9270e-01],
        [9.9047e-01],
        [9.8792e-01],
        [9.8499e-01],
        [9.8166e-01],
        [9.7784e-01],
        [9.7375e-01],
        [9.6895e-01],
        [9.6354e-01],
        [9.5750e-01],
        [9.5074e-01],
        [9.4323e-01],
        [9.3483e-01],
        [9.2562e-01],
        [9.1540e-01],
        [9.0427e-01],
        [8.9199e-01],
        [8.7872e-01],
        [8.6418e-01],
        [8.4860e-01],
        [8.3165e-01],
        [8.1361e-01],
        [7.9413e-01],
        [7.7358e-01],
        [7.5153e-01],
        [7.2848e-01],
        [7.0393e-01],
        [6.7981e-01],
        [6.5089e-01],
        [6.2553e-01],
        [5.9501e-01],
        [5.6737e-01],
        [5.3403e-01],
        [5.0621e-01],
        [4.7032e-01],
        [4.4094e-01],
        [4.0508e-01],
        [3.7706e-01],
        [3.3975e-01],
        [3.1410e-01],
        [2.7876e-01],
        [2.5077e-01],
        [2.1836e-01],
        [1.9441e-01],
        [1.6288e-01],
        [1.4063e-01],
        [1.1401e-01],
        [9.7593e-02],
        [7.3298e-02],
        [6.3521e-02],
        [4.2087e-02],
        [3.1982e-02],
        [1.7582e-02],
        [2.2703e-02],
        [2.0127e-02],
        [1.3335e-02],
        [2.6162e-02],
        [1.9412e-02],
        [3.9738e-02],
        [4.0652e-02],
        [6.0540e-02],
        [6.8783e-02],
        [9.5234e-02],
        [1.1020e-01],
        [1.3548e-01],
        [1.5645e-01],
        [1.8685e-01],
        [2.1280e-01],
        [2.4118e-01],
        [2.7117e-01],
        [3.0297e-01],
        [3.3054e-01],
        [3.6979e-01],
        [3.9474e-01],
        [4.3026e-01],
        [4.6141e-01],
        [4.9704e-01],
        [5.2458e-01],
        [5.5608e-01],
        [5.8701e-01],
        [6.0968e-01],
        [6.4572e-01],
        [6.7049e-01],
        [6.9356e-01],
        [7.1954e-01],
        [7.4559e-01],
        [7.6725e-01],
        [7.8710e-01],
        [8.1009e-01],
        [8.2638e-01],
        [8.4386e-01],
        [8.5965e-01],
        [8.7704e-01],
        [8.8959e-01],
        [9.0091e-01],
        [9.1114e-01],
        [9.2370e-01],
        [9.3285e-01],
        [9.4098e-01],
        [9.4821e-01],
        [9.5586e-01],
        [9.6211e-01],
        [9.6699e-01],
        [9.7185e-01],
        [9.7682e-01],
        [9.8085e-01],
        [9.8398e-01],
        [9.8701e-01],
        [9.9001e-01],
        [9.9221e-01],
        [9.9410e-01],
        [9.9573e-01],
        [9.9748e-01],
        [9.9875e-01],
        [9.9983e-01],
        [1.0007e+00],
        [1.0016e+00],
        [1.0023e+00],
        [1.0029e+00],
        [1.0034e+00],
        [1.0038e+00],
        [1.0042e+00],
        [1.0045e+00],
        [1.0047e+00],
        [1.0049e+00],
        [1.0051e+00],
        [1.0052e+00],
        [1.0054e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0054e+00],
        [1.0052e+00],
        [1.0051e+00],
        [1.0049e+00],
        [1.0047e+00],
        [1.0044e+00],
        [1.0040e+00],
        [1.0039e+00],
        [1.0036e+00],
        [1.0030e+00],
        [1.0022e+00],
        [1.0015e+00],
        [1.0004e+00],
        [9.9935e-01],
        [9.9812e-01],
        [9.9792e-01],
        [9.9642e-01],
        [9.9391e-01],
        [9.9166e-01],
        [9.8898e-01],
        [9.8579e-01],
        [9.8201e-01],
        [9.7750e-01],
        [9.7852e-01],
        [9.7336e-01],
        [9.6723e-01],
        [9.5993e-01],
        [9.5768e-01],
        [9.4858e-01],
        [9.3777e-01],
        [9.4021e-01],
        [9.2782e-01],
        [9.1308e-01],
        [9.0852e-01],
        [8.9015e-01],
        [8.6830e-01],
        [8.6154e-01],
        [8.3429e-01],
        [8.4045e-01],
        [8.3233e-01],
        [7.9956e-01],
        [7.8942e-01],
        [7.4855e-01],
        [6.9997e-01],
        [6.8493e-01],
        [6.6916e-01],
        [6.8127e-01],
        [6.6532e-01],
        [6.0101e-01],
        [5.8112e-01],
        [5.6025e-01],
        [4.7610e-01],
        [4.5007e-01],
        [4.2275e-01],
        [4.4372e-01],
        [4.1610e-01],
        [3.8712e-01],
        [3.5671e-01],
        [3.2481e-01],
        [1.9620e-01],
        [1.5641e-01],
        [2.8318e-01],
        [2.4767e-01],
        [2.1041e-01],
        [1.7132e-01],
        [1.3031e-01],
        [8.7279e-02],
        [4.2138e-02],
        [1.1668e-02],
        [1.4567e-01],
        [1.0340e-01],
        [5.9046e-02],
        [1.2924e-01],
        [8.6157e-02],
        [4.0961e-02],
        [1.1668e-02],
        [1.1668e-02],
        [2.0846e-01],
        [1.6928e-01],
        [1.2817e-01],
        [1.9323e-01],
        [1.5330e-01],
        [1.1140e-01],
        [1.7771e-01],
        [1.3701e-01],
        [3.5353e-01],
        [3.2147e-01],
        [3.7221e-01],
        [3.4107e-01],
        [3.9035e-01],
        [3.6011e-01],
        [4.0798e-01],
        [5.5697e-01],
        [5.3491e-01],
        [5.6982e-01],
        [6.0215e-01],
        [5.8231e-01],
        [6.1371e-01],
        [6.4278e-01],
        [6.6970e-01],
        [7.1986e-01],
        [7.4106e-01],
        [7.6069e-01],
        [7.7887e-01],
        [7.9570e-01],
        [8.1128e-01],
        [8.2570e-01],
        [8.3906e-01],
        [8.8062e-01],
        [8.8991e-01],
        [8.9850e-01],
        [9.0646e-01],
        [9.1383e-01],
        [9.2065e-01],
        [9.2697e-01],
        [9.3281e-01],
        [9.5102e-01],
        [9.6105e-01],
        [9.6437e-01],
        [9.6744e-01],
        [9.7029e-01],
        [9.7680e-01],
        [9.7895e-01],
        [9.8565e-01],
        [9.8935e-01],
        [9.9057e-01],
        [9.9170e-01],
        [9.9429e-01],
        [9.9515e-01],
        [9.9711e-01],
        [9.9775e-01],
        [1.0005e+00],
        [1.0009e+00],
        [1.0018e+00],
        [1.0025e+00],
        [1.0028e+00],
        [1.0033e+00],
        [1.0035e+00],
        [1.0040e+00],
        [1.0046e+00],
        [1.0047e+00],
        [1.0047e+00],
        [1.0051e+00],
        [1.0053e+00],
        [1.0053e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([-1.4023e-02,  4.3458e-02,  3.7555e-03,  3.0263e-02, -6.5150e-03,
         3.6990e-02,  2.6598e-03, -9.8441e-03, -2.2577e-03, -1.5939e-03,
        -2.2540e-03, -2.4247e-03,  6.8245e-03,  1.2555e-04, -8.7512e-03,
        -5.3056e-03, -1.4206e-04, -1.1041e-02,  4.3873e-04, -8.7170e-03,
        -5.2629e-03, -1.6799e-02, -1.2789e-02, -3.8228e-03, -2.0489e-02,
        -8.8875e-03, -1.3522e-02, -1.5904e-02, -7.7465e-03, -2.3211e-02,
        -3.0481e-03, -3.0216e-02, -2.9448e-02, -7.1247e-03, -3.6304e-02,
        -3.7125e-03, -3.1503e-02, -1.1755e-03, -9.5560e-03, -3.9648e-02,
        -7.8614e-03, -1.7497e-02, -7.1822e-03, -1.7140e-02,  6.4978e-03,
        -1.9536e-03, -2.1114e-02, -3.6623e-03, -1.0882e-02,  7.3972e-03,
        -8.8794e-03,  4.2045e-03, -3.4324e-03,  1.2809e-02,  3.5709e-03,
        -1.3374e-03, -1.7628e-04, -1.0162e-03,  6.2137e-03,  1.2555e-04,
         1.2993e-02,  2.6202e-03, -6.1406e-04,  9.2357e-03, -1.5932e-03,
         1.4716e-02,  4.1034e-03,  1.9261e-02,  9.4081e-03, -2.7731e-03,
         1.3682e-02,  2.1636e-03,  1.6968e-02,  5.9310e-03,  1.9301e-02,
         8.5298e-03,  2.0763e-02,  1.0035e-02, -3.6145e-03,  1.0367e-02,
         1.5892e-02,  3.2640e-03,  2.4370e-03,  7.9930e-03,  6.6568e-03,
         1.1253e-02,  9.5116e-03,  7.5283e-03,  1.1330e-02, -3.7822e-03,
         4.2789e-04, -2.6380e-03,  1.1181e-03, -2.0207e-03,  1.2080e-03,
         4.3720e-03,  8.7169e-04, -5.3229e-04, -6.5525e-05,  5.4862e-05,
         3.1868e-04,  5.0348e-04,  5.8165e-04,  5.9515e-04,  5.9463e-04,
         6.2206e-04,  5.7666e-04,  5.2240e-04,  4.1878e-04,  2.7405e-04,
         1.1654e-03,  3.5794e-03, -1.2383e-04, -3.5239e-04, -5.6436e-04,
         1.2466e-03,  3.4542e-03,  5.5396e-03,  7.4540e-03,  9.2231e-03,
         6.1825e-03,  7.8254e-03,  9.3210e-03,  1.0620e-02,  1.6551e-02,
         1.7387e-02,  1.8063e-02,  2.2633e-02,  1.5249e-02,  1.5418e-02,
         1.9703e-02,  1.9403e-02,  2.2874e-02,  2.2137e-02,  2.4930e-02,
         1.6694e-02,  1.9458e-02,  1.7607e-02,  1.9827e-02,  2.1720e-02,
         1.9280e-02,  2.0784e-02,  2.2085e-02,  1.1209e-02,  1.2457e-02,
         1.3549e-02,  1.4462e-02,  1.5252e-02,  1.0893e-02,  1.1541e-02,
         1.2120e-02,  3.3362e-03,  3.8647e-03,  4.3043e-03,  4.7118e-03,
         5.0741e-03,  5.4222e-03,  5.7128e-03,  6.0017e-03,  5.6135e-04,
         6.0048e-04,  2.9916e-03,  3.2211e-03,  3.4897e-03,  3.7234e-03,
         3.9237e-03,  5.9171e-04,  5.7786e-04,  6.6497e-04,  7.1667e-03,
         7.3877e-03,  7.5810e-03,  1.3261e-02,  1.3413e-02,  1.0362e-02,
         1.0565e-02,  1.0742e-02,  1.5999e-02,  2.0650e-02,  2.0753e-02,
         2.4824e-02,  2.4914e-02,  2.2707e-02,  2.6546e-02,  2.6629e-02,
         2.9949e-02,  3.2894e-02,  3.2940e-02,  3.5506e-02,  3.7752e-02,
         3.6488e-02,  3.8622e-02,  4.0478e-02,  4.0509e-02,  4.2143e-02,
         4.3580e-02,  4.4851e-02,  4.4091e-02,  4.5280e-02,  4.6333e-02,
         4.7254e-02,  4.8067e-02,  4.8778e-02,  4.9702e-02,  5.0214e-02,
         5.0114e-02,  5.0568e-02,  5.0961e-02,  5.1483e-02,  5.1760e-02,
         5.2134e-02,  5.2441e-02,  5.2593e-02,  5.2513e-02,  5.2730e-02,
         5.2903e-02,  5.2978e-02,  5.3094e-02,  5.3182e-02,  5.3248e-02,
         5.3295e-02,  5.3224e-02,  5.3255e-02,  5.3297e-02,  5.3300e-02,
         5.3293e-02,  5.3278e-02,  5.3269e-02,  5.3201e-02,  5.3172e-02,
         5.3148e-02,  5.3109e-02,  5.3073e-02,  5.3034e-02,  5.2985e-02,
         5.2938e-02,  5.2876e-02,  5.2826e-02,  5.2774e-02,  5.2718e-02,
         5.2663e-02,  5.2607e-02,  5.2549e-02,  5.2492e-02,  5.2429e-02,
         5.2369e-02,  5.2309e-02,  5.2249e-02,  5.2188e-02,  5.2127e-02,
         5.2065e-02,  5.2004e-02,  5.1940e-02,  5.1879e-02,  5.1817e-02,
         5.1754e-02,  5.1693e-02,  5.1630e-02,  5.1568e-02,  5.1505e-02,
         5.1443e-02,  5.1380e-02,  5.1318e-02,  5.1256e-02,  5.1194e-02,
         5.1131e-02,  5.1069e-02,  5.1007e-02,  5.0945e-02,  5.0883e-02,
         5.0822e-02,  5.0760e-02,  5.0698e-02,  5.0637e-02,  5.0575e-02,
         5.0514e-02,  5.0453e-02,  5.0392e-02,  5.0331e-02,  5.0269e-02,
         5.0209e-02,  5.0148e-02,  5.0087e-02,  5.0027e-02,  4.9966e-02,
         4.9906e-02,  4.9846e-02,  4.9786e-02,  4.9726e-02,  4.9666e-02,
         4.9606e-02,  4.9546e-02,  4.9487e-02,  4.9427e-02,  4.9368e-02,
         4.9309e-02,  4.9250e-02,  4.9190e-02,  4.9131e-02,  4.9073e-02,
         4.9014e-02,  4.8955e-02,  4.8897e-02,  4.8838e-02,  4.8780e-02,
         4.8721e-02,  4.8663e-02,  4.8606e-02,  4.8548e-02,  4.8490e-02,
         4.8432e-02,  4.8374e-02,  4.8317e-02,  4.8259e-02,  4.8202e-02,
         4.8145e-02,  4.8088e-02,  4.8031e-02,  4.7974e-02,  4.7917e-02,
         4.7860e-02,  4.7804e-02,  4.7747e-02,  4.7691e-02,  4.7634e-02,
         4.7578e-02,  4.7522e-02,  4.7466e-02,  4.7410e-02,  4.7354e-02,
         4.7298e-02,  4.7243e-02,  4.7187e-02,  4.7132e-02,  4.7077e-02,
         4.7021e-02,  4.6966e-02,  4.6911e-02,  4.6856e-02,  4.6801e-02,
         4.6746e-02,  4.6692e-02,  4.6637e-02,  4.6583e-02,  4.6528e-02,
         4.6474e-02,  4.6419e-02,  4.6365e-02,  4.6311e-02,  4.6257e-02,
         4.6204e-02,  4.6150e-02,  4.6096e-02,  4.6043e-02,  4.5989e-02,
         4.5936e-02,  4.5882e-02,  4.5829e-02,  4.5776e-02,  4.5723e-02,
         4.5670e-02,  4.5617e-02,  4.5565e-02,  4.5512e-02,  4.5459e-02,
         4.5407e-02,  4.5354e-02,  4.5302e-02,  4.5250e-02,  4.5198e-02,
         4.5146e-02,  4.5094e-02,  4.5042e-02,  4.4990e-02,  4.4938e-02,
         4.4887e-02,  4.4835e-02,  4.4784e-02,  4.4732e-02,  4.4681e-02,
         4.4630e-02,  4.4579e-02,  4.4528e-02,  4.4477e-02,  4.4426e-02,
         4.4375e-02,  4.4325e-02,  4.4274e-02,  4.4224e-02,  4.4173e-02,
         4.4123e-02,  4.4073e-02,  4.4023e-02,  4.3973e-02,  4.3923e-02,
         4.3873e-02,  4.3823e-02,  4.3773e-02,  4.3724e-02,  4.3674e-02,
         4.3625e-02,  4.3575e-02,  4.3526e-02,  4.3477e-02,  4.3427e-02,
         4.3378e-02,  4.3329e-02,  4.3281e-02,  4.3232e-02,  4.3183e-02,
         4.3134e-02,  4.3086e-02,  4.3037e-02,  4.2989e-02,  4.2941e-02,
         4.2892e-02,  4.2844e-02,  4.2796e-02,  4.2748e-02,  4.2700e-02,
         4.2652e-02,  4.2604e-02,  4.2557e-02,  4.2509e-02,  4.2462e-02,
         4.2414e-02,  4.2367e-02,  4.2319e-02,  4.2272e-02,  4.2225e-02,
         4.2178e-02,  4.2131e-02,  4.2084e-02,  4.2037e-02,  4.1991e-02,
         4.1944e-02,  4.1897e-02,  4.1851e-02,  4.1804e-02,  4.1758e-02,
         4.1711e-02,  4.1665e-02,  4.1619e-02,  4.1573e-02,  4.1527e-02,
         4.1481e-02,  4.1435e-02,  4.1390e-02,  4.1344e-02,  4.1298e-02,
         4.1252e-02,  4.1207e-02,  4.1161e-02,  4.1116e-02,  4.1071e-02,
         4.1026e-02,  4.0980e-02,  4.0935e-02,  4.0890e-02,  4.0845e-02,
         4.0800e-02,  4.0755e-02,  4.0710e-02,  4.0665e-02,  4.0620e-02,
         4.0575e-02,  4.0531e-02,  4.0486e-02,  4.0441e-02,  4.0396e-02,
         4.0351e-02,  4.0306e-02,  4.0261e-02,  4.0215e-02,  4.0170e-02,
         4.0124e-02,  4.0079e-02,  4.0032e-02,  3.9986e-02,  3.9939e-02,
         3.9892e-02,  3.9845e-02,  3.9797e-02,  3.9748e-02,  3.9699e-02,
         3.9648e-02,  3.9597e-02,  3.9545e-02,  3.9492e-02,  3.9437e-02,
         3.9382e-02,  3.9324e-02,  3.9265e-02,  3.9203e-02,  3.9140e-02,
         3.9074e-02,  3.9005e-02,  3.8934e-02,  3.8859e-02,  3.8780e-02,
         3.6674e-02,  3.6460e-02,  3.6232e-02,  3.5989e-02,  3.5731e-02,
         3.5457e-02,  3.5165e-02,  3.4857e-02,  3.4528e-02,  3.4186e-02,
         3.3820e-02,  3.3424e-02,  3.3014e-02,  3.2585e-02,  3.2130e-02,
         3.1653e-02,  3.1149e-02,  3.0646e-02,  3.0099e-02,  2.9528e-02,
         2.8933e-02,  2.8315e-02,  2.7674e-02,  2.7005e-02,  2.6316e-02,
         2.5605e-02,  2.4874e-02,  2.4120e-02,  2.3352e-02,  2.2562e-02,
         2.1760e-02,  2.0938e-02,  2.0114e-02,  1.9271e-02,  1.8427e-02,
         1.7566e-02,  1.6716e-02,  1.5849e-02,  1.5039e-02,  1.4112e-02,
         1.3340e-02,  1.2444e-02,  1.1675e-02,  1.0775e-02,  1.0062e-02,
         9.1743e-03,  8.4665e-03,  7.6433e-03,  7.0207e-03,  6.2183e-03,
         5.6881e-03,  4.9712e-03,  4.4166e-03,  3.7918e-03,  3.3489e-03,
         2.7645e-03,  2.3680e-03,  1.9015e-03,  1.6209e-03,  1.1986e-03,
         1.0392e-03,  6.8329e-04,  5.1741e-04,  2.8179e-04,  3.5987e-04,
         3.2831e-04,  2.1850e-04,  4.2170e-04,  3.1198e-04,  6.4021e-04,
         6.5534e-04,  9.8408e-04,  1.1168e-03,  1.5564e-03,  1.8075e-03,
         2.2483e-03,  2.6116e-03,  3.1506e-03,  3.6193e-03,  4.1456e-03,
         4.7137e-03,  5.3322e-03,  5.8799e-03,  6.6831e-03,  7.2101e-03,
         7.9855e-03,  8.6760e-03,  9.5081e-03,  1.0169e-02,  1.0957e-02,
         1.1758e-02,  1.2365e-02,  1.3375e-02,  1.4099e-02,  1.4798e-02,
         1.5621e-02,  1.6488e-02,  1.7243e-02,  1.7969e-02,  1.8851e-02,
         1.9509e-02,  2.0248e-02,  2.0949e-02,  2.1773e-02,  2.2395e-02,
         2.2987e-02,  2.3548e-02,  2.4284e-02,  2.4851e-02,  2.5383e-02,
         2.5881e-02,  2.6445e-02,  2.6935e-02,  2.7336e-02,  2.7762e-02,
         2.8230e-02,  2.8636e-02,  2.8968e-02,  2.9313e-02,  2.9683e-02,
         2.9970e-02,  3.0232e-02,  3.0473e-02,  3.0756e-02,  3.0975e-02,
         3.1173e-02,  3.1352e-02,  3.1540e-02,  3.1699e-02,  3.1827e-02,
         3.1975e-02,  3.2086e-02,  3.2185e-02,  3.2282e-02,  3.2379e-02,
         3.2451e-02,  3.2513e-02,  3.2565e-02,  3.2619e-02,  3.2655e-02,
         3.2694e-02,  3.2716e-02,  3.2747e-02,  3.2758e-02,  3.2772e-02,
         3.2780e-02,  3.2787e-02,  3.2787e-02,  3.2783e-02,  3.2775e-02,
         3.2768e-02,  3.2758e-02,  3.2743e-02,  3.2728e-02,  3.2710e-02,
         3.2692e-02,  3.2671e-02,  3.2649e-02,  3.2627e-02,  3.2603e-02,
         3.2578e-02,  3.2553e-02,  3.2526e-02,  3.2499e-02,  3.2471e-02,
         3.2443e-02,  3.2415e-02,  3.2386e-02,  3.2356e-02,  3.2327e-02,
         3.2297e-02,  3.2267e-02,  3.2237e-02,  3.2206e-02,  3.2176e-02,
         3.2145e-02,  3.2115e-02,  3.2084e-02,  3.2053e-02,  3.2022e-02,
         3.1992e-02,  3.1960e-02,  3.1930e-02,  3.1899e-02,  3.1868e-02,
         3.1837e-02,  3.1806e-02,  3.1776e-02,  3.1745e-02,  3.1714e-02,
         3.1683e-02,  3.1653e-02,  3.1622e-02,  3.1591e-02,  3.1561e-02,
         3.1530e-02,  3.1500e-02,  3.1469e-02,  3.1439e-02,  3.1408e-02,
         3.1378e-02,  3.1347e-02,  3.1317e-02,  3.1287e-02,  3.1257e-02,
         3.1227e-02,  3.1197e-02,  3.1166e-02,  3.1137e-02,  3.1107e-02,
         3.1077e-02,  3.1047e-02,  3.1017e-02,  3.0987e-02,  3.0957e-02,
         3.0928e-02,  3.0898e-02,  3.0869e-02,  3.0839e-02,  3.0810e-02,
         3.0780e-02,  3.0751e-02,  3.0722e-02,  3.0693e-02,  3.0663e-02,
         3.0634e-02,  3.0606e-02,  3.0577e-02,  3.0548e-02,  3.0519e-02,
         3.0491e-02,  3.0463e-02,  3.0435e-02,  3.0406e-02,  3.0378e-02,
         3.0351e-02,  3.0323e-02,  3.0296e-02,  3.0270e-02,  3.0243e-02,
         3.0217e-02,  3.0189e-02,  3.0165e-02,  3.0140e-02,  3.0116e-02,
         3.0093e-02,  3.0069e-02,  3.0047e-02,  3.0027e-02,  3.0001e-02,
         2.9982e-02,  2.9962e-02,  2.9946e-02,  2.9932e-02,  2.9917e-02,
         2.9907e-02,  2.9895e-02,  2.9869e-02,  2.9865e-02,  2.9859e-02,
         2.9855e-02,  2.9854e-02,  2.9865e-02,  2.9872e-02,  2.9848e-02,
         2.9859e-02,  2.9875e-02,  2.9896e-02,  2.9923e-02,  2.9939e-02,
         2.9976e-02,  3.0020e-02,  3.0000e-02,  3.0031e-02,  3.0090e-02,
         3.0158e-02,  3.0206e-02,  3.0290e-02,  3.0350e-02,  3.0416e-02,
         3.0401e-02,  3.0473e-02,  3.0589e-02,  3.0672e-02,  3.0760e-02,
         3.0850e-02,  3.0942e-02,  3.1035e-02,  3.0979e-02,  3.1070e-02,
         3.1156e-02,  3.1234e-02,  3.1232e-02,  3.1292e-02,  3.1331e-02,
         3.1289e-02,  3.1302e-02,  3.1281e-02,  3.1242e-02,  3.1150e-02,
         3.0975e-02,  3.0890e-02,  3.0579e-02,  3.0618e-02,  3.0497e-02,
         3.0028e-02,  2.9845e-02,  2.9114e-02,  2.8111e-02,  2.7736e-02,
         2.7345e-02,  2.7605e-02,  2.7189e-02,  2.5528e-02,  2.4936e-02,
         2.4316e-02,  2.1637e-02,  2.0726e-02,  1.9734e-02,  2.0445e-02,
         1.9443e-02,  1.8333e-02,  1.7144e-02,  1.5851e-02,  1.0205e-02,
         8.2746e-03,  1.4057e-02,  1.2508e-02,  1.0802e-02,  8.9692e-03,
         6.9261e-03,  4.7274e-03,  2.3324e-03,  6.5654e-04,  7.6534e-03,
         5.5405e-03,  3.2144e-03,  6.8198e-03,  4.6369e-03,  2.2336e-03,
         6.5052e-04,  6.4966e-04,  1.0537e-02,  8.6834e-03,  6.7148e-03,
         9.7761e-03,  7.9067e-03,  5.8490e-03,  9.0474e-03,  7.0935e-03,
         1.6458e-02,  1.5196e-02,  1.7129e-02,  1.5911e-02,  1.7756e-02,
         1.6597e-02,  1.8341e-02,  2.3094e-02,  2.2423e-02,  2.3410e-02,
         2.4255e-02,  2.3688e-02,  2.4494e-02,  2.5191e-02,  2.5790e-02,
         2.6834e-02,  2.7204e-02,  2.7529e-02,  2.7800e-02,  2.8032e-02,
         2.8220e-02,  2.8379e-02,  2.8506e-02,  2.8855e-02,  2.8882e-02,
         2.8898e-02,  2.8899e-02,  2.8890e-02,  2.8871e-02,  2.8843e-02,
         2.8809e-02,  2.8705e-02,  2.8591e-02,  2.8526e-02,  2.8460e-02,
         2.8392e-02,  2.8252e-02,  2.8181e-02,  2.7988e-02,  2.7847e-02,
         2.7778e-02,  2.7710e-02,  2.7575e-02,  2.7510e-02,  2.7383e-02,
         2.7321e-02,  2.7114e-02,  2.7058e-02,  2.6955e-02,  2.6859e-02,
         2.6809e-02,  2.6720e-02,  2.6673e-02,  2.6592e-02,  2.6466e-02,
         2.6426e-02,  2.6404e-02,  2.6298e-02,  2.6207e-02,  2.6185e-02,
         2.6105e-02,  2.6083e-02,  2.6013e-02,  2.5992e-02,  2.5930e-02,
         2.5908e-02,  2.5854e-02,  2.5806e-02,  2.5784e-02,  2.5740e-02,
         2.5718e-02,  2.5678e-02,  2.5656e-02,  2.5619e-02,  2.5585e-02,
         2.5563e-02,  2.5531e-02,  2.5509e-02,  2.5479e-02,  2.5453e-02,
         2.5425e-02,  2.5399e-02,  2.5377e-02,  2.5351e-02,  2.5329e-02,
         2.5302e-02,  2.5280e-02,  2.5256e-02,  2.5234e-02,  2.5210e-02,
         2.5186e-02,  2.5165e-02,  2.5142e-02,  2.5119e-02,  2.5097e-02,
         2.5075e-02,  2.5053e-02,  2.5030e-02,  2.5009e-02,  2.4986e-02,
         2.4965e-02,  2.4943e-02,  2.4921e-02,  2.4900e-02,  2.4878e-02,
         2.4856e-02,  2.4835e-02,  2.4813e-02,  2.4792e-02,  2.4770e-02,
         2.4749e-02,  2.4728e-02,  2.4706e-02,  2.4685e-02,  2.4664e-02,
         2.4642e-02,  2.4621e-02,  2.4600e-02,  2.4579e-02,  2.4558e-02,
         2.4537e-02,  2.4516e-02,  2.4495e-02,  2.4474e-02,  2.4453e-02,
         2.4432e-02,  2.4411e-02,  2.4390e-02,  2.4369e-02,  2.4348e-02,
         2.4327e-02,  2.4307e-02,  2.4286e-02,  2.4265e-02,  2.4244e-02],
       device='cuda:0')
Selected points (indices): {224}
Selected new x values (normalized): tensor([0.2242], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-1103.1030], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter4/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:34:48 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_4 [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		M_1: [-1103.1]               [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:34:48 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:34:49 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_4, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:34:49 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:34:49 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_4/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 4
Starting iteration 5
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.1041, 0.5812, 0.8528],
       device='cuda:0') torch.Size([8])
These training_points are used in the GP tensor([0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.1041, 0.5812, 0.8528],
       device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[9.0882e-03],
        [1.8540e-01],
        [9.8903e-03],
        [1.0000e-06],
        [6.8032e-03],
        [6.0986e-03],
        [1.0036e-01],
        [1.0597e-02],
        [1.0000e-06],
        [9.7324e-02],
        [1.0000e-06],
        [1.0000e-06],
        [7.1259e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.8979e-02],
        [1.0000e-06],
        [2.7644e-01],
        [1.0000e-06],
        [1.0000e-06],
        [2.0120e-01],
        [8.0666e-02],
        [1.0000e-06],
        [9.7024e-02],
        [1.0000e-06],
        [3.0265e-01],
        [1.0000e-06],
        [1.0000e-06],
        [1.8116e-01],
        [4.1312e-02],
        [1.0000e-06],
        [2.3598e-01],
        [9.9626e-02],
        [1.0000e-06],
        [6.1501e-02],
        [1.0000e-06],
        [2.2957e-01],
        [8.0783e-02],
        [1.0000e-06],
        [2.3066e-01],
        [7.4702e-02],
        [1.0000e-06],
        [2.0952e-01],
        [4.1385e-02],
        [1.0000e-06],
        [1.6388e-01],
        [1.0000e-06],
        [2.6029e-01],
        [9.0538e-02],
        [1.0000e-06],
        [1.8030e-01],
        [1.0000e-06],
        [1.0000e-06],
        [7.0423e-02],
        [9.9862e-02],
        [3.3139e-01],
        [1.6400e-01],
        [7.6856e-03],
        [2.1687e-01],
        [1.6549e-02],
        [3.8551e-02],
        [2.7583e-01],
        [8.6561e-02],
        [1.0000e-06],
        [1.2537e-01],
        [1.3843e-01],
        [3.4350e-01],
        [1.6490e-01],
        [2.7237e-01],
        [7.0995e-02],
        [1.8619e-01],
        [1.8883e-01],
        [2.8457e-01],
        [1.8603e-01],
        [1.7979e-01],
        [2.6802e-01],
        [3.4370e-01],
        [2.4267e-01],
        [2.2260e-01],
        [2.9264e-01],
        [1.7390e-01],
        [2.4073e-01],
        [2.9826e-01],
        [2.6026e-01],
        [1.2146e-01],
        [1.7557e-01],
        [2.2247e-01],
        [2.6323e-01],
        [1.1194e-01],
        [1.5190e-01],
        [1.8698e-01],
        [2.1790e-01],
        [4.6873e-02],
        [7.8149e-02],
        [1.0615e-01],
        [3.4051e-02],
        [5.9811e-02],
        [8.3292e-02],
        [1.0484e-01],
        [1.1342e-03],
        [4.8566e-02],
        [6.7947e-02],
        [8.6155e-02],
        [1.0870e-02],
        [2.2921e-02],
        [4.0228e-02],
        [5.6728e-02],
        [9.2049e-03],
        [7.2717e-03],
        [1.2148e-01],
        [1.3497e-01],
        [5.4785e-02],
        [6.8333e-02],
        [1.8972e-01],
        [1.0000e-06],
        [1.2398e-01],
        [1.3371e-01],
        [2.4372e-01],
        [1.6930e-01],
        [1.7512e-01],
        [2.7637e-01],
        [3.6378e-01],
        [2.0192e-01],
        [2.9456e-01],
        [3.7429e-01],
        [4.4282e-01],
        [3.7652e-01],
        [3.6465e-01],
        [4.2614e-01],
        [3.4984e-01],
        [4.0607e-01],
        [4.5371e-01],
        [4.9390e-01],
        [4.1409e-01],
        [4.4969e-01],
        [4.7914e-01],
        [5.0325e-01],
        [4.1142e-01],
        [4.3118e-01],
        [4.4651e-01],
        [4.5799e-01],
        [3.4493e-01],
        [3.5193e-01],
        [4.3207e-01],
        [4.3289e-01],
        [3.0490e-01],
        [3.0130e-01],
        [3.7902e-01],
        [2.3382e-01],
        [2.2411e-01],
        [3.0593e-01],
        [2.9458e-01],
        [1.2497e-01],
        [2.1401e-01],
        [1.9846e-01],
        [2.7871e-01],
        [1.0272e-01],
        [8.3103e-02],
        [1.7340e-01],
        [2.5453e-01],
        [7.1311e-02],
        [1.6185e-01],
        [1.4186e-01],
        [2.2509e-01],
        [3.3801e-02],
        [1.2699e-01],
        [2.1101e-01],
        [1.3192e-01],
        [1.0964e-01],
        [1.9442e-01],
        [2.7078e-01],
        [1.9642e-01],
        [1.7394e-01],
        [2.5062e-01],
        [3.1950e-01],
        [2.4778e-01],
        [3.1519e-01],
        [3.7548e-01],
        [4.2929e-01],
        [3.6521e-01],
        [4.1706e-01],
        [4.6291e-01],
        [3.9803e-01],
        [4.4122e-01],
        [4.7874e-01],
        [5.1103e-01],
        [4.4300e-01],
        [4.7132e-01],
        [4.9450e-01],
        [5.7078e-01],
        [4.9955e-01],
        [5.1036e-01],
        [5.1672e-01],
        [5.7603e-01],
        [4.9243e-01],
        [5.1825e-01],
        [5.0896e-01],
        [5.2660e-01],
        [4.5538e-01],
        [4.6851e-01],
        [4.4426e-01],
        [3.5236e-01],
        [3.5854e-01],
        [3.6204e-01],
        [3.6326e-01],
        [2.4936e-01],
        [2.4690e-01],
        [2.8894e-01],
        [2.8360e-01],
        [1.5011e-01],
        [1.4142e-01],
        [1.8458e-01],
        [1.7448e-01],
        [7.7488e-02],
        [6.4830e-02],
        [1.0929e-01],
        [7.6829e-03],
        [9.2346e-03],
        [1.0038e-02],
        [2.0448e-02],
        [1.0884e-02],
        [1.1306e-02],
        [1.1471e-02],
        [1.1552e-02],
        [1.1552e-02],
        [1.1492e-02],
        [1.1346e-02],
        [1.1872e-02],
        [1.1112e-02],
        [1.0869e-02],
        [5.2908e-02],
        [9.6015e-02],
        [1.0226e-02],
        [3.3292e-02],
        [1.3355e-01],
        [2.9243e-02],
        [1.2993e-01],
        [1.6957e-01],
        [2.5580e-01],
        [1.6614e-01],
        [2.5274e-01],
        [2.8685e-01],
        [3.6101e-01],
        [3.2768e-01],
        [3.9764e-01],
        [4.2521e-01],
        [4.8511e-01],
        [4.5821e-01],
        [5.1472e-01],
        [5.6540e-01],
        [5.4265e-01],
        [5.9045e-01],
        [6.3332e-01],
        [6.9201e-01],
        [6.7581e-01],
        [7.0987e-01],
        [7.4042e-01],
        [7.8223e-01],
        [7.7069e-01],
        [8.0774e-01],
        [8.2819e-01],
        [8.5617e-01],
        [8.4845e-01],
        [8.7325e-01],
        [8.9413e-01],
        [9.0566e-01],
        [9.0688e-01],
        [9.2246e-01],
        [9.3560e-01],
        [9.3645e-01],
        [9.4361e-01],
        [9.5341e-01],
        [9.6166e-01],
        [9.6220e-01],
        [9.7129e-01],
        [9.7673e-01],
        [9.8131e-01],
        [9.8161e-01],
        [9.8542e-01],
        [9.8967e-01],
        [9.9221e-01],
        [9.9319e-01],
        [9.9518e-01],
        [9.9685e-01],
        [9.9813e-01],
        [9.9902e-01],
        [1.0003e+00],
        [1.0011e+00],
        [1.0019e+00],
        [1.0025e+00],
        [1.0031e+00],
        [1.0035e+00],
        [1.0040e+00],
        [1.0042e+00],
        [1.0045e+00],
        [1.0047e+00],
        [1.0049e+00],
        [1.0051e+00],
        [1.0052e+00],
        [1.0053e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0054e+00],
        [1.0053e+00],
        [1.0052e+00],
        [1.0051e+00],
        [1.0049e+00],
        [1.0047e+00],
        [1.0045e+00],
        [1.0042e+00],
        [1.0039e+00],
        [1.0035e+00],
        [1.0031e+00],
        [1.0025e+00],
        [1.0019e+00],
        [1.0012e+00],
        [1.0003e+00],
        [9.9934e-01],
        [9.9819e-01],
        [9.9684e-01],
        [9.9529e-01],
        [9.9354e-01],
        [9.9150e-01],
        [9.8915e-01],
        [9.8648e-01],
        [9.8343e-01],
        [9.8000e-01],
        [9.7628e-01],
        [9.7192e-01],
        [9.6698e-01],
        [9.6151e-01],
        [9.5536e-01],
        [9.4853e-01],
        [9.4095e-01],
        [9.3260e-01],
        [9.2340e-01],
        [9.1369e-01],
        [9.0263e-01],
        [8.9069e-01],
        [8.7761e-01],
        [8.6333e-01],
        [8.4808e-01],
        [8.3154e-01],
        [8.1364e-01],
        [7.9595e-01],
        [7.7575e-01],
        [7.5458e-01],
        [7.3199e-01],
        [7.0854e-01],
        [6.8371e-01],
        [6.5749e-01],
        [6.3280e-01],
        [6.0400e-01],
        [5.7635e-01],
        [5.4500e-01],
        [5.1521e-01],
        [4.8350e-01],
        [4.5406e-01],
        [4.2068e-01],
        [3.9011e-01],
        [3.5794e-01],
        [3.2675e-01],
        [2.9406e-01],
        [2.6560e-01],
        [2.3299e-01],
        [2.0523e-01],
        [1.8613e-01],
        [1.6328e-01],
        [1.3641e-01],
        [1.1567e-01],
        [9.4428e-02],
        [7.6319e-02],
        [5.7849e-02],
        [4.2781e-02],
        [3.1288e-02],
        [2.7333e-02],
        [1.5655e-02],
        [1.1636e-02],
        [1.5368e-02],
        [1.1552e-02],
        [1.5081e-02],
        [2.6481e-02],
        [3.7750e-02],
        [6.0045e-02],
        [7.0928e-02],
        [8.8877e-02],
        [1.0648e-01],
        [1.3061e-01],
        [1.5409e-01],
        [1.7695e-01],
        [2.0546e-01],
        [2.3300e-01],
        [2.5959e-01],
        [2.8526e-01],
        [3.1547e-01],
        [3.4955e-01],
        [3.7706e-01],
        [4.1276e-01],
        [4.4204e-01],
        [4.7404e-01],
        [5.1008e-01],
        [5.3822e-01],
        [5.6820e-01],
        [5.9626e-01],
        [6.2550e-01],
        [6.4568e-01],
        [6.7529e-01],
        [7.0008e-01],
        [7.2522e-01],
        [7.5228e-01],
        [7.6760e-01],
        [7.9058e-01],
        [8.0981e-01],
        [8.2871e-01],
        [8.4199e-01],
        [8.6009e-01],
        [8.7310e-01],
        [8.8776e-01],
        [8.9831e-01],
        [9.1166e-01],
        [9.2007e-01],
        [9.3072e-01],
        [9.3849e-01],
        [9.4685e-01],
        [9.5295e-01],
        [9.5952e-01],
        [9.6590e-01],
        [9.7058e-01],
        [9.7543e-01],
        [9.7900e-01],
        [9.8269e-01],
        [9.8572e-01],
        [9.8848e-01],
        [9.9075e-01],
        [9.9303e-01],
        [9.9470e-01],
        [9.9652e-01],
        [9.9774e-01],
        [9.9906e-01],
        [1.0000e+00],
        [1.0010e+00],
        [1.0017e+00],
        [1.0024e+00],
        [1.0030e+00],
        [1.0034e+00],
        [1.0038e+00],
        [1.0041e+00],
        [1.0044e+00],
        [1.0047e+00],
        [1.0049e+00],
        [1.0050e+00],
        [1.0052e+00],
        [1.0053e+00],
        [1.0054e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0054e+00],
        [1.0053e+00],
        [1.0052e+00],
        [1.0050e+00],
        [1.0050e+00],
        [1.0047e+00],
        [1.0045e+00],
        [1.0041e+00],
        [1.0041e+00],
        [1.0036e+00],
        [1.0031e+00],
        [1.0029e+00],
        [1.0022e+00],
        [1.0011e+00],
        [1.0001e+00],
        [1.0001e+00],
        [9.9876e-01],
        [9.9659e-01],
        [9.9449e-01],
        [9.9446e-01],
        [9.9186e-01],
        [9.8868e-01],
        [9.8476e-01],
        [9.8470e-01],
        [9.8145e-01],
        [9.7587e-01],
        [9.7580e-01],
        [9.6893e-01],
        [9.6324e-01],
        [9.5349e-01],
        [9.5654e-01],
        [9.4136e-01],
        [9.3140e-01],
        [9.1991e-01],
        [9.2491e-01],
        [8.9999e-01],
        [8.8364e-01],
        [8.6476e-01],
        [8.7298e-01],
        [8.5246e-01],
        [8.2877e-01],
        [8.0142e-01],
        [8.1333e-01],
        [7.8360e-01],
        [7.4926e-01],
        [7.6422e-01],
        [7.2689e-01],
        [6.8380e-01],
        [6.3405e-01],
        [6.5571e-01],
        [6.0162e-01],
        [5.3918e-01],
        [5.3038e-01],
        [5.5809e-01],
        [4.8892e-01],
        [4.0905e-01],
        [3.9780e-01],
        [4.3324e-01],
        [3.4478e-01],
        [2.4264e-01],
        [3.7157e-01],
        [2.7358e-01],
        [2.5978e-01],
        [1.4451e-01],
        [2.9002e-01],
        [1.7942e-01],
        [5.1740e-02],
        [3.3754e-02],
        [1.9797e-01],
        [7.3158e-02],
        [5.5575e-02],
        [1.1552e-02],
        [9.4095e-02],
        [7.6907e-02],
        [1.1552e-02],
        [1.1552e-02],
        [9.7760e-02],
        [1.1552e-02],
        [1.1552e-02],
        [1.1814e-01],
        [1.0141e-01],
        [1.1552e-02],
        [1.1552e-02],
        [1.2171e-01],
        [1.0505e-01],
        [8.8065e-02],
        [7.0764e-02],
        [2.2873e-01],
        [2.1408e-01],
        [1.9916e-01],
        [1.8395e-01],
        [3.2280e-01],
        [3.0992e-01],
        [2.9680e-01],
        [4.1658e-01],
        [4.0547e-01],
        [3.9416e-01],
        [4.5585e-01],
        [5.4876e-01],
        [5.4014e-01],
        [5.3136e-01],
        [5.2242e-01],
        [6.5129e-01],
        [6.4460e-01],
        [6.3779e-01],
        [6.7491e-01],
        [7.3081e-01],
        [7.2563e-01],
        [7.5389e-01],
        [7.4914e-01],
        [8.1756e-01],
        [8.1401e-01],
        [8.3336e-01],
        [8.6249e-01],
        [8.7694e-01],
        [8.7451e-01],
        [8.8776e-01],
        [9.0770e-01],
        [9.1759e-01],
        [9.2649e-01],
        [9.2499e-01],
        [9.4653e-01],
        [9.5251e-01],
        [9.5789e-01],
        [9.5698e-01],
        [9.7000e-01],
        [9.7361e-01],
        [9.7685e-01],
        [9.7977e-01],
        [9.8417e-01],
        [9.8635e-01],
        [9.8831e-01],
        [9.9297e-01],
        [9.9426e-01],
        [9.9543e-01],
        [9.9647e-01],
        [9.9896e-01],
        [9.9965e-01],
        [1.0003e+00],
        [1.0008e+00],
        [1.0021e+00],
        [1.0029e+00],
        [1.0032e+00],
        [1.0035e+00],
        [1.0041e+00],
        [1.0043e+00],
        [1.0046e+00],
        [1.0049e+00],
        [1.0050e+00],
        [1.0051e+00],
        [1.0052e+00],
        [1.0054e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([ 2.2893e-03,  4.7157e-02,  2.5802e-03, -7.6283e-04,  1.9044e-03,
         1.4332e-03,  2.3424e-02,  2.5631e-03, -4.0418e-03,  1.9978e-02,
        -1.4185e-03, -9.0406e-03,  1.2817e-02, -9.0116e-03, -1.0121e-02,
         3.0333e-03, -8.9802e-03,  3.4683e-02, -8.2853e-04, -1.1705e-02,
         2.3186e-02,  9.4106e-03, -1.9135e-02,  1.0314e-02, -1.4846e-03,
         2.7998e-02, -4.2823e-03, -5.9260e-03,  1.5741e-02,  3.5977e-03,
        -1.0808e-02,  1.8712e-02,  7.8583e-03, -2.1101e-02,  4.6095e-03,
        -8.4984e-03,  1.6349e-02,  5.7288e-03, -6.9392e-03,  1.5679e-02,
         5.0798e-03, -7.7248e-03,  1.3747e-02,  2.6619e-03, -1.0684e-02,
         1.0445e-02, -1.4010e-03,  1.6436e-02,  5.6957e-03, -5.0118e-03,
         1.1223e-02, -9.2028e-04, -3.4388e-03,  4.3304e-03,  6.1573e-03,
         2.0454e-02,  1.0071e-02,  4.5059e-04,  1.3333e-02,  1.0076e-03,
         2.3630e-03,  1.6910e-02,  5.2848e-03, -1.0147e-03,  7.6695e-03,
         8.4259e-03,  2.0965e-02,  1.0033e-02,  1.6542e-02,  4.2733e-03,
         1.1219e-02,  1.1346e-02,  1.7103e-02,  1.1105e-02,  1.0683e-02,
         1.5925e-02,  2.0386e-02,  1.4276e-02,  1.3041e-02,  1.7120e-02,
         1.0104e-02,  1.3942e-02,  1.7262e-02,  1.4972e-02,  6.9140e-03,
         9.9707e-03,  1.2620e-02,  1.4890e-02,  6.2756e-03,  8.4935e-03,
         1.0423e-02,  1.2121e-02,  2.5864e-03,  4.2930e-03,  5.8206e-03,
         1.8538e-03,  3.2595e-03,  4.5139e-03,  5.6714e-03,  5.1767e-05,
         2.6058e-03,  3.6367e-03,  4.6135e-03,  5.6840e-04,  1.2322e-03,
         2.1360e-03,  3.0097e-03,  5.0210e-04,  3.7019e-04,  6.3974e-03,
         7.0808e-03,  2.8600e-03,  3.5649e-03,  9.9392e-03, -2.6924e-04,
         6.4403e-03,  6.9230e-03,  1.2697e-02,  8.7347e-03,  9.0250e-03,
         1.4321e-02,  1.8955e-02,  1.0355e-02,  1.5176e-02,  1.9396e-02,
         2.3083e-02,  1.9467e-02,  1.8813e-02,  2.2094e-02,  1.7991e-02,
         2.0989e-02,  2.3568e-02,  2.5769e-02,  2.1430e-02,  2.3400e-02,
         2.5024e-02,  2.6413e-02,  2.1432e-02,  2.2564e-02,  2.3445e-02,
         2.4133e-02,  1.8070e-02,  1.8501e-02,  2.2896e-02,  2.3009e-02,
         1.6121e-02,  1.5969e-02,  2.0229e-02,  1.2408e-02,  1.1933e-02,
         1.6379e-02,  1.5803e-02,  6.6790e-03,  1.1486e-02,  1.0653e-02,
         1.5022e-02,  5.5077e-03,  4.4558e-03,  9.3648e-03,  1.3777e-02,
         3.8502e-03,  8.7388e-03,  7.6675e-03,  1.2193e-02,  1.8182e-03,
         6.8744e-03,  1.1407e-02,  7.1401e-03,  5.9270e-03,  1.0513e-02,
         1.4631e-02,  1.0613e-02,  9.3897e-03,  1.3537e-02,  1.7240e-02,
         1.3343e-02,  1.6969e-02,  2.0222e-02,  2.3127e-02,  1.9632e-02,
         2.2436e-02,  2.4907e-02,  2.1379e-02,  2.3712e-02,  2.5711e-02,
         2.7460e-02,  2.3787e-02,  2.5294e-02,  2.6551e-02,  3.0683e-02,
         2.6836e-02,  2.7437e-02,  2.7795e-02,  3.1024e-02,  2.6512e-02,
         2.7943e-02,  2.7458e-02,  2.8445e-02,  2.4611e-02,  2.5344e-02,
         2.4072e-02,  1.9129e-02,  1.9497e-02,  1.9699e-02,  1.9772e-02,
         1.3630e-02,  1.3501e-02,  1.5784e-02,  1.5522e-02,  8.2397e-03,
         7.7785e-03,  1.0140e-02,  9.5801e-03,  4.2741e-03,  3.5618e-03,
         6.0266e-03,  4.3546e-04,  5.2051e-04,  5.4604e-04,  1.1389e-03,
         5.8775e-04,  6.2275e-04,  6.2997e-04,  6.3917e-04,  6.4244e-04,
         6.3986e-04,  6.2963e-04,  6.6686e-04,  6.1381e-04,  5.9291e-04,
         2.8835e-03,  5.2360e-03,  5.6806e-04,  1.8062e-03,  7.2314e-03,
         1.5895e-03,  7.0401e-03,  9.1614e-03,  1.3734e-02,  8.9456e-03,
         1.3542e-02,  1.5339e-02,  1.9196e-02,  1.7423e-02,  2.1084e-02,
         2.2486e-02,  2.5571e-02,  2.4139e-02,  2.7027e-02,  2.9606e-02,
         2.8395e-02,  3.0804e-02,  3.2947e-02,  3.5873e-02,  3.5017e-02,
         3.6683e-02,  3.8186e-02,  4.0232e-02,  3.9610e-02,  4.1412e-02,
         4.2386e-02,  4.3727e-02,  4.3288e-02,  4.4474e-02,  4.5455e-02,
         4.5976e-02,  4.5979e-02,  4.6699e-02,  4.7295e-02,  4.7283e-02,
         4.7581e-02,  4.8012e-02,  4.8366e-02,  4.8335e-02,  4.8732e-02,
         4.8947e-02,  4.9119e-02,  4.9075e-02,  4.9208e-02,  4.9365e-02,
         4.9437e-02,  4.9428e-02,  4.9471e-02,  4.9499e-02,  4.9507e-02,
         4.9495e-02,  4.9501e-02,  4.9484e-02,  4.9473e-02,  4.9444e-02,
         4.9419e-02,  4.9382e-02,  4.9351e-02,  4.9307e-02,  4.9268e-02,
         4.9220e-02,  4.9175e-02,  4.9125e-02,  4.9076e-02,  4.9025e-02,
         4.8973e-02,  4.8920e-02,  4.8865e-02,  4.8812e-02,  4.8757e-02,
         4.8703e-02,  4.8647e-02,  4.8592e-02,  4.8537e-02,  4.8481e-02,
         4.8425e-02,  4.8369e-02,  4.8313e-02,  4.8257e-02,  4.8201e-02,
         4.8145e-02,  4.8089e-02,  4.8033e-02,  4.7977e-02,  4.7921e-02,
         4.7865e-02,  4.7810e-02,  4.7754e-02,  4.7698e-02,  4.7642e-02,
         4.7587e-02,  4.7531e-02,  4.7476e-02,  4.7421e-02,  4.7366e-02,
         4.7311e-02,  4.7256e-02,  4.7201e-02,  4.7146e-02,  4.7091e-02,
         4.7036e-02,  4.6982e-02,  4.6927e-02,  4.6873e-02,  4.6818e-02,
         4.6764e-02,  4.6710e-02,  4.6656e-02,  4.6602e-02,  4.6548e-02,
         4.6494e-02,  4.6441e-02,  4.6387e-02,  4.6334e-02,  4.6280e-02,
         4.6227e-02,  4.6173e-02,  4.6120e-02,  4.6067e-02,  4.6014e-02,
         4.5961e-02,  4.5909e-02,  4.5856e-02,  4.5803e-02,  4.5751e-02,
         4.5698e-02,  4.5646e-02,  4.5594e-02,  4.5542e-02,  4.5489e-02,
         4.5437e-02,  4.5386e-02,  4.5334e-02,  4.5282e-02,  4.5230e-02,
         4.5179e-02,  4.5128e-02,  4.5076e-02,  4.5025e-02,  4.4973e-02,
         4.4922e-02,  4.4871e-02,  4.4820e-02,  4.4769e-02,  4.4719e-02,
         4.4668e-02,  4.4618e-02,  4.4567e-02,  4.4517e-02,  4.4466e-02,
         4.4416e-02,  4.4366e-02,  4.4315e-02,  4.4265e-02,  4.4216e-02,
         4.4166e-02,  4.4116e-02,  4.4066e-02,  4.4017e-02,  4.3967e-02,
         4.3918e-02,  4.3868e-02,  4.3819e-02,  4.3770e-02,  4.3721e-02,
         4.3672e-02,  4.3623e-02,  4.3574e-02,  4.3525e-02,  4.3476e-02,
         4.3428e-02,  4.3379e-02,  4.3331e-02,  4.3282e-02,  4.3234e-02,
         4.3186e-02,  4.3137e-02,  4.3089e-02,  4.3041e-02,  4.2993e-02,
         4.2946e-02,  4.2898e-02,  4.2850e-02,  4.2803e-02,  4.2755e-02,
         4.2708e-02,  4.2660e-02,  4.2613e-02,  4.2566e-02,  4.2518e-02,
         4.2471e-02,  4.2425e-02,  4.2378e-02,  4.2331e-02,  4.2284e-02,
         4.2237e-02,  4.2191e-02,  4.2144e-02,  4.2098e-02,  4.2051e-02,
         4.2005e-02,  4.1959e-02,  4.1913e-02,  4.1867e-02,  4.1821e-02,
         4.1775e-02,  4.1729e-02,  4.1683e-02,  4.1637e-02,  4.1592e-02,
         4.1546e-02,  4.1501e-02,  4.1455e-02,  4.1410e-02,  4.1364e-02,
         4.1319e-02,  4.1274e-02,  4.1229e-02,  4.1184e-02,  4.1139e-02,
         4.1094e-02,  4.1049e-02,  4.1004e-02,  4.0959e-02,  4.0914e-02,
         4.0869e-02,  4.0825e-02,  4.0780e-02,  4.0735e-02,  4.0690e-02,
         4.0646e-02,  4.0601e-02,  4.0556e-02,  4.0511e-02,  4.0466e-02,
         4.0421e-02,  4.0376e-02,  4.0330e-02,  4.0285e-02,  4.0239e-02,
         4.0193e-02,  4.0146e-02,  4.0099e-02,  4.0052e-02,  4.0004e-02,
         3.9956e-02,  3.9907e-02,  3.9857e-02,  3.9806e-02,  3.9755e-02,
         3.9702e-02,  3.9649e-02,  3.9594e-02,  3.9537e-02,  3.9479e-02,
         3.9419e-02,  3.9357e-02,  3.9293e-02,  3.9227e-02,  3.9158e-02,
         3.9086e-02,  3.9010e-02,  3.8931e-02,  3.8848e-02,  3.8762e-02,
         3.6418e-02,  3.6182e-02,  3.5931e-02,  3.5665e-02,  3.5387e-02,
         3.5088e-02,  3.4772e-02,  3.4437e-02,  3.4083e-02,  3.3717e-02,
         3.3324e-02,  3.2908e-02,  3.2474e-02,  3.2015e-02,  3.1538e-02,
         3.1056e-02,  3.0532e-02,  2.9983e-02,  2.9415e-02,  2.8821e-02,
         2.8205e-02,  2.7567e-02,  2.6909e-02,  2.6230e-02,  2.5555e-02,
         2.4833e-02,  2.4098e-02,  2.3344e-02,  2.2567e-02,  2.1783e-02,
         2.0977e-02,  2.0156e-02,  1.9382e-02,  1.8547e-02,  1.7716e-02,
         1.6865e-02,  1.6035e-02,  1.5189e-02,  1.4345e-02,  1.3580e-02,
         1.2724e-02,  1.1936e-02,  1.1083e-02,  1.0300e-02,  9.5034e-03,
         8.7833e-03,  8.0071e-03,  7.3142e-03,  6.6095e-03,  5.9441e-03,
         5.2740e-03,  4.7078e-03,  4.0720e-03,  3.5465e-03,  3.1869e-03,
         2.7794e-03,  2.2946e-03,  1.9247e-03,  1.5640e-03,  1.2530e-03,
         9.4350e-04,  6.9034e-04,  5.0090e-04,  4.3770e-04,  2.4912e-04,
         1.8652e-04,  2.4894e-04,  1.8617e-04,  2.4069e-04,  4.2015e-04,
         6.0753e-04,  9.7523e-04,  1.1549e-03,  1.4532e-03,  1.7438e-03,
         2.1686e-03,  2.5640e-03,  2.9750e-03,  3.4911e-03,  3.9934e-03,
         4.4963e-03,  4.9927e-03,  5.5738e-03,  6.2684e-03,  6.8362e-03,
         7.5957e-03,  8.2485e-03,  8.9726e-03,  9.8244e-03,  1.0519e-02,
         1.1270e-02,  1.2012e-02,  1.2810e-02,  1.3379e-02,  1.4249e-02,
         1.5011e-02,  1.5818e-02,  1.6736e-02,  1.7270e-02,  1.8114e-02,
         1.8856e-02,  1.9623e-02,  2.0183e-02,  2.0993e-02,  2.1602e-02,
         2.2329e-02,  2.2873e-02,  2.3610e-02,  2.4092e-02,  2.4748e-02,
         2.5246e-02,  2.5821e-02,  2.6259e-02,  2.6764e-02,  2.7287e-02,
         2.7692e-02,  2.8142e-02,  2.8490e-02,  2.8876e-02,  2.9212e-02,
         2.9540e-02,  2.9824e-02,  3.0133e-02,  3.0370e-02,  3.0655e-02,
         3.0851e-02,  3.1087e-02,  3.1268e-02,  3.1461e-02,  3.1608e-02,
         3.1765e-02,  3.1919e-02,  3.2036e-02,  3.2157e-02,  3.2248e-02,
         3.2343e-02,  3.2422e-02,  3.2494e-02,  3.2553e-02,  3.2606e-02,
         3.2655e-02,  3.2703e-02,  3.2726e-02,  3.2759e-02,  3.2780e-02,
         3.2800e-02,  3.2810e-02,  3.2826e-02,  3.2827e-02,  3.2828e-02,
         3.2829e-02,  3.2821e-02,  3.2815e-02,  3.2804e-02,  3.2791e-02,
         3.2775e-02,  3.2760e-02,  3.2741e-02,  3.2722e-02,  3.2701e-02,
         3.2679e-02,  3.2655e-02,  3.2632e-02,  3.2607e-02,  3.2581e-02,
         3.2554e-02,  3.2528e-02,  3.2500e-02,  3.2472e-02,  3.2443e-02,
         3.2415e-02,  3.2385e-02,  3.2356e-02,  3.2326e-02,  3.2297e-02,
         3.2267e-02,  3.2237e-02,  3.2207e-02,  3.2176e-02,  3.2146e-02,
         3.2115e-02,  3.2085e-02,  3.2054e-02,  3.2024e-02,  3.1993e-02,
         3.1963e-02,  3.1932e-02,  3.1901e-02,  3.1871e-02,  3.1840e-02,
         3.1810e-02,  3.1779e-02,  3.1749e-02,  3.1719e-02,  3.1688e-02,
         3.1658e-02,  3.1627e-02,  3.1597e-02,  3.1567e-02,  3.1536e-02,
         3.1506e-02,  3.1476e-02,  3.1446e-02,  3.1416e-02,  3.1386e-02,
         3.1356e-02,  3.1326e-02,  3.1296e-02,  3.1266e-02,  3.1236e-02,
         3.1206e-02,  3.1177e-02,  3.1147e-02,  3.1117e-02,  3.1088e-02,
         3.1058e-02,  3.1029e-02,  3.1000e-02,  3.0970e-02,  3.0941e-02,
         3.0912e-02,  3.0883e-02,  3.0854e-02,  3.0825e-02,  3.0796e-02,
         3.0767e-02,  3.0739e-02,  3.0710e-02,  3.0682e-02,  3.0654e-02,
         3.0626e-02,  3.0597e-02,  3.0570e-02,  3.0543e-02,  3.0516e-02,
         3.0489e-02,  3.0462e-02,  3.0436e-02,  3.0409e-02,  3.0385e-02,
         3.0359e-02,  3.0336e-02,  3.0309e-02,  3.0288e-02,  3.0265e-02,
         3.0245e-02,  3.0218e-02,  3.0200e-02,  3.0182e-02,  3.0168e-02,
         3.0142e-02,  3.0131e-02,  3.0119e-02,  3.0095e-02,  3.0085e-02,
         3.0084e-02,  3.0080e-02,  3.0059e-02,  3.0060e-02,  3.0065e-02,
         3.0074e-02,  3.0056e-02,  3.0072e-02,  3.0082e-02,  3.0109e-02,
         3.0095e-02,  3.0130e-02,  3.0157e-02,  3.0207e-02,  3.0180e-02,
         3.0240e-02,  3.0287e-02,  3.0283e-02,  3.0339e-02,  3.0430e-02,
         3.0502e-02,  3.0474e-02,  3.0554e-02,  3.0677e-02,  3.0774e-02,
         3.0746e-02,  3.0850e-02,  3.0958e-02,  3.1071e-02,  3.1044e-02,
         3.1114e-02,  3.1229e-02,  3.1200e-02,  3.1311e-02,  3.1372e-02,
         3.1460e-02,  3.1397e-02,  3.1491e-02,  3.1504e-02,  3.1489e-02,
         3.1454e-02,  3.1391e-02,  3.1283e-02,  3.1112e-02,  3.1149e-02,
         3.0937e-02,  3.0645e-02,  3.0242e-02,  3.0377e-02,  2.9904e-02,
         2.9276e-02,  2.9513e-02,  2.8775e-02,  2.7817e-02,  2.6578e-02,
         2.7094e-02,  2.5652e-02,  2.3806e-02,  2.3510e-02,  2.4332e-02,
         2.2118e-02,  1.9294e-02,  1.8846e-02,  2.0132e-02,  1.6752e-02,
         1.2394e-02,  1.7762e-02,  1.3723e-02,  1.3101e-02,  7.7074e-03,
         1.4365e-02,  9.3884e-03,  2.8644e-03,  1.8946e-03,  1.0227e-02,
         3.9921e-03,  3.0545e-03,  6.5414e-04,  5.0762e-03,  4.1693e-03,
         6.5173e-04,  6.5087e-04,  5.2413e-03,  6.4898e-04,  6.4812e-04,
         6.2479e-03,  5.4036e-03,  6.4571e-04,  6.4485e-04,  6.3991e-03,
         5.5633e-03,  4.6840e-03,  3.7840e-03,  1.1354e-02,  1.0686e-02,
         1.0003e-02,  9.3056e-03,  1.5243e-02,  1.4725e-02,  1.4178e-02,
         1.8683e-02,  1.8292e-02,  1.7859e-02,  1.9988e-02,  2.2844e-02,
         2.2580e-02,  2.2285e-02,  2.1998e-02,  2.5462e-02,  2.5284e-02,
         2.5081e-02,  2.5930e-02,  2.7070e-02,  2.6942e-02,  2.7441e-02,
         2.7321e-02,  2.8379e-02,  2.8301e-02,  2.8519e-02,  2.8797e-02,
         2.8886e-02,  2.8840e-02,  2.8904e-02,  2.8967e-02,  2.8963e-02,
         2.8941e-02,  2.8913e-02,  2.8835e-02,  2.8772e-02,  2.8701e-02,
         2.8682e-02,  2.8505e-02,  2.8420e-02,  2.8334e-02,  2.8248e-02,
         2.8116e-02,  2.8028e-02,  2.7943e-02,  2.7746e-02,  2.7665e-02,
         2.7585e-02,  2.7507e-02,  2.7337e-02,  2.7266e-02,  2.7197e-02,
         2.7129e-02,  2.6988e-02,  2.6886e-02,  2.6828e-02,  2.6772e-02,
         2.6663e-02,  2.6612e-02,  2.6535e-02,  2.6447e-02,  2.6404e-02,
         2.6361e-02,  2.6300e-02,  2.6231e-02,  2.6195e-02,  2.6143e-02,
         2.6108e-02,  2.6042e-02,  2.6010e-02,  2.5955e-02,  2.5930e-02,
         2.5896e-02,  2.5872e-02,  2.5825e-02,  2.5784e-02,  2.5760e-02,
         2.5731e-02,  2.5695e-02,  2.5672e-02,  2.5638e-02,  2.5607e-02,
         2.5584e-02,  2.5559e-02,  2.5536e-02,  2.5508e-02,  2.5481e-02,
         2.5459e-02,  2.5433e-02,  2.5407e-02,  2.5385e-02,  2.5361e-02,
         2.5339e-02,  2.5315e-02,  2.5291e-02,  2.5270e-02,  2.5246e-02,
         2.5224e-02,  2.5202e-02,  2.5179e-02,  2.5157e-02,  2.5136e-02,
         2.5113e-02,  2.5092e-02,  2.5069e-02,  2.5048e-02,  2.5026e-02,
         2.5005e-02,  2.4983e-02,  2.4962e-02,  2.4940e-02,  2.4919e-02,
         2.4897e-02,  2.4876e-02,  2.4855e-02,  2.4833e-02,  2.4812e-02,
         2.4791e-02,  2.4770e-02,  2.4748e-02,  2.4727e-02,  2.4706e-02,
         2.4685e-02,  2.4664e-02,  2.4643e-02,  2.4622e-02,  2.4601e-02,
         2.4580e-02,  2.4559e-02,  2.4538e-02,  2.4518e-02,  2.4497e-02,
         2.4476e-02,  2.4455e-02,  2.4435e-02,  2.4414e-02,  2.4393e-02],
       device='cuda:0')
Selected points (indices): {284}
Selected new x values (normalized): tensor([0.2843], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-862.8629], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter5/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:35:34 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_5 [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		M_1: [-862.86]               [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:35:34 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:35:35 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_5, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:35:35 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:35:35 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_5/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 5
Starting iteration 6
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.1617, 0.0046, 0.0561, 0.2242, 0.0180, 0.2843, 0.1041, 0.5812, 0.8528],
       device='cuda:0') torch.Size([9])
These training_points are used in the GP tensor([0.1617, 0.0046, 0.0561, 0.2242, 0.0180, 0.2843, 0.1041, 0.5812, 0.8528],
       device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[3.9840e-02],
        [1.0100e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.4779e-01],
        [7.2965e-02],
        [1.0000e-06],
        [2.0526e-01],
        [1.0000e-06],
        [1.0000e-06],
        [8.1838e-03],
        [1.0000e-06],
        [1.0573e-01],
        [1.0000e-06],
        [1.0000e-06],
        [6.8852e-02],
        [7.8537e-03],
        [1.2054e-01],
        [1.0000e-06],
        [7.3322e-03],
        [3.2099e-02],
        [1.0000e-06],
        [5.6269e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.6382e-01],
        [1.0000e-06],
        [1.6852e-01],
        [3.3366e-02],
        [1.0000e-06],
        [2.9555e-02],
        [1.0000e-06],
        [2.3687e-01],
        [1.0000e-06],
        [1.0000e-06],
        [8.4893e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.2838e-01],
        [1.0000e-06],
        [8.0935e-02],
        [1.0000e-06],
        [1.0000e-06],
        [8.1712e-02],
        [1.0000e-06],
        [2.1815e-01],
        [5.2717e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [6.1546e-02],
        [1.0000e-06],
        [1.0000e-06],
        [5.4639e-03],
        [1.0000e-06],
        [5.3845e-02],
        [1.1202e-02],
        [4.8167e-03],
        [1.5786e-01],
        [1.0000e-06],
        [2.1864e-01],
        [2.3125e-02],
        [1.0000e-06],
        [8.6530e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [2.0605e-01],
        [1.0000e-06],
        [1.0000e-06],
        [4.3396e-02],
        [1.0000e-06],
        [7.4517e-02],
        [8.7982e-02],
        [2.0509e-01],
        [2.1158e-01],
        [1.0929e-01],
        [1.1033e-01],
        [2.1300e-01],
        [2.0674e-01],
        [2.9151e-01],
        [1.8500e-01],
        [1.6647e-01],
        [2.4420e-01],
        [3.1088e-01],
        [8.5748e-02],
        [1.5796e-01],
        [2.2033e-01],
        [2.7438e-01],
        [3.2138e-01],
        [1.9037e-01],
        [1.3425e-01],
        [1.8045e-01],
        [2.2136e-01],
        [2.5781e-01],
        [1.0216e-01],
        [1.3981e-01],
        [1.7393e-01],
        [2.0506e-01],
        [3.1895e-02],
        [6.5443e-02],
        [9.6552e-02],
        [2.2897e-01],
        [2.5293e-01],
        [8.5681e-02],
        [1.1258e-01],
        [1.3799e-01],
        [1.6204e-01],
        [9.3560e-02],
        [1.1765e-01],
        [1.4045e-01],
        [2.6110e-01],
        [2.7894e-01],
        [1.1238e-01],
        [2.3472e-01],
        [2.5069e-01],
        [3.5219e-01],
        [3.6356e-01],
        [3.0485e-01],
        [3.1422e-01],
        [4.0194e-01],
        [4.0641e-01],
        [3.4557e-01],
        [3.4585e-01],
        [4.2093e-01],
        [4.8479e-01],
        [4.7688e-01],
        [4.1155e-01],
        [4.6725e-01],
        [4.4886e-01],
        [4.9378e-01],
        [5.3150e-01],
        [4.5790e-01],
        [4.2271e-01],
        [4.5402e-01],
        [4.7981e-01],
        [3.8437e-01],
        [4.0609e-01],
        [4.2345e-01],
        [4.3709e-01],
        [4.4753e-01],
        [3.3174e-01],
        [3.3886e-01],
        [3.4346e-01],
        [3.4591e-01],
        [3.4652e-01],
        [1.9977e-01],
        [1.9724e-01],
        [1.9326e-01],
        [2.8410e-01],
        [1.1898e-01],
        [1.1135e-01],
        [1.0283e-01],
        [9.3535e-02],
        [1.9191e-01],
        [8.0053e-03],
        [9.2594e-03],
        [9.9138e-02],
        [8.7790e-02],
        [1.8529e-01],
        [1.1370e-02],
        [1.1341e-02],
        [8.8307e-02],
        [7.5847e-02],
        [1.0184e-02],
        [9.3658e-03],
        [8.6123e-02],
        [1.8243e-01],
        [1.7024e-01],
        [9.4264e-02],
        [8.0056e-02],
        [1.7562e-01],
        [2.6082e-01],
        [2.4764e-01],
        [1.7645e-01],
        [2.5948e-01],
        [3.3324e-01],
        [3.9868e-01],
        [2.4965e-01],
        [3.2054e-01],
        [3.8308e-01],
        [4.3807e-01],
        [4.8626e-01],
        [4.2753e-01],
        [4.7222e-01],
        [5.1076e-01],
        [5.4368e-01],
        [4.8228e-01],
        [5.1087e-01],
        [5.3423e-01],
        [5.5274e-01],
        [5.6675e-01],
        [4.9253e-01],
        [5.0042e-01],
        [5.6277e-01],
        [5.6197e-01],
        [5.5753e-01],
        [4.6456e-01],
        [4.8537e-01],
        [5.0208e-01],
        [4.8375e-01],
        [4.0236e-01],
        [4.1298e-01],
        [3.8330e-01],
        [3.8953e-01],
        [3.9384e-01],
        [2.8855e-01],
        [2.9043e-01],
        [2.9095e-01],
        [2.9033e-01],
        [2.8876e-01],
        [1.6009e-01],
        [1.5667e-01],
        [1.5257e-01],
        [1.9988e-01],
        [5.3179e-02],
        [4.7131e-02],
        [9.9156e-02],
        [9.2786e-02],
        [1.4185e-01],
        [1.0650e-02],
        [3.7915e-02],
        [3.0316e-02],
        [8.2053e-02],
        [1.3089e-01],
        [1.0973e-02],
        [2.4049e-02],
        [7.5386e-02],
        [1.2378e-01],
        [2.3691e-02],
        [7.4156e-02],
        [1.2160e-01],
        [1.6613e-01],
        [2.0785e-01],
        [1.1522e-01],
        [1.5805e-01],
        [2.4679e-01],
        [2.8136e-01],
        [3.1317e-01],
        [2.7546e-01],
        [3.0477e-01],
        [3.7193e-01],
        [3.9375e-01],
        [3.5454e-01],
        [3.7252e-01],
        [4.2458e-01],
        [4.6954e-01],
        [4.7600e-01],
        [4.3049e-01],
        [4.6538e-01],
        [4.9439e-01],
        [5.1803e-01],
        [5.3680e-01],
        [4.8118e-01],
        [4.9377e-01],
        [5.0192e-01],
        [5.0595e-01],
        [4.3279e-01],
        [4.2966e-01],
        [4.5789e-01],
        [4.4766e-01],
        [4.3402e-01],
        [3.7517e-01],
        [3.5413e-01],
        [3.7064e-01],
        [3.4451e-01],
        [3.5707e-01],
        [2.3376e-01],
        [2.4510e-01],
        [2.5485e-01],
        [2.1539e-01],
        [1.1733e-01],
        [1.2529e-01],
        [1.3234e-01],
        [1.3864e-01],
        [1.4432e-01],
        [3.4366e-02],
        [3.9861e-02],
        [4.4965e-02],
        [4.9753e-02],
        [1.0644e-02],
        [1.1161e-02],
        [1.1338e-02],
        [1.1382e-02],
        [6.9973e-02],
        [1.3330e-02],
        [1.1075e-02],
        [2.0978e-02],
        [5.5107e-02],
        [5.8526e-02],
        [9.1327e-02],
        [6.5681e-02],
        [1.2615e-01],
        [1.0148e-01],
        [1.5965e-01],
        [2.1409e-01],
        [2.1694e-01],
        [2.6771e-01],
        [2.7039e-01],
        [3.1773e-01],
        [3.2024e-01],
        [3.6438e-01],
        [4.2415e-01],
        [4.2629e-01],
        [4.8031e-01],
        [4.8225e-01],
        [5.3106e-01],
        [5.4737e-01],
        [5.9011e-01],
        [6.2887e-01],
        [6.4183e-01],
        [6.7578e-01],
        [6.8713e-01],
        [7.2574e-01],
        [7.3537e-01],
        [7.6814e-01],
        [7.9030e-01],
        [8.0412e-01],
        [8.2855e-01],
        [8.3992e-01],
        [8.6002e-01],
        [8.6936e-01],
        [8.8589e-01],
        [8.9358e-01],
        [9.1020e-01],
        [9.2178e-01],
        [9.2958e-01],
        [9.3881e-01],
        [9.4503e-01],
        [9.5403e-01],
        [9.5883e-01],
        [9.6578e-01],
        [9.7170e-01],
        [9.7487e-01],
        [9.7944e-01],
        [9.8188e-01],
        [9.8604e-01],
        [9.8787e-01],
        [9.9098e-01],
        [9.9355e-01],
        [9.9468e-01],
        [9.9660e-01],
        [9.9771e-01],
        [9.9910e-01],
        [9.9990e-01],
        [1.0011e+00],
        [1.0019e+00],
        [1.0023e+00],
        [1.0030e+00],
        [1.0034e+00],
        [1.0038e+00],
        [1.0041e+00],
        [1.0044e+00],
        [1.0047e+00],
        [1.0048e+00],
        [1.0050e+00],
        [1.0051e+00],
        [1.0052e+00],
        [1.0053e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0054e+00],
        [1.0054e+00],
        [1.0053e+00],
        [1.0052e+00],
        [1.0051e+00],
        [1.0049e+00],
        [1.0048e+00],
        [1.0046e+00],
        [1.0043e+00],
        [1.0040e+00],
        [1.0037e+00],
        [1.0033e+00],
        [1.0028e+00],
        [1.0023e+00],
        [1.0016e+00],
        [1.0008e+00],
        [9.9990e-01],
        [9.9883e-01],
        [9.9758e-01],
        [9.9616e-01],
        [9.9450e-01],
        [9.9261e-01],
        [9.9041e-01],
        [9.8788e-01],
        [9.8506e-01],
        [9.8186e-01],
        [9.7809e-01],
        [9.7399e-01],
        [9.6936e-01],
        [9.6422e-01],
        [9.5816e-01],
        [9.5169e-01],
        [9.4453e-01],
        [9.3662e-01],
        [9.2753e-01],
        [9.1777e-01],
        [9.0736e-01],
        [8.9507e-01],
        [8.8246e-01],
        [8.6895e-01],
        [8.5425e-01],
        [8.3730e-01],
        [8.2030e-01],
        [8.0197e-01],
        [7.8138e-01],
        [7.6064e-01],
        [7.3904e-01],
        [7.1609e-01],
        [6.8992e-01],
        [6.6475e-01],
        [6.3901e-01],
        [6.1133e-01],
        [5.8321e-01],
        [5.4948e-01],
        [5.1886e-01],
        [4.8821e-01],
        [4.5777e-01],
        [4.2780e-01],
        [3.9620e-01],
        [3.6787e-01],
        [3.2762e-01],
        [2.9887e-01],
        [2.6890e-01],
        [2.4065e-01],
        [2.1442e-01],
        [1.8729e-01],
        [1.6252e-01],
        [1.4040e-01],
        [1.0711e-01],
        [9.0705e-02],
        [7.4003e-02],
        [5.6996e-02],
        [4.7196e-02],
        [3.3504e-02],
        [2.7291e-02],
        [1.7056e-02],
        [1.1383e-02],
        [1.2171e-02],
        [1.3603e-02],
        [2.2742e-02],
        [3.1797e-02],
        [4.8277e-02],
        [4.5791e-02],
        [6.2034e-02],
        [8.5223e-02],
        [1.0784e-01],
        [1.2990e-01],
        [1.5807e-01],
        [1.7890e-01],
        [2.0226e-01],
        [2.2810e-01],
        [2.5897e-01],
        [2.9419e-01],
        [3.2243e-01],
        [3.5466e-01],
        [3.9020e-01],
        [4.1686e-01],
        [4.4900e-01],
        [4.7939e-01],
        [5.1199e-01],
        [5.4257e-01],
        [5.7464e-01],
        [6.0448e-01],
        [6.3076e-01],
        [6.6083e-01],
        [6.8088e-01],
        [7.1157e-01],
        [7.3296e-01],
        [7.5281e-01],
        [7.7670e-01],
        [7.9665e-01],
        [8.1640e-01],
        [8.3289e-01],
        [8.5164e-01],
        [8.6506e-01],
        [8.7732e-01],
        [8.9302e-01],
        [9.0284e-01],
        [9.1542e-01],
        [9.2457e-01],
        [9.3449e-01],
        [9.4270e-01],
        [9.4908e-01],
        [9.5678e-01],
        [9.6241e-01],
        [9.6830e-01],
        [9.7261e-01],
        [9.7755e-01],
        [9.8080e-01],
        [9.8401e-01],
        [9.8725e-01],
        [9.8963e-01],
        [9.9203e-01],
        [9.9398e-01],
        [9.9588e-01],
        [9.9715e-01],
        [9.9837e-01],
        [9.9966e-01],
        [1.0005e+00],
        [1.0014e+00],
        [1.0020e+00],
        [1.0027e+00],
        [1.0032e+00],
        [1.0036e+00],
        [1.0040e+00],
        [1.0043e+00],
        [1.0045e+00],
        [1.0047e+00],
        [1.0049e+00],
        [1.0051e+00],
        [1.0052e+00],
        [1.0053e+00],
        [1.0053e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0055e+00],
        [1.0054e+00],
        [1.0053e+00],
        [1.0052e+00],
        [1.0051e+00],
        [1.0050e+00],
        [1.0048e+00],
        [1.0045e+00],
        [1.0042e+00],
        [1.0042e+00],
        [1.0037e+00],
        [1.0032e+00],
        [1.0026e+00],
        [1.0025e+00],
        [1.0018e+00],
        [1.0008e+00],
        [9.9964e-01],
        [9.9817e-01],
        [9.9808e-01],
        [9.9623e-01],
        [9.9393e-01],
        [9.9197e-01],
        [9.8863e-01],
        [9.8844e-01],
        [9.8555e-01],
        [9.8066e-01],
        [9.7459e-01],
        [9.7614e-01],
        [9.7120e-01],
        [9.6543e-01],
        [9.5243e-01],
        [9.4352e-01],
        [9.4662e-01],
        [9.3674e-01],
        [9.2521e-01],
        [9.1174e-01],
        [8.9602e-01],
        [9.0151e-01],
        [8.8408e-01],
        [8.6373e-01],
        [8.3998e-01],
        [8.4827e-01],
        [8.2193e-01],
        [7.9119e-01],
        [7.5531e-01],
        [7.1343e-01],
        [7.6067e-01],
        [7.1968e-01],
        [6.7184e-01],
        [6.1599e-01],
        [6.3547e-01],
        [6.2432e-01],
        [5.6053e-01],
        [4.8607e-01],
        [4.7042e-01],
        [4.9717e-01],
        [4.8186e-01],
        [3.9424e-01],
        [2.9197e-01],
        [2.7048e-01],
        [3.0722e-01],
        [2.8619e-01],
        [1.6584e-01],
        [1.4056e-01],
        [2.8037e-01],
        [1.5905e-01],
        [1.3356e-01],
        [1.1383e-02],
        [1.1383e-02],
        [1.2650e-01],
        [1.1383e-02],
        [1.1383e-02],
        [1.1383e-02],
        [1.1383e-02],
        [6.5219e-02],
        [1.1383e-02],
        [1.1383e-02],
        [1.1383e-02],
        [2.9066e-02],
        [1.1383e-02],
        [1.1383e-02],
        [1.1383e-02],
        [1.1383e-02],
        [8.3747e-02],
        [5.5989e-02],
        [2.7396e-02],
        [1.1383e-02],
        [1.1383e-02],
        [1.3537e-01],
        [1.0916e-01],
        [8.2170e-02],
        [1.6615e-01],
        [3.0183e-01],
        [2.8064e-01],
        [2.5881e-01],
        [3.2673e-01],
        [3.0628e-01],
        [4.1932e-01],
        [4.7264e-01],
        [4.5659e-01],
        [4.4006e-01],
        [4.9149e-01],
        [5.7459e-01],
        [6.1380e-01],
        [6.0200e-01],
        [6.3871e-01],
        [6.9802e-01],
        [7.2600e-01],
        [7.1758e-01],
        [7.4378e-01],
        [7.3589e-01],
        [8.0608e-01],
        [8.2423e-01],
        [8.1877e-01],
        [8.3576e-01],
        [8.5122e-01],
        [8.7618e-01],
        [8.8796e-01],
        [8.9867e-01],
        [9.0840e-01],
        [9.3371e-01],
        [9.4026e-01],
        [9.3829e-01],
        [9.4442e-01],
        [9.4999e-01],
        [9.6449e-01],
        [9.6823e-01],
        [9.7164e-01],
        [9.7474e-01],
        [9.8280e-01],
        [9.8488e-01],
        [9.8677e-01],
        [9.8849e-01],
        [9.9190e-01],
        [9.9549e-01],
        [9.9642e-01],
        [9.9726e-01],
        [9.9803e-01],
        [9.9873e-01],
        [1.0012e+00],
        [1.0016e+00],
        [1.0019e+00],
        [1.0027e+00],
        [1.0035e+00],
        [1.0037e+00],
        [1.0041e+00],
        [1.0042e+00],
        [1.0045e+00],
        [1.0048e+00],
        [1.0050e+00],
        [1.0051e+00],
        [1.0052e+00],
        [1.0052e+00],
        [1.0054e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([ 1.7635e-02,  2.7685e-03, -7.8477e-03, -1.7412e-03,  4.0738e-02,
         2.0775e-02, -6.5074e-03,  4.2794e-02, -5.9385e-03, -5.2963e-03,
         1.5959e-03, -5.1139e-03,  1.6418e-02, -5.7829e-04, -5.9816e-03,
         8.6685e-03,  1.1156e-03,  1.2963e-02, -4.3675e-04,  1.0006e-03,
         2.9437e-03, -1.5417e-03,  4.6522e-03, -7.2866e-03, -4.3267e-03,
         1.1842e-02, -1.0024e-02,  1.1386e-02,  2.2181e-03, -1.5542e-02,
         1.8821e-03, -8.2783e-03,  1.4341e-02, -8.8674e-03, -2.0397e-02,
         4.9215e-03, -4.4738e-03, -1.5354e-02,  7.2987e-03, -1.8422e-02,
         4.6084e-03, -5.4267e-03, -1.6128e-02,  4.6594e-03, -5.9822e-03,
         1.2632e-02,  3.0507e-03, -5.5363e-03, -3.0276e-03, -4.9793e-03,
         3.7400e-03, -1.3790e-03, -2.8797e-03,  3.2677e-04, -2.6012e-04,
         3.4839e-03,  6.9773e-04,  2.8661e-04,  1.0479e-02, -2.4894e-04,
         1.4721e-02,  1.6288e-03, -1.3735e-03,  6.0442e-03, -3.7880e-03,
        -3.5275e-03, -5.6909e-03, -3.9560e-03,  1.4537e-02, -6.9739e-05,
        -1.2607e-02,  3.1365e-03, -4.9833e-03,  5.4036e-03,  6.3399e-03,
         1.4468e-02,  1.4841e-02,  7.7408e-03,  7.7455e-03,  1.4669e-02,
         1.4127e-02,  1.9553e-02,  1.2467e-02,  1.1127e-02,  1.6011e-02,
         2.0038e-02,  5.5912e-03,  1.0094e-02,  1.3855e-02,  1.6974e-02,
         1.9590e-02,  1.1560e-02,  8.1058e-03,  1.0713e-02,  1.2990e-02,
         1.4940e-02,  5.8796e-03,  7.9625e-03,  9.8174e-03,  1.1460e-02,
         1.7660e-03,  3.5962e-03,  5.2793e-03,  1.2415e-02,  1.3629e-02,
         4.5515e-03,  5.9864e-03,  7.2550e-03,  8.5119e-03,  4.8537e-03,
         6.0768e-03,  7.2486e-03,  1.3473e-02,  1.4332e-02,  5.7128e-03,
         1.1958e-02,  1.2719e-02,  1.7925e-02,  1.8456e-02,  1.5366e-02,
         1.5801e-02,  2.0295e-02,  2.0486e-02,  1.7316e-02,  1.7301e-02,
         2.1144e-02,  2.4468e-02,  2.4060e-02,  2.0656e-02,  2.3551e-02,
         2.2615e-02,  2.5003e-02,  2.7032e-02,  2.3195e-02,  2.1419e-02,
         2.3107e-02,  2.4528e-02,  1.9591e-02,  2.0802e-02,  2.1788e-02,
         2.2573e-02,  2.3189e-02,  1.7180e-02,  1.7603e-02,  1.7923e-02,
         1.8109e-02,  1.8206e-02,  1.0509e-02,  1.0404e-02,  1.0215e-02,
         1.5073e-02,  6.3223e-03,  5.9371e-03,  5.4979e-03,  5.0130e-03,
         1.0275e-02,  4.2738e-04,  4.9058e-04,  5.3464e-03,  4.7426e-03,
         9.9814e-03,  6.2258e-04,  6.1449e-04,  4.7851e-03,  4.0947e-03,
         5.4329e-04,  4.9729e-04,  4.6515e-03,  9.8752e-03,  9.1954e-03,
         5.1330e-03,  4.3573e-03,  9.5084e-03,  1.4087e-02,  1.3399e-02,
         9.5647e-03,  1.4030e-02,  1.7977e-02,  2.1469e-02,  1.3508e-02,
         1.7327e-02,  2.0672e-02,  2.3614e-02,  2.6173e-02,  2.3079e-02,
         2.5477e-02,  2.7534e-02,  2.9293e-02,  2.6081e-02,  2.7628e-02,
         2.8875e-02,  2.9894e-02,  3.0663e-02,  2.6805e-02,  2.7239e-02,
         3.0525e-02,  3.0521e-02,  3.0324e-02,  2.5455e-02,  2.6572e-02,
         2.7474e-02,  2.6507e-02,  2.2197e-02,  2.2761e-02,  2.1178e-02,
         2.1500e-02,  2.1724e-02,  1.6053e-02,  1.6125e-02,  1.6139e-02,
         1.6105e-02,  1.6015e-02,  8.9516e-03,  8.7410e-03,  8.5133e-03,
         1.1093e-02,  2.9976e-03,  2.6540e-03,  5.5095e-03,  5.1511e-03,
         7.8039e-03,  5.9274e-04,  2.0924e-03,  1.6715e-03,  4.4879e-03,
         7.0986e-03,  5.8466e-04,  1.3135e-03,  4.0654e-03,  6.6102e-03,
         1.2433e-03,  3.9235e-03,  6.3671e-03,  8.6331e-03,  1.0705e-02,
         5.9239e-03,  8.0454e-03,  1.2431e-02,  1.4041e-02,  1.5469e-02,
         1.3528e-02,  1.4788e-02,  1.7873e-02,  1.8729e-02,  1.6714e-02,
         1.7363e-02,  1.9603e-02,  2.1461e-02,  2.1524e-02,  1.9227e-02,
         2.0600e-02,  2.1676e-02,  2.2505e-02,  2.3106e-02,  2.0430e-02,
         2.0763e-02,  2.0927e-02,  2.0906e-02,  1.7591e-02,  1.7302e-02,
         1.8371e-02,  1.7803e-02,  1.7110e-02,  1.4586e-02,  1.3651e-02,
         1.4260e-02,  1.3132e-02,  1.3579e-02,  8.7006e-03,  9.1068e-03,
         9.4634e-03,  7.9271e-03,  4.2484e-03,  4.5244e-03,  4.7800e-03,
         4.9882e-03,  5.1878e-03,  1.2221e-03,  1.4042e-03,  1.6037e-03,
         1.7559e-03,  3.7157e-04,  3.8945e-04,  4.0089e-04,  3.8894e-04,
         2.4465e-03,  4.6771e-04,  3.8997e-04,  7.1854e-04,  1.9142e-03,
         2.0313e-03,  3.1913e-03,  2.2782e-03,  4.4294e-03,  3.5411e-03,
         5.5997e-03,  7.5707e-03,  7.6714e-03,  9.5079e-03,  9.6187e-03,
         1.1370e-02,  1.1447e-02,  1.3087e-02,  1.5393e-02,  1.5462e-02,
         1.7573e-02,  1.7624e-02,  1.9576e-02,  2.0222e-02,  2.1968e-02,
         2.3587e-02,  2.4125e-02,  2.5582e-02,  2.6070e-02,  2.7781e-02,
         2.8198e-02,  2.9707e-02,  3.0739e-02,  3.1385e-02,  3.2578e-02,
         3.3129e-02,  3.4151e-02,  3.4617e-02,  3.5489e-02,  3.5886e-02,
         3.6809e-02,  3.7467e-02,  3.7906e-02,  3.8455e-02,  3.8821e-02,
         3.9389e-02,  3.9684e-02,  4.0146e-02,  4.0554e-02,  4.0760e-02,
         4.1090e-02,  4.1253e-02,  4.1578e-02,  4.1703e-02,  4.1961e-02,
         4.2181e-02,  4.2258e-02,  4.2431e-02,  4.2518e-02,  4.2650e-02,
         4.2711e-02,  4.2832e-02,  4.2911e-02,  4.2941e-02,  4.3013e-02,
         4.3035e-02,  4.3078e-02,  4.3092e-02,  4.3117e-02,  4.3138e-02,
         4.3135e-02,  4.3146e-02,  4.3133e-02,  4.3133e-02,  4.3114e-02,
         4.3104e-02,  4.3091e-02,  4.3066e-02,  4.3045e-02,  4.3016e-02,
         4.2991e-02,  4.2958e-02,  4.2929e-02,  4.2898e-02,  4.2861e-02,
         4.2827e-02,  4.2788e-02,  4.2751e-02,  4.2712e-02,  4.2673e-02,
         4.2633e-02,  4.2591e-02,  4.2550e-02,  4.2508e-02,  4.2466e-02,
         4.2422e-02,  4.2379e-02,  4.2336e-02,  4.2292e-02,  4.2248e-02,
         4.2204e-02,  4.2160e-02,  4.2115e-02,  4.2071e-02,  4.2026e-02,
         4.1982e-02,  4.1937e-02,  4.1892e-02,  4.1847e-02,  4.1803e-02,
         4.1758e-02,  4.1713e-02,  4.1668e-02,  4.1624e-02,  4.1579e-02,
         4.1534e-02,  4.1490e-02,  4.1445e-02,  4.1401e-02,  4.1356e-02,
         4.1312e-02,  4.1268e-02,  4.1223e-02,  4.1179e-02,  4.1135e-02,
         4.1091e-02,  4.1047e-02,  4.1003e-02,  4.0959e-02,  4.0915e-02,
         4.0871e-02,  4.0828e-02,  4.0784e-02,  4.0740e-02,  4.0697e-02,
         4.0654e-02,  4.0610e-02,  4.0567e-02,  4.0524e-02,  4.0480e-02,
         4.0437e-02,  4.0394e-02,  4.0351e-02,  4.0308e-02,  4.0266e-02,
         4.0223e-02,  4.0180e-02,  4.0137e-02,  4.0095e-02,  4.0052e-02,
         4.0010e-02,  3.9967e-02,  3.9925e-02,  3.9883e-02,  3.9841e-02,
         3.9799e-02,  3.9757e-02,  3.9715e-02,  3.9673e-02,  3.9631e-02,
         3.9589e-02,  3.9547e-02,  3.9506e-02,  3.9464e-02,  3.9422e-02,
         3.9381e-02,  3.9340e-02,  3.9298e-02,  3.9257e-02,  3.9216e-02,
         3.9174e-02,  3.9133e-02,  3.9092e-02,  3.9051e-02,  3.9010e-02,
         3.8969e-02,  3.8928e-02,  3.8887e-02,  3.8846e-02,  3.8805e-02,
         3.8764e-02,  3.8723e-02,  3.8682e-02,  3.8641e-02,  3.8600e-02,
         3.8558e-02,  3.8517e-02,  3.8475e-02,  3.8434e-02,  3.8392e-02,
         3.8350e-02,  3.8308e-02,  3.8265e-02,  3.8222e-02,  3.8179e-02,
         3.8135e-02,  3.8091e-02,  3.8046e-02,  3.8001e-02,  3.7954e-02,
         3.7907e-02,  3.7859e-02,  3.7810e-02,  3.7760e-02,  3.7708e-02,
         3.7655e-02,  3.7600e-02,  3.7543e-02,  3.7485e-02,  3.7424e-02,
         3.7360e-02,  3.7294e-02,  3.7225e-02,  3.7153e-02,  3.7076e-02,
         3.5029e-02,  3.4823e-02,  3.4602e-02,  3.4370e-02,  3.4119e-02,
         3.3858e-02,  3.3576e-02,  3.3277e-02,  3.2965e-02,  3.2630e-02,
         3.2282e-02,  3.1908e-02,  3.1513e-02,  3.1105e-02,  3.0677e-02,
         3.0210e-02,  2.9739e-02,  2.9244e-02,  2.8731e-02,  2.8169e-02,
         2.7609e-02,  2.7027e-02,  2.6423e-02,  2.5775e-02,  2.5123e-02,
         2.4466e-02,  2.3737e-02,  2.3033e-02,  2.2320e-02,  2.1582e-02,
         2.0783e-02,  2.0021e-02,  1.9243e-02,  1.8414e-02,  1.7620e-02,
         1.6825e-02,  1.6031e-02,  1.5157e-02,  1.4364e-02,  1.3572e-02,
         1.2770e-02,  1.1983e-02,  1.1080e-02,  1.0287e-02,  9.5310e-03,
         8.7982e-03,  8.1098e-03,  7.4011e-03,  6.7806e-03,  5.9322e-03,
         5.3439e-03,  4.7502e-03,  4.2083e-03,  3.7030e-03,  3.2073e-03,
         2.7546e-03,  2.3525e-03,  1.7762e-03,  1.4967e-03,  1.2183e-03,
         9.3318e-04,  7.6696e-04,  5.3848e-04,  4.3615e-04,  2.7130e-04,
         1.8514e-04,  1.9271e-04,  2.1592e-04,  3.6417e-04,  5.1242e-04,
         7.7788e-04,  7.3824e-04,  1.0039e-03,  1.3949e-03,  1.7709e-03,
         2.1475e-03,  2.6353e-03,  2.9976e-03,  3.4156e-03,  3.8896e-03,
         4.4611e-03,  5.1372e-03,  5.6877e-03,  6.3356e-03,  7.0737e-03,
         7.6365e-03,  8.3382e-03,  9.0184e-03,  9.7801e-03,  1.0513e-02,
         1.1319e-02,  1.2088e-02,  1.2798e-02,  1.3642e-02,  1.4217e-02,
         1.5147e-02,  1.5821e-02,  1.6475e-02,  1.7294e-02,  1.8014e-02,
         1.8758e-02,  1.9405e-02,  2.0187e-02,  2.0768e-02,  2.1323e-02,
         2.2077e-02,  2.2569e-02,  2.3239e-02,  2.3749e-02,  2.4336e-02,
         2.4850e-02,  2.5266e-02,  2.5806e-02,  2.6221e-02,  2.6685e-02,
         2.7041e-02,  2.7483e-02,  2.7785e-02,  2.8104e-02,  2.8450e-02,
         2.8718e-02,  2.9009e-02,  2.9259e-02,  2.9526e-02,  2.9708e-02,
         2.9897e-02,  3.0118e-02,  3.0270e-02,  3.0448e-02,  3.0570e-02,
         3.0714e-02,  3.0823e-02,  3.0931e-02,  3.1031e-02,  3.1115e-02,
         3.1200e-02,  3.1255e-02,  3.1327e-02,  3.1378e-02,  3.1411e-02,
         3.1455e-02,  3.1485e-02,  3.1515e-02,  3.1534e-02,  3.1558e-02,
         3.1566e-02,  3.1571e-02,  3.1580e-02,  3.1577e-02,  3.1578e-02,
         3.1573e-02,  3.1567e-02,  3.1557e-02,  3.1544e-02,  3.1531e-02,
         3.1515e-02,  3.1498e-02,  3.1480e-02,  3.1460e-02,  3.1440e-02,
         3.1417e-02,  3.1395e-02,  3.1372e-02,  3.1348e-02,  3.1323e-02,
         3.1298e-02,  3.1272e-02,  3.1246e-02,  3.1219e-02,  3.1192e-02,
         3.1165e-02,  3.1138e-02,  3.1110e-02,  3.1083e-02,  3.1055e-02,
         3.1027e-02,  3.0998e-02,  3.0970e-02,  3.0942e-02,  3.0913e-02,
         3.0885e-02,  3.0857e-02,  3.0828e-02,  3.0800e-02,  3.0771e-02,
         3.0743e-02,  3.0714e-02,  3.0686e-02,  3.0657e-02,  3.0629e-02,
         3.0601e-02,  3.0572e-02,  3.0544e-02,  3.0515e-02,  3.0487e-02,
         3.0459e-02,  3.0430e-02,  3.0402e-02,  3.0374e-02,  3.0346e-02,
         3.0318e-02,  3.0290e-02,  3.0262e-02,  3.0234e-02,  3.0206e-02,
         3.0178e-02,  3.0150e-02,  3.0122e-02,  3.0094e-02,  3.0067e-02,
         3.0039e-02,  3.0011e-02,  2.9984e-02,  2.9956e-02,  2.9929e-02,
         2.9901e-02,  2.9874e-02,  2.9846e-02,  2.9819e-02,  2.9792e-02,
         2.9765e-02,  2.9738e-02,  2.9711e-02,  2.9684e-02,  2.9657e-02,
         2.9630e-02,  2.9603e-02,  2.9577e-02,  2.9550e-02,  2.9524e-02,
         2.9498e-02,  2.9472e-02,  2.9446e-02,  2.9420e-02,  2.9395e-02,
         2.9371e-02,  2.9345e-02,  2.9320e-02,  2.9296e-02,  2.9273e-02,
         2.9250e-02,  2.9225e-02,  2.9203e-02,  2.9182e-02,  2.9161e-02,
         2.9138e-02,  2.9118e-02,  2.9100e-02,  2.9085e-02,  2.9070e-02,
         2.9046e-02,  2.9033e-02,  2.9022e-02,  2.9012e-02,  2.9006e-02,
         2.8985e-02,  2.8982e-02,  2.8982e-02,  2.8986e-02,  2.8961e-02,
         2.8969e-02,  2.8983e-02,  2.8991e-02,  2.9015e-02,  2.8991e-02,
         2.9022e-02,  2.9046e-02,  2.9092e-02,  2.9127e-02,  2.9104e-02,
         2.9168e-02,  2.9219e-02,  2.9278e-02,  2.9256e-02,  2.9323e-02,
         2.9397e-02,  2.9481e-02,  2.9574e-02,  2.9553e-02,  2.9655e-02,
         2.9765e-02,  2.9841e-02,  2.9965e-02,  2.9945e-02,  3.0029e-02,
         3.0162e-02,  3.0296e-02,  3.0228e-02,  3.0315e-02,  3.0397e-02,
         3.0551e-02,  3.0608e-02,  3.0551e-02,  3.0594e-02,  3.0617e-02,
         3.0607e-02,  3.0556e-02,  3.0539e-02,  3.0453e-02,  3.0303e-02,
         3.0072e-02,  3.0117e-02,  2.9818e-02,  2.9393e-02,  2.8799e-02,
         2.8007e-02,  2.8833e-02,  2.8072e-02,  2.7034e-02,  2.5670e-02,
         2.6120e-02,  2.5831e-02,  2.4086e-02,  2.1789e-02,  2.1254e-02,
         2.2100e-02,  2.1578e-02,  1.8521e-02,  1.4481e-02,  1.3545e-02,
         1.5056e-02,  1.4186e-02,  8.7238e-03,  7.4806e-03,  1.3891e-02,
         8.3673e-03,  7.1154e-03,  6.5328e-04,  6.5242e-04,  6.7248e-03,
         6.5087e-04,  6.5001e-04,  6.4915e-04,  6.4846e-04,  3.5628e-03,
         6.4657e-04,  6.4588e-04,  6.4502e-04,  1.6021e-03,  6.4347e-04,
         6.4244e-04,  6.4175e-04,  6.4089e-04,  4.4723e-03,  3.0206e-03,
         1.5097e-03,  6.3763e-04,  6.3694e-04,  7.0122e-03,  5.7008e-03,
         4.3375e-03,  8.4398e-03,  1.4305e-02,  1.3418e-02,  1.2500e-02,
         1.5226e-02,  1.4398e-02,  1.8555e-02,  2.0293e-02,  1.9766e-02,
         1.9192e-02,  2.0823e-02,  2.3176e-02,  2.4167e-02,  2.3839e-02,
         2.4716e-02,  2.5974e-02,  2.6488e-02,  2.6307e-02,  2.6751e-02,
         2.6579e-02,  2.7637e-02,  2.7828e-02,  2.7738e-02,  2.7900e-02,
         2.8020e-02,  2.8183e-02,  2.8216e-02,  2.8235e-02,  2.8233e-02,
         2.8189e-02,  2.8136e-02,  2.8119e-02,  2.8062e-02,  2.7998e-02,
         2.7820e-02,  2.7742e-02,  2.7660e-02,  2.7577e-02,  2.7368e-02,
         2.7285e-02,  2.7204e-02,  2.7122e-02,  2.6970e-02,  2.6782e-02,
         2.6709e-02,  2.6638e-02,  2.6568e-02,  2.6500e-02,  2.6293e-02,
         2.6233e-02,  2.6175e-02,  2.6075e-02,  2.5957e-02,  2.5907e-02,
         2.5825e-02,  2.5779e-02,  2.5705e-02,  2.5620e-02,  2.5557e-02,
         2.5519e-02,  2.5462e-02,  2.5426e-02,  2.5364e-02,  2.5340e-02,
         2.5271e-02,  2.5210e-02,  2.5188e-02,  2.5153e-02,  2.5130e-02,
         2.5081e-02,  2.5036e-02,  2.5014e-02,  2.4975e-02,  2.4939e-02,
         2.4917e-02,  2.4884e-02,  2.4869e-02,  2.4837e-02,  2.4807e-02,
         2.4786e-02,  2.4758e-02,  2.4737e-02,  2.4711e-02,  2.4685e-02,
         2.4665e-02,  2.4640e-02,  2.4618e-02,  2.4595e-02,  2.4572e-02,
         2.4551e-02,  2.4529e-02,  2.4508e-02,  2.4487e-02,  2.4465e-02,
         2.4445e-02,  2.4423e-02,  2.4403e-02,  2.4381e-02,  2.4361e-02,
         2.4341e-02,  2.4320e-02,  2.4299e-02,  2.4279e-02,  2.4258e-02,
         2.4238e-02,  2.4218e-02,  2.4198e-02,  2.4177e-02,  2.4157e-02,
         2.4137e-02,  2.4117e-02,  2.4097e-02,  2.4077e-02,  2.4057e-02,
         2.4037e-02,  2.4017e-02,  2.3997e-02,  2.3977e-02,  2.3957e-02,
         2.3938e-02,  2.3918e-02,  2.3898e-02,  2.3878e-02,  2.3859e-02,
         2.3839e-02,  2.3819e-02,  2.3800e-02,  2.3780e-02,  2.3761e-02,
         2.3741e-02,  2.3721e-02,  2.3702e-02,  2.3682e-02,  2.3663e-02],
       device='cuda:0')
Selected points (indices): {356}
Selected new x values (normalized): tensor([0.3564], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-574.5746], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter6/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:36:20 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_6 [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		M_1: [-574.57]               [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:36:20 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:36:21 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:36:21 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:36:21 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:36:21 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:36:21 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:36:21 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:36:21 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:36:21 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:36:21 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:36:21 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_6, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:36:21 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:36:21 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_6/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 6
Starting iteration 7
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843, 0.1041, 0.5812,
        0.8528], device='cuda:0') torch.Size([10])
These training_points are used in the GP tensor([0.3564, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843, 0.1041, 0.5812,
        0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[1.0000e-06],
        [1.0000e-06],
        [6.2037e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.0776e-02],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.8662e-01],
        [1.0000e-06],
        [9.4929e-02],
        [1.0000e-06],
        [1.0000e-06],
        [2.9785e-01],
        [9.1450e-02],
        [1.8757e-01],
        [1.0000e-06],
        [2.5579e-01],
        [1.0000e-06],
        [1.0581e-01],
        [3.5952e-01],
        [1.4786e-01],
        [2.0515e-01],
        [1.0000e-06],
        [2.1783e-01],
        [4.2219e-01],
        [2.1502e-01],
        [2.4500e-01],
        [1.0000e-06],
        [2.1863e-01],
        [1.0000e-06],
        [1.7599e-01],
        [3.6565e-01],
        [1.1471e-01],
        [3.1079e-01],
        [3.1313e-02],
        [2.3753e-01],
        [3.9630e-01],
        [1.4163e-01],
        [3.1330e-01],
        [1.7588e-02],
        [2.0649e-01],
        [1.0000e-06],
        [6.9905e-02],
        [2.3895e-01],
        [1.0000e-06],
        [9.0397e-02],
        [1.0000e-06],
        [1.0000e-06],
        [8.7931e-02],
        [4.6596e-03],
        [1.3388e-01],
        [8.0835e-03],
        [6.3368e-03],
        [9.3420e-03],
        [7.9862e-03],
        [1.4301e-01],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.3266e-01],
        [1.0000e-06],
        [1.5712e-01],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.0000e-06],
        [1.1551e-01],
        [1.0000e-06],
        [1.2178e-01],
        [1.0000e-06],
        [1.1833e-01],
        [2.3514e-01],
        [1.0222e-01],
        [2.1320e-01],
        [6.9590e-02],
        [1.7459e-01],
        [1.5430e-02],
        [1.1426e-01],
        [3.7519e-01],
        [2.5662e-02],
        [3.0180e-01],
        [1.4488e-01],
        [1.9961e-01],
        [4.1274e-01],
        [6.0058e-02],
        [3.0073e-01],
        [1.2288e-01],
        [1.5082e-01],
        [1.0000e-06],
        [1.8499e-01],
        [1.9960e-01],
        [1.0000e-06],
        [2.1654e-01],
        [1.0000e-06],
        [5.0948e-03],
        [2.2993e-01],
        [1.1425e-02],
        [2.3258e-01],
        [2.6885e-03],
        [1.2615e-02],
        [8.4053e-03],
        [1.1573e-02],
        [1.1563e-02],
        [1.1526e-02],
        [1.1904e-01],
        [1.1595e-01],
        [8.3398e-03],
        [6.6029e-03],
        [4.4732e-03],
        [1.8988e-03],
        [2.0136e-01],
        [1.9641e-01],
        [1.9085e-01],
        [1.8457e-01],
        [1.7740e-01],
        [1.6915e-01],
        [3.4514e-01],
        [3.3613e-01],
        [3.2553e-01],
        [3.1297e-01],
        [2.9804e-01],
        [3.6550e-01],
        [4.8924e-01],
        [4.7100e-01],
        [4.4909e-01],
        [4.9124e-01],
        [4.6320e-01],
        [4.2941e-01],
        [5.7541e-01],
        [5.4032e-01],
        [5.5767e-01],
        [5.1260e-01],
        [5.2256e-01],
        [5.7430e-01],
        [5.7517e-01],
        [5.1505e-01],
        [5.0874e-01],
        [4.3160e-01],
        [4.1700e-01],
        [5.1798e-01],
        [4.3292e-01],
        [4.0981e-01],
        [3.8370e-01],
        [3.5461e-01],
        [2.3152e-01],
        [3.4905e-01],
        [3.1389e-01],
        [2.7585e-01],
        [2.3484e-01],
        [1.9077e-01],
        [1.4351e-01],
        [2.6847e-01],
        [2.2474e-01],
        [1.7809e-01],
        [1.2836e-01],
        [7.5389e-02],
        [1.9003e-02],
        [1.6000e-01],
        [1.0841e-01],
        [5.3547e-02],
        [1.1397e-01],
        [5.9220e-02],
        [1.0992e-02],
        [1.4372e-01],
        [1.9797e-01],
        [1.4784e-01],
        [9.4396e-02],
        [1.5116e-01],
        [9.7366e-02],
        [3.1662e-01],
        [2.7247e-01],
        [3.1672e-01],
        [2.7148e-01],
        [3.1454e-01],
        [2.6751e-01],
        [4.4168e-01],
        [4.0106e-01],
        [4.3242e-01],
        [4.6067e-01],
        [4.8587e-01],
        [4.4172e-01],
        [5.6489e-01],
        [5.7912e-01],
        [5.9039e-01],
        [5.4434e-01],
        [5.4998e-01],
        [5.5177e-01],
        [6.3141e-01],
        [6.2517e-01],
        [6.1497e-01],
        [6.0044e-01],
        [5.8116e-01],
        [5.5663e-01],
        [6.0763e-01],
        [5.7632e-01],
        [5.3893e-01],
        [5.5477e-01],
        [5.0895e-01],
        [4.5548e-01],
        [4.9329e-01],
        [4.3269e-01],
        [4.3834e-01],
        [3.6732e-01],
        [2.8572e-01],
        [2.8772e-01],
        [3.2357e-01],
        [2.3240e-01],
        [2.3126e-01],
        [1.2606e-01],
        [1.2338e-01],
        [4.2036e-03],
        [1.5923e-01],
        [4.2165e-02],
        [3.7540e-02],
        [3.2668e-02],
        [1.0050e-02],
        [1.0620e-02],
        [1.1193e-02],
        [1.1458e-02],
        [1.1637e-02],
        [1.1743e-02],
        [1.1749e-02],
        [1.1662e-02],
        [1.7342e-02],
        [1.1271e-02],
        [1.0767e-02],
        [1.0154e-02],
        [9.3233e-03],
        [8.2201e-03],
        [8.5797e-02],
        [7.8829e-02],
        [7.1378e-02],
        [1.2044e-01],
        [1.1220e-01],
        [1.0311e-01],
        [2.3772e-01],
        [2.7505e-01],
        [2.6454e-01],
        [2.9811e-01],
        [2.8494e-01],
        [3.1415e-01],
        [4.4400e-01],
        [4.2755e-01],
        [4.4417e-01],
        [4.5751e-01],
        [4.6740e-01],
        [4.7364e-01],
        [5.5543e-01],
        [5.5309e-01],
        [5.4681e-01],
        [5.3622e-01],
        [5.2088e-01],
        [5.0030e-01],
        [5.4854e-01],
        [5.4886e-01],
        [5.1550e-01],
        [4.7545e-01],
        [4.6288e-01],
        [4.4626e-01],
        [4.7005e-01],
        [4.4682e-01],
        [3.8217e-01],
        [3.4966e-01],
        [3.1317e-01],
        [2.7259e-01],
        [3.2801e-01],
        [2.8492e-01],
        [2.3786e-01],
        [1.8665e-01],
        [1.3107e-01],
        [7.0881e-02],
        [1.3340e-01],
        [7.2032e-02],
        [6.6471e-02],
        [8.7880e-03],
        [9.7144e-03],
        [5.8266e-02],
        [5.1520e-02],
        [1.1363e-02],
        [1.1580e-02],
        [1.1675e-02],
        [1.1750e-02],
        [2.6199e-02],
        [1.8686e-02],
        [1.1565e-02],
        [1.1428e-02],
        [1.1259e-02],
        [1.1058e-02],
        [1.1015e-01],
        [1.0309e-01],
        [9.5918e-02],
        [8.8628e-02],
        [1.3722e-01],
        [1.3009e-01],
        [2.3493e-01],
        [2.7542e-01],
        [2.6897e-01],
        [3.0728e-01],
        [3.4334e-01],
        [3.9973e-01],
        [4.1205e-01],
        [4.4155e-01],
        [4.8810e-01],
        [5.1261e-01],
        [5.3518e-01],
        [5.8491e-01],
        [6.0222e-01],
        [6.1760e-01],
        [6.5481e-01],
        [6.7561e-01],
        [6.8349e-01],
        [7.1780e-01],
        [7.2910e-01],
        [7.2902e-01],
        [7.5071e-01],
        [7.5282e-01],
        [7.5183e-01],
        [7.6938e-01],
        [7.6192e-01],
        [7.5094e-01],
        [7.5791e-01],
        [7.4822e-01],
        [7.2665e-01],
        [7.2413e-01],
        [7.0424e-01],
        [6.8056e-01],
        [6.6930e-01],
        [6.4982e-01],
        [6.1558e-01],
        [5.9607e-01],
        [5.6756e-01],
        [5.3599e-01],
        [5.0855e-01],
        [4.7086e-01],
        [4.2964e-01],
        [4.1234e-01],
        [3.8519e-01],
        [3.3581e-01],
        [3.1429e-01],
        [2.8162e-01],
        [2.4719e-01],
        [2.2206e-01],
        [1.8446e-01],
        [1.4494e-01],
        [1.4338e-01],
        [1.0171e-01],
        [5.7964e-02],
        [8.5268e-02],
        [4.0644e-02],
        [2.4967e-02],
        [2.2885e-02],
        [1.1748e-02],
        [3.5533e-02],
        [1.9715e-02],
        [1.1766e-02],
        [3.2356e-02],
        [4.6915e-02],
        [3.1267e-02],
        [7.3870e-02],
        [7.3347e-02],
        [8.7289e-02],
        [1.2744e-01],
        [1.4058e-01],
        [1.5352e-01],
        [2.0341e-01],
        [2.2767e-01],
        [2.5119e-01],
        [2.9537e-01],
        [3.2753e-01],
        [3.4804e-01],
        [3.9615e-01],
        [4.2375e-01],
        [4.5010e-01],
        [4.9874e-01],
        [5.2170e-01],
        [5.5078e-01],
        [5.9705e-01],
        [6.2161e-01],
        [6.4469e-01],
        [6.8141e-01],
        [7.0563e-01],
        [7.2804e-01],
        [7.6016e-01],
        [7.7850e-01],
        [7.9548e-01],
        [8.2268e-01],
        [8.3899e-01],
        [8.5384e-01],
        [8.7350e-01],
        [8.8716e-01],
        [8.9772e-01],
        [9.1317e-01],
        [9.2273e-01],
        [9.3246e-01],
        [9.4295e-01],
        [9.5032e-01],
        [9.5682e-01],
        [9.6448e-01],
        [9.6933e-01],
        [9.7458e-01],
        [9.7867e-01],
        [9.8276e-01],
        [9.8623e-01],
        [9.8894e-01],
        [9.9160e-01],
        [9.9393e-01],
        [9.9566e-01],
        [9.9733e-01],
        [9.9879e-01],
        [9.9986e-01],
        [1.0009e+00],
        [1.0018e+00],
        [1.0025e+00],
        [1.0031e+00],
        [1.0036e+00],
        [1.0040e+00],
        [1.0044e+00],
        [1.0047e+00],
        [1.0049e+00],
        [1.0051e+00],
        [1.0052e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0054e+00],
        [1.0053e+00],
        [1.0052e+00],
        [1.0050e+00],
        [1.0048e+00],
        [1.0046e+00],
        [1.0042e+00],
        [1.0039e+00],
        [1.0034e+00],
        [1.0029e+00],
        [1.0022e+00],
        [1.0015e+00],
        [1.0006e+00],
        [9.9951e-01],
        [9.9822e-01],
        [9.9676e-01],
        [9.9506e-01],
        [9.9299e-01],
        [9.9068e-01],
        [9.8801e-01],
        [9.8481e-01],
        [9.8127e-01],
        [9.7726e-01],
        [9.7247e-01],
        [9.6724e-01],
        [9.6137e-01],
        [9.5438e-01],
        [9.4691e-01],
        [9.3861e-01],
        [9.2880e-01],
        [9.1847e-01],
        [9.0715e-01],
        [8.9408e-01],
        [8.8033e-01],
        [8.6544e-01],
        [8.4808e-01],
        [8.3040e-01],
        [8.1150e-01],
        [7.8960e-01],
        [7.6664e-01],
        [7.4462e-01],
        [7.1801e-01],
        [6.8993e-01],
        [6.6486e-01],
        [6.3451e-01],
        [6.0304e-01],
        [5.7446e-01],
        [5.3972e-01],
        [5.0415e-01],
        [4.7481e-01],
        [4.3873e-01],
        [4.0257e-01],
        [3.7226e-01],
        [3.3449e-01],
        [2.9723e-01],
        [2.7031e-01],
        [2.3553e-01],
        [2.0226e-01],
        [1.7822e-01],
        [1.4919e-01],
        [1.1915e-01],
        [9.9723e-02],
        [7.5242e-02],
        [5.0100e-02],
        [4.4307e-02],
        [2.6015e-02],
        [1.5144e-02],
        [1.6897e-02],
        [1.1768e-02],
        [1.1768e-02],
        [1.2268e-02],
        [1.6821e-02],
        [2.1354e-02],
        [3.8332e-02],
        [5.0261e-02],
        [6.2043e-02],
        [9.2700e-02],
        [1.1098e-01],
        [1.3571e-01],
        [1.7053e-01],
        [1.9362e-01],
        [2.2222e-01],
        [2.5943e-01],
        [2.9132e-01],
        [3.2184e-01],
        [3.5939e-01],
        [3.9182e-01],
        [4.3453e-01],
        [4.6048e-01],
        [4.9841e-01],
        [5.3370e-01],
        [5.6214e-01],
        [5.9300e-01],
        [6.2767e-01],
        [6.5045e-01],
        [6.8534e-01],
        [7.1226e-01],
        [7.3422e-01],
        [7.6089e-01],
        [7.8494e-01],
        [8.0147e-01],
        [8.2440e-01],
        [8.4475e-01],
        [8.5912e-01],
        [8.7558e-01],
        [8.9019e-01],
        [9.0214e-01],
        [9.1521e-01],
        [9.2663e-01],
        [9.3481e-01],
        [9.4376e-01],
        [9.5243e-01],
        [9.5869e-01],
        [9.6528e-01],
        [9.7094e-01],
        [9.7552e-01],
        [9.8016e-01],
        [9.8375e-01],
        [9.8695e-01],
        [9.8984e-01],
        [9.9230e-01],
        [9.9426e-01],
        [9.9619e-01],
        [9.9780e-01],
        [9.9908e-01],
        [1.0002e+00],
        [1.0012e+00],
        [1.0020e+00],
        [1.0027e+00],
        [1.0032e+00],
        [1.0037e+00],
        [1.0041e+00],
        [1.0045e+00],
        [1.0047e+00],
        [1.0049e+00],
        [1.0051e+00],
        [1.0053e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0057e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0057e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0055e+00],
        [1.0054e+00],
        [1.0053e+00],
        [1.0052e+00],
        [1.0049e+00],
        [1.0047e+00],
        [1.0044e+00],
        [1.0042e+00],
        [1.0038e+00],
        [1.0036e+00],
        [1.0026e+00],
        [1.0017e+00],
        [1.0012e+00],
        [1.0007e+00],
        [9.9930e-01],
        [9.9852e-01],
        [9.9558e-01],
        [9.9436e-01],
        [9.9299e-01],
        [9.8954e-01],
        [9.8760e-01],
        [9.8543e-01],
        [9.7730e-01],
        [9.7391e-01],
        [9.7011e-01],
        [9.6587e-01],
        [9.6112e-01],
        [9.5581e-01],
        [9.3591e-01],
        [9.2762e-01],
        [9.1833e-01],
        [9.1946e-01],
        [9.0921e-01],
        [8.9774e-01],
        [8.5478e-01],
        [8.5672e-01],
        [8.3903e-01],
        [8.1925e-01],
        [7.9711e-01],
        [7.9980e-01],
        [7.1793e-01],
        [7.2163e-01],
        [6.8792e-01],
        [6.9201e-01],
        [6.5479e-01],
        [6.5930e-01],
        [5.2164e-01],
        [5.2786e-01],
        [4.7118e-01],
        [4.7805e-01],
        [4.8484e-01],
        [4.2305e-01],
        [2.8723e-01],
        [2.9647e-01],
        [3.0559e-01],
        [2.2254e-01],
        [2.3261e-01],
        [2.4256e-01],
        [6.4674e-02],
        [7.6775e-02],
        [8.8720e-02],
        [1.0051e-01],
        [1.1215e-01],
        [1.2364e-01],
        [1.1768e-02],
        [1.1768e-02],
        [1.1768e-02],
        [1.1768e-02],
        [1.1768e-02],
        [1.1768e-02],
        [1.1768e-02],
        [1.1768e-02],
        [1.1768e-02],
        [1.1768e-02],
        [1.1768e-02],
        [8.8048e-02],
        [1.1768e-02],
        [1.1768e-02],
        [3.2661e-02],
        [4.5173e-02],
        [1.6896e-01],
        [1.7972e-01],
        [1.0690e-01],
        [1.1846e-01],
        [2.3280e-01],
        [2.4274e-01],
        [3.4107e-01],
        [1.8615e-01],
        [2.9177e-01],
        [3.8379e-01],
        [3.9179e-01],
        [4.7091e-01],
        [5.3985e-01],
        [4.9877e-01],
        [5.0529e-01],
        [5.6979e-01],
        [6.2598e-01],
        [6.7493e-01],
        [7.1758e-01],
        [6.9217e-01],
        [7.3259e-01],
        [7.6781e-01],
        [7.9848e-01],
        [8.2521e-01],
        [8.4849e-01],
        [8.3462e-01],
        [8.5669e-01],
        [8.7591e-01],
        [8.9266e-01],
        [9.1884e-01],
        [9.3006e-01],
        [9.2338e-01],
        [9.3401e-01],
        [9.5063e-01],
        [9.4576e-01],
        [9.6396e-01],
        [9.6026e-01],
        [9.8111e-01],
        [9.7893e-01],
        [9.8709e-01],
        [9.8543e-01],
        [9.8855e-01],
        [9.9380e-01],
        [9.9273e-01],
        [9.9672e-01],
        [9.9812e-01],
        [9.9743e-01],
        [1.0000e+00],
        [1.0009e+00],
        [1.0024e+00],
        [1.0021e+00],
        [1.0038e+00],
        [1.0037e+00],
        [1.0040e+00],
        [1.0046e+00],
        [1.0045e+00],
        [1.0051e+00],
        [1.0050e+00],
        [1.0052e+00],
        [1.0054e+00],
        [1.0055e+00],
        [1.0056e+00],
        [1.0056e+00],
        [1.0057e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0058e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00],
        [1.0059e+00]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([-4.6432e-02, -8.0551e-02,  2.2047e-02, -1.1781e-02, -5.4605e-03,
         2.7813e-03, -4.2294e-02, -8.7247e-03, -2.6558e-03,  4.5779e-02,
        -9.8555e-04,  2.4710e-02, -6.6463e-04, -2.1248e-03,  5.2348e-02,
         1.9606e-02,  3.3945e-02, -9.8590e-03,  3.9218e-02, -1.9601e-02,
         1.6593e-02,  4.3529e-02,  2.0063e-02,  2.5200e-02, -7.0886e-03,
         2.4111e-02,  3.9889e-02,  2.1785e-02,  2.3333e-02, -3.3746e-03,
         1.9544e-02, -7.4292e-03,  1.4970e-02,  2.8397e-02,  9.3440e-03,
         2.3386e-02,  2.4808e-03,  1.7469e-02,  2.7663e-02,  1.0286e-02,
         2.1654e-02,  1.2873e-03,  1.4225e-02, -7.3997e-03,  4.8436e-03,
         1.6014e-02, -2.8118e-03,  6.1264e-03, -2.4466e-03, -4.3615e-04,
         5.9320e-03,  3.1060e-04,  8.9220e-03,  5.3641e-04,  4.6177e-04,
         6.0306e-04,  5.2188e-04,  9.5712e-03, -6.5439e-05, -1.1887e-03,
        -4.3684e-04, -1.9158e-03,  8.9127e-03, -3.0075e-03,  1.0543e-02,
        -4.8736e-03, -3.9975e-03, -7.0701e-03, -2.5541e-03,  7.7663e-03,
        -1.6781e-03,  8.1175e-03, -1.4749e-03,  7.8717e-03,  1.5281e-02,
         6.7207e-03,  1.3772e-02,  4.5652e-03,  1.1195e-02,  1.0193e-03,
         7.2629e-03,  2.2876e-02,  1.6270e-03,  1.8307e-02,  8.8721e-03,
         1.2024e-02,  2.4105e-02,  3.6050e-03,  1.7464e-02,  7.1911e-03,
         8.7047e-03, -4.2094e-03,  1.0511e-02,  1.1213e-02, -1.1020e-03,
         1.1994e-02, -7.4898e-05,  2.9383e-04,  1.2490e-02,  6.2223e-04,
         1.2510e-02,  1.5220e-04,  6.8965e-04,  4.4337e-04,  6.0306e-04,
         6.0718e-04,  6.1862e-04,  6.2514e-03,  6.0503e-03,  4.3408e-04,
         3.6211e-04,  2.3536e-04,  7.7392e-05,  1.0365e-02,  1.0086e-02,
         9.7942e-03,  9.4369e-03,  9.0760e-03,  8.6524e-03,  1.7556e-02,
         1.7091e-02,  1.6543e-02,  1.5911e-02,  1.5136e-02,  1.8545e-02,
         2.4785e-02,  2.3870e-02,  2.2783e-02,  2.4922e-02,  2.3539e-02,
         2.1864e-02,  2.9237e-02,  2.7517e-02,  2.8428e-02,  2.6206e-02,
         2.6744e-02,  2.9403e-02,  2.9486e-02,  2.6514e-02,  2.6245e-02,
         2.2378e-02,  2.1686e-02,  2.6812e-02,  2.2562e-02,  2.1414e-02,
         2.0096e-02,  1.8612e-02,  1.2264e-02,  1.8358e-02,  1.6560e-02,
         1.4597e-02,  1.2467e-02,  1.0162e-02,  7.6991e-03,  1.4234e-02,
         1.1949e-02,  9.5205e-03,  6.8691e-03,  4.0549e-03,  1.0182e-03,
         8.5407e-03,  5.8061e-03,  2.9081e-03,  6.1146e-03,  3.1866e-03,
         6.0718e-04,  7.6942e-03,  1.0551e-02,  7.9071e-03,  5.0678e-03,
         8.0951e-03,  5.2243e-03,  1.6702e-02,  1.4442e-02,  1.6723e-02,
         1.4418e-02,  1.6648e-02,  1.4237e-02,  2.3146e-02,  2.1121e-02,
         2.2756e-02,  2.4179e-02,  2.5498e-02,  2.3336e-02,  2.9450e-02,
         3.0204e-02,  3.0790e-02,  2.8644e-02,  2.8965e-02,  2.9105e-02,
         3.2977e-02,  3.2732e-02,  3.2290e-02,  3.1638e-02,  3.0748e-02,
         2.9595e-02,  3.2037e-02,  3.0554e-02,  2.8749e-02,  2.9493e-02,
         2.7238e-02,  2.4579e-02,  2.6412e-02,  2.3359e-02,  2.3617e-02,
         2.0001e-02,  1.5721e-02,  1.5807e-02,  1.7628e-02,  1.2824e-02,
         1.2751e-02,  7.0173e-03,  6.8847e-03,  2.3725e-04,  8.7797e-03,
         2.3711e-03,  2.1168e-03,  1.8212e-03,  5.7081e-04,  5.8079e-04,
         6.3014e-04,  6.4450e-04,  6.4382e-04,  6.4485e-04,  6.5620e-04,
         6.4124e-04,  9.3387e-04,  6.1484e-04,  5.8723e-04,  5.6032e-04,
         4.9230e-04,  4.3322e-04,  4.5160e-03,  4.1671e-03,  3.7429e-03,
         6.2442e-03,  5.7847e-03,  5.3038e-03,  1.1951e-02,  1.3699e-02,
         1.3104e-02,  1.4608e-02,  1.3865e-02,  1.5142e-02,  2.0960e-02,
         2.0035e-02,  2.0619e-02,  2.1024e-02,  2.1261e-02,  2.1312e-02,
         2.4628e-02,  2.4292e-02,  2.3772e-02,  2.3070e-02,  2.2183e-02,
         2.1081e-02,  2.2873e-02,  2.2676e-02,  2.1080e-02,  1.9235e-02,
         1.8560e-02,  1.7738e-02,  1.8544e-02,  1.7485e-02,  1.4799e-02,
         1.3424e-02,  1.1930e-02,  1.0291e-02,  1.2359e-02,  1.0656e-02,
         8.8335e-03,  6.8905e-03,  4.7920e-03,  2.5686e-03,  4.8441e-03,
         2.5957e-03,  2.3725e-03,  3.1989e-04,  3.5153e-04,  2.0813e-03,
         1.8170e-03,  4.0003e-04,  4.0020e-04,  4.0863e-04,  4.0227e-04,
         9.0669e-04,  6.3900e-04,  4.0382e-04,  3.8602e-04,  3.8309e-04,
         3.7862e-04,  3.7834e-03,  3.5373e-03,  3.2578e-03,  3.0075e-03,
         4.6483e-03,  4.3874e-03,  7.9333e-03,  9.2992e-03,  9.0174e-03,
         1.0278e-02,  1.1446e-02,  1.3337e-02,  1.3651e-02,  1.4565e-02,
         1.6070e-02,  1.6783e-02,  1.7415e-02,  1.9021e-02,  1.9440e-02,
         1.9762e-02,  2.0902e-02,  2.1421e-02,  2.1430e-02,  2.2477e-02,
         2.2625e-02,  2.2313e-02,  2.2886e-02,  2.2681e-02,  2.2368e-02,
         2.2848e-02,  2.2297e-02,  2.1638e-02,  2.1752e-02,  2.1207e-02,
         2.0218e-02,  2.0024e-02,  1.9186e-02,  1.8244e-02,  1.7799e-02,
         1.7077e-02,  1.5887e-02,  1.5228e-02,  1.4310e-02,  1.3323e-02,
         1.2496e-02,  1.1391e-02,  1.0232e-02,  9.7626e-03,  9.0275e-03,
         7.7357e-03,  7.1851e-03,  6.3664e-03,  5.5321e-03,  4.9238e-03,
         4.0522e-03,  3.1391e-03,  3.1064e-03,  2.1797e-03,  1.2325e-03,
         1.8094e-03,  8.5106e-04,  5.2635e-04,  4.8714e-04,  2.4344e-04,
         7.5371e-04,  4.0777e-04,  2.4516e-04,  6.7271e-04,  9.8752e-04,
         6.5173e-04,  1.5557e-03,  1.5443e-03,  1.8477e-03,  2.7288e-03,
         3.0112e-03,  3.3122e-03,  4.4447e-03,  4.9989e-03,  5.5609e-03,
         6.6280e-03,  7.4115e-03,  7.9294e-03,  9.1631e-03,  9.8987e-03,
         1.0613e-02,  1.1967e-02,  1.2625e-02,  1.3474e-02,  1.4900e-02,
         1.5678e-02,  1.6431e-02,  1.7672e-02,  1.8524e-02,  1.9333e-02,
         2.0555e-02,  2.1275e-02,  2.1964e-02,  2.3133e-02,  2.3857e-02,
         2.4542e-02,  2.5504e-02,  2.6203e-02,  2.6758e-02,  2.7625e-02,
         2.8183e-02,  2.8782e-02,  2.9466e-02,  2.9970e-02,  3.0434e-02,
         3.1024e-02,  3.1410e-02,  3.1856e-02,  3.2221e-02,  3.2612e-02,
         3.2965e-02,  3.3252e-02,  3.3556e-02,  3.3842e-02,  3.4061e-02,
         3.4292e-02,  3.4507e-02,  3.4671e-02,  3.4849e-02,  3.5006e-02,
         3.5130e-02,  3.5257e-02,  3.5367e-02,  3.5452e-02,  3.5538e-02,
         3.5615e-02,  3.5669e-02,  3.5723e-02,  3.5770e-02,  3.5801e-02,
         3.5832e-02,  3.5856e-02,  3.5870e-02,  3.5882e-02,  3.5889e-02,
         3.5888e-02,  3.5886e-02,  3.5880e-02,  3.5869e-02,  3.5856e-02,
         3.5841e-02,  3.5822e-02,  3.5802e-02,  3.5780e-02,  3.5755e-02,
         3.5729e-02,  3.5702e-02,  3.5674e-02,  3.5644e-02,  3.5614e-02,
         3.5582e-02,  3.5550e-02,  3.5517e-02,  3.5484e-02,  3.5450e-02,
         3.5416e-02,  3.5381e-02,  3.5346e-02,  3.5311e-02,  3.5275e-02,
         3.5240e-02,  3.5204e-02,  3.5168e-02,  3.5132e-02,  3.5096e-02,
         3.5059e-02,  3.5023e-02,  3.4987e-02,  3.4950e-02,  3.4914e-02,
         3.4877e-02,  3.4841e-02,  3.4805e-02,  3.4768e-02,  3.4732e-02,
         3.4695e-02,  3.4659e-02,  3.4623e-02,  3.4586e-02,  3.4550e-02,
         3.4513e-02,  3.4477e-02,  3.4440e-02,  3.4403e-02,  3.4367e-02,
         3.4330e-02,  3.4293e-02,  3.4256e-02,  3.4218e-02,  3.4181e-02,
         3.4143e-02,  3.4104e-02,  3.4066e-02,  3.4027e-02,  3.3988e-02,
         3.3948e-02,  3.3907e-02,  3.3866e-02,  3.3823e-02,  3.3780e-02,
         3.3736e-02,  3.3691e-02,  3.3644e-02,  3.3596e-02,  3.3546e-02,
         3.2294e-02,  3.2168e-02,  3.2032e-02,  3.1887e-02,  3.1733e-02,
         3.1566e-02,  3.1388e-02,  3.1199e-02,  3.0995e-02,  3.0776e-02,
         3.0545e-02,  3.0291e-02,  3.0028e-02,  2.9749e-02,  2.9440e-02,
         2.9122e-02,  2.8783e-02,  2.8412e-02,  2.8032e-02,  2.7631e-02,
         2.7189e-02,  2.6741e-02,  2.6270e-02,  2.5750e-02,  2.5228e-02,
         2.4685e-02,  2.4084e-02,  2.3489e-02,  2.2876e-02,  2.2206e-02,
         2.1543e-02,  2.0861e-02,  2.0114e-02,  1.9387e-02,  1.8651e-02,
         1.7841e-02,  1.7033e-02,  1.6291e-02,  1.5438e-02,  1.4578e-02,
         1.3845e-02,  1.2992e-02,  1.2141e-02,  1.1402e-02,  1.0535e-02,
         9.6793e-03,  8.9944e-03,  8.1817e-03,  7.4018e-03,  6.7616e-03,
         5.9867e-03,  5.2462e-03,  4.7229e-03,  4.0656e-03,  3.4501e-03,
         3.0112e-03,  2.5015e-03,  1.9779e-03,  1.6449e-03,  1.2266e-03,
         8.1675e-04,  7.2181e-04,  4.2342e-04,  2.3536e-04,  2.6632e-04,
         1.8806e-04,  1.8789e-04,  2.0337e-04,  2.6563e-04,  3.4345e-04,
         6.1587e-04,  8.1004e-04,  9.9664e-04,  1.5098e-03,  1.8130e-03,
         2.2326e-03,  2.8392e-03,  3.2430e-03,  3.7480e-03,  4.4248e-03,
         5.0225e-03,  5.5974e-03,  6.3282e-03,  6.9793e-03,  7.8574e-03,
         8.4126e-03,  9.2410e-03,  1.0043e-02,  1.0705e-02,  1.1443e-02,
         1.2310e-02,  1.2896e-02,  1.3834e-02,  1.4584e-02,  1.5223e-02,
         1.6030e-02,  1.6791e-02,  1.7332e-02,  1.8121e-02,  1.8858e-02,
         1.9396e-02,  2.0048e-02,  2.0655e-02,  2.1172e-02,  2.1772e-02,
         2.2324e-02,  2.2738e-02,  2.3216e-02,  2.3708e-02,  2.4080e-02,
         2.4497e-02,  2.4878e-02,  2.5202e-02,  2.5555e-02,  2.5843e-02,
         2.6115e-02,  2.6380e-02,  2.6618e-02,  2.6819e-02,  2.7034e-02,
         2.7225e-02,  2.7386e-02,  2.7539e-02,  2.7688e-02,  2.7800e-02,
         2.7928e-02,  2.8020e-02,  2.8104e-02,  2.8191e-02,  2.8265e-02,
         2.8318e-02,  2.8373e-02,  2.8429e-02,  2.8459e-02,  2.8499e-02,
         2.8517e-02,  2.8543e-02,  2.8563e-02,  2.8573e-02,  2.8582e-02,
         2.8588e-02,  2.8590e-02,  2.8588e-02,  2.8583e-02,  2.8576e-02,
         2.8568e-02,  2.8556e-02,  2.8542e-02,  2.8528e-02,  2.8512e-02,
         2.8495e-02,  2.8477e-02,  2.8457e-02,  2.8437e-02,  2.8416e-02,
         2.8394e-02,  2.8372e-02,  2.8349e-02,  2.8325e-02,  2.8301e-02,
         2.8277e-02,  2.8253e-02,  2.8228e-02,  2.8203e-02,  2.8177e-02,
         2.8152e-02,  2.8126e-02,  2.8101e-02,  2.8075e-02,  2.8049e-02,
         2.8023e-02,  2.7997e-02,  2.7971e-02,  2.7945e-02,  2.7919e-02,
         2.7893e-02,  2.7867e-02,  2.7841e-02,  2.7815e-02,  2.7789e-02,
         2.7763e-02,  2.7737e-02,  2.7711e-02,  2.7685e-02,  2.7659e-02,
         2.7633e-02,  2.7607e-02,  2.7582e-02,  2.7556e-02,  2.7530e-02,
         2.7504e-02,  2.7479e-02,  2.7453e-02,  2.7428e-02,  2.7402e-02,
         2.7376e-02,  2.7351e-02,  2.7325e-02,  2.7300e-02,  2.7274e-02,
         2.7249e-02,  2.7224e-02,  2.7198e-02,  2.7173e-02,  2.7148e-02,
         2.7123e-02,  2.7098e-02,  2.7072e-02,  2.7047e-02,  2.7022e-02,
         2.6997e-02,  2.6972e-02,  2.6947e-02,  2.6923e-02,  2.6898e-02,
         2.6873e-02,  2.6848e-02,  2.6823e-02,  2.6798e-02,  2.6774e-02,
         2.6749e-02,  2.6724e-02,  2.6700e-02,  2.6675e-02,  2.6651e-02,
         2.6627e-02,  2.6602e-02,  2.6578e-02,  2.6554e-02,  2.6530e-02,
         2.6505e-02,  2.6481e-02,  2.6457e-02,  2.6433e-02,  2.6410e-02,
         2.6386e-02,  2.6363e-02,  2.6339e-02,  2.6316e-02,  2.6293e-02,
         2.6270e-02,  2.6249e-02,  2.6227e-02,  2.6204e-02,  2.6182e-02,
         2.6161e-02,  2.6140e-02,  2.6121e-02,  2.6101e-02,  2.6081e-02,
         2.6063e-02,  2.6044e-02,  2.6026e-02,  2.6015e-02,  2.5999e-02,
         2.5984e-02,  2.5970e-02,  2.5954e-02,  2.5943e-02,  2.5947e-02,
         2.5940e-02,  2.5930e-02,  2.5928e-02,  2.5921e-02,  2.5922e-02,
         2.5948e-02,  2.5959e-02,  2.5952e-02,  2.5969e-02,  2.5991e-02,
         2.5990e-02,  2.6075e-02,  2.6081e-02,  2.6126e-02,  2.6137e-02,
         2.6194e-02,  2.6211e-02,  2.6323e-02,  2.6407e-02,  2.6438e-02,
         2.6471e-02,  2.6578e-02,  2.6619e-02,  2.6808e-02,  2.6861e-02,
         2.6916e-02,  2.7070e-02,  2.7133e-02,  2.7198e-02,  2.7457e-02,
         2.7529e-02,  2.7601e-02,  2.7673e-02,  2.7744e-02,  2.7812e-02,
         2.8045e-02,  2.8089e-02,  2.8121e-02,  2.8087e-02,  2.8110e-02,
         2.8112e-02,  2.8021e-02,  2.8002e-02,  2.7888e-02,  2.7722e-02,
         2.7498e-02,  2.7495e-02,  2.6420e-02,  2.6448e-02,  2.5868e-02,
         2.5902e-02,  2.5185e-02,  2.5249e-02,  2.1989e-02,  2.2128e-02,
         2.0487e-02,  2.0663e-02,  2.0836e-02,  1.8904e-02,  1.3952e-02,
         1.4295e-02,  1.4630e-02,  1.1195e-02,  1.1609e-02,  1.2013e-02,
         3.5476e-03,  4.1868e-03,  4.7863e-03,  5.3966e-03,  5.9689e-03,
         6.5279e-03,  6.6033e-04,  6.5964e-04,  6.5861e-04,  6.5775e-04,
         6.5689e-04,  6.5586e-04,  6.5517e-04,  6.5431e-04,  6.5328e-04,
         6.5242e-04,  6.5156e-04,  4.6692e-03,  6.4966e-04,  6.4880e-04,
         1.8007e-03,  2.4594e-03,  8.4949e-03,  8.9644e-03,  5.5439e-03,
         6.0947e-03,  1.1225e-02,  1.1616e-02,  1.5368e-02,  9.1693e-03,
         1.3498e-02,  1.6788e-02,  1.7037e-02,  1.9471e-02,  2.1327e-02,
         2.0211e-02,  2.0369e-02,  2.1999e-02,  2.3211e-02,  2.4133e-02,
         2.4829e-02,  2.4381e-02,  2.4993e-02,  2.5438e-02,  2.5751e-02,
         2.5959e-02,  2.6085e-02,  2.5975e-02,  2.6073e-02,  2.6118e-02,
         2.6117e-02,  2.6044e-02,  2.5962e-02,  2.5975e-02,  2.5888e-02,
         2.5707e-02,  2.5736e-02,  2.5467e-02,  2.5505e-02,  2.5037e-02,
         2.5075e-02,  2.4797e-02,  2.4833e-02,  2.4698e-02,  2.4446e-02,
         2.4476e-02,  2.4243e-02,  2.4133e-02,  2.4156e-02,  2.3954e-02,
         2.3858e-02,  2.3691e-02,  2.3703e-02,  2.3473e-02,  2.3478e-02,
         2.3408e-02,  2.3292e-02,  2.3293e-02,  2.3138e-02,  2.3135e-02,
         2.3083e-02,  2.3003e-02,  2.2958e-02,  2.2891e-02,  2.2853e-02,
         2.2797e-02,  2.2762e-02,  2.2729e-02,  2.2684e-02,  2.2654e-02,
         2.2615e-02,  2.2588e-02,  2.2561e-02,  2.2527e-02,  2.2503e-02,
         2.2466e-02,  2.2449e-02,  2.2417e-02,  2.2395e-02,  2.2377e-02,
         2.2349e-02,  2.2328e-02,  2.2303e-02,  2.2285e-02,  2.2264e-02,
         2.2241e-02,  2.2221e-02,  2.2200e-02,  2.2180e-02,  2.2160e-02,
         2.2141e-02,  2.2122e-02,  2.2102e-02,  2.2083e-02,  2.2063e-02,
         2.2045e-02,  2.2026e-02,  2.2007e-02,  2.1988e-02,  2.1969e-02,
         2.1951e-02,  2.1932e-02,  2.1914e-02,  2.1895e-02,  2.1877e-02,
         2.1859e-02,  2.1840e-02,  2.1822e-02,  2.1804e-02,  2.1786e-02,
         2.1768e-02,  2.1749e-02,  2.1731e-02,  2.1713e-02,  2.1695e-02,
         2.1677e-02,  2.1659e-02,  2.1641e-02,  2.1623e-02,  2.1605e-02,
         2.1587e-02,  2.1569e-02,  2.1551e-02,  2.1533e-02,  2.1515e-02,
         2.1497e-02,  2.1479e-02,  2.1462e-02,  2.1444e-02,  2.1426e-02,
         2.1408e-02,  2.1391e-02,  2.1373e-02,  2.1355e-02,  2.1338e-02,
         2.1320e-02,  2.1303e-02,  2.1285e-02,  2.1267e-02,  2.1250e-02],
       device='cuda:0')
Selected points (indices): {14}
Selected new x values (normalized): tensor([0.0140], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-1943.9440], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter7/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:37:05 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_7 [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		M_1: [-1943.94]              [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:37:05 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:37:06 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:37:06 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:37:08 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_7, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:37:08 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:37:08 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_7/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 7
Starting iteration 8
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843, 0.1041,
        0.5812, 0.8528], device='cuda:0') torch.Size([11])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843, 0.1041,
        0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter8/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:37:53 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_8 [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:37:53 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:37:55 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_8, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:37:55 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:37:55 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_8/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 8
Starting iteration 9
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter9/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:38:40 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_9 [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:38:40 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:38:41 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:38:42 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:38:42 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:38:42 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:38:42 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:38:42 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:38:42 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:38:42 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:38:42 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:38:42 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:38:42 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:38:42 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_9, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:38:42 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:38:42 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_9/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 9
Starting iteration 10
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter10/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:39:27 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_10 [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:39:27 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:39:28 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:39:29 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_10, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:39:29 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:39:29 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_10/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 10
Starting iteration 11
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter11/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:40:14 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_11 [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:40:14 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:40:15 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:40:16 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:40:16 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:40:16 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:40:16 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:40:16 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:40:16 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:40:16 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:40:16 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:40:16 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:40:16 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:40:16 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_11, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:40:16 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:40:16 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_11/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 11
Starting iteration 12
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter12/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:41:00 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_12 [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:41:00 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:41:02 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_12, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:41:02 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:41:02 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_12/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 12
Starting iteration 13
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter13/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:41:47 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_13 [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:41:47 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:41:49 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_13, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:41:49 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:41:49 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_13/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 13
Starting iteration 14
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter14/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:42:34 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_14 [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:42:34 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:42:35 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_14, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:42:35 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:42:35 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_14/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 14
Starting iteration 15
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter15/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:43:20 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_15 [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:43:20 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:43:21 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:43:22 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:43:22 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:43:22 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:43:22 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:43:22 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:43:22 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:43:22 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:43:22 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:43:22 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:43:22 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:43:22 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_15, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:43:22 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:43:22 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_15/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 15
Starting iteration 16
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter16/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:44:06 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_16 [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:44:06 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:44:08 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_16, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:44:08 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:44:08 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_16/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 16
Starting iteration 17
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter17/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:44:52 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_17 [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:44:52 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:44:53 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:44:53 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:44:54 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_17, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:44:54 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:44:54 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_17/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 17
Starting iteration 18
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter18/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:45:39 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_18 [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:45:39 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:45:40 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:45:41 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:45:41 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:45:41 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:45:41 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:45:41 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:45:41 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:45:41 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:45:41 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:45:41 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:45:41 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:45:41 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_18, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:45:41 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:45:41 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_18/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 18
Starting iteration 19
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter19/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:46:25 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_19 [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:46:25 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:46:26 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:46:27 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:46:27 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:46:27 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:46:27 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:46:27 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:46:27 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:46:27 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:46:27 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:46:27 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:46:27 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:46:27 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_19, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:46:27 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:46:27 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_19/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 19
Starting iteration 20
Initial Training points:  tensor([0.8528, 0.5812, 0.1617, 0.0046], device='cuda:0') torch.Size([4])
Training points after adding:  tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0') torch.Size([12])
These training_points are used in the GP tensor([0.3564, 0.0140, 0.0000, 0.1617, 0.0046, 0.0561, 0.0180, 0.2242, 0.2843,
        0.1041, 0.5812, 0.8528], device='cuda:0')
Point: tensor([0.0000, 0.0010, 0.0020, 0.0030, 0.0040, 0.0050, 0.0060, 0.0070, 0.0080,
        0.0090, 0.0100, 0.0110, 0.0120, 0.0130, 0.0140, 0.0150, 0.0160, 0.0170,
        0.0180, 0.0190, 0.0200, 0.0210, 0.0220, 0.0230, 0.0240, 0.0250, 0.0260,
        0.0270, 0.0280, 0.0290, 0.0300, 0.0310, 0.0320, 0.0330, 0.0340, 0.0350,
        0.0360, 0.0370, 0.0380, 0.0390, 0.0400, 0.0410, 0.0420, 0.0430, 0.0440,
        0.0450, 0.0460, 0.0470, 0.0480, 0.0490, 0.0501, 0.0511, 0.0521, 0.0531,
        0.0541, 0.0551, 0.0561, 0.0571, 0.0581, 0.0591, 0.0601, 0.0611, 0.0621,
        0.0631, 0.0641, 0.0651, 0.0661, 0.0671, 0.0681, 0.0691, 0.0701, 0.0711,
        0.0721, 0.0731, 0.0741, 0.0751, 0.0761, 0.0771, 0.0781, 0.0791, 0.0801,
        0.0811, 0.0821, 0.0831, 0.0841, 0.0851, 0.0861, 0.0871, 0.0881, 0.0891,
        0.0901, 0.0911, 0.0921, 0.0931, 0.0941, 0.0951, 0.0961, 0.0971, 0.0981,
        0.0991, 0.1001, 0.1011, 0.1021, 0.1031, 0.1041, 0.1051, 0.1061, 0.1071,
        0.1081, 0.1091, 0.1101, 0.1111, 0.1121, 0.1131, 0.1141, 0.1151, 0.1161,
        0.1171, 0.1181, 0.1191, 0.1201, 0.1211, 0.1221, 0.1231, 0.1241, 0.1251,
        0.1261, 0.1271, 0.1281, 0.1291, 0.1301, 0.1311, 0.1321, 0.1331, 0.1341,
        0.1351, 0.1361, 0.1371, 0.1381, 0.1391, 0.1401, 0.1411, 0.1421, 0.1431,
        0.1441, 0.1451, 0.1461, 0.1471, 0.1481, 0.1491, 0.1502, 0.1512, 0.1522,
        0.1532, 0.1542, 0.1552, 0.1562, 0.1572, 0.1582, 0.1592, 0.1602, 0.1612,
        0.1622, 0.1632, 0.1642, 0.1652, 0.1662, 0.1672, 0.1682, 0.1692, 0.1702,
        0.1712, 0.1722, 0.1732, 0.1742, 0.1752, 0.1762, 0.1772, 0.1782, 0.1792,
        0.1802, 0.1812, 0.1822, 0.1832, 0.1842, 0.1852, 0.1862, 0.1872, 0.1882,
        0.1892, 0.1902, 0.1912, 0.1922, 0.1932, 0.1942, 0.1952, 0.1962, 0.1972,
        0.1982, 0.1992, 0.2002, 0.2012, 0.2022, 0.2032, 0.2042, 0.2052, 0.2062,
        0.2072, 0.2082, 0.2092, 0.2102, 0.2112, 0.2122, 0.2132, 0.2142, 0.2152,
        0.2162, 0.2172, 0.2182, 0.2192, 0.2202, 0.2212, 0.2222, 0.2232, 0.2242,
        0.2252, 0.2262, 0.2272, 0.2282, 0.2292, 0.2302, 0.2312, 0.2322, 0.2332,
        0.2342, 0.2352, 0.2362, 0.2372, 0.2382, 0.2392, 0.2402, 0.2412, 0.2422,
        0.2432, 0.2442, 0.2452, 0.2462, 0.2472, 0.2482, 0.2492, 0.2503, 0.2513,
        0.2523, 0.2533, 0.2543, 0.2553, 0.2563, 0.2573, 0.2583, 0.2593, 0.2603,
        0.2613, 0.2623, 0.2633, 0.2643, 0.2653, 0.2663, 0.2673, 0.2683, 0.2693,
        0.2703, 0.2713, 0.2723, 0.2733, 0.2743, 0.2753, 0.2763, 0.2773, 0.2783,
        0.2793, 0.2803, 0.2813, 0.2823, 0.2833, 0.2843, 0.2853, 0.2863, 0.2873,
        0.2883, 0.2893, 0.2903, 0.2913, 0.2923, 0.2933, 0.2943, 0.2953, 0.2963,
        0.2973, 0.2983, 0.2993, 0.3003, 0.3013, 0.3023, 0.3033, 0.3043, 0.3053,
        0.3063, 0.3073, 0.3083, 0.3093, 0.3103, 0.3113, 0.3123, 0.3133, 0.3143,
        0.3153, 0.3163, 0.3173, 0.3183, 0.3193, 0.3203, 0.3213, 0.3223, 0.3233,
        0.3243, 0.3253, 0.3263, 0.3273, 0.3283, 0.3293, 0.3303, 0.3313, 0.3323,
        0.3333, 0.3343, 0.3353, 0.3363, 0.3373, 0.3383, 0.3393, 0.3403, 0.3413,
        0.3423, 0.3433, 0.3443, 0.3453, 0.3463, 0.3473, 0.3483, 0.3493, 0.3504,
        0.3514, 0.3524, 0.3534, 0.3544, 0.3554, 0.3564, 0.3574, 0.3584, 0.3594,
        0.3604, 0.3614, 0.3624, 0.3634, 0.3644, 0.3654, 0.3664, 0.3674, 0.3684,
        0.3694, 0.3704, 0.3714, 0.3724, 0.3734, 0.3744, 0.3754, 0.3764, 0.3774,
        0.3784, 0.3794, 0.3804, 0.3814, 0.3824, 0.3834, 0.3844, 0.3854, 0.3864,
        0.3874, 0.3884, 0.3894, 0.3904, 0.3914, 0.3924, 0.3934, 0.3944, 0.3954,
        0.3964, 0.3974, 0.3984, 0.3994, 0.4004, 0.4014, 0.4024, 0.4034, 0.4044,
        0.4054, 0.4064, 0.4074, 0.4084, 0.4094, 0.4104, 0.4114, 0.4124, 0.4134,
        0.4144, 0.4154, 0.4164, 0.4174, 0.4184, 0.4194, 0.4204, 0.4214, 0.4224,
        0.4234, 0.4244, 0.4254, 0.4264, 0.4274, 0.4284, 0.4294, 0.4304, 0.4314,
        0.4324, 0.4334, 0.4344, 0.4354, 0.4364, 0.4374, 0.4384, 0.4394, 0.4404,
        0.4414, 0.4424, 0.4434, 0.4444, 0.4454, 0.4464, 0.4474, 0.4484, 0.4494,
        0.4505, 0.4515, 0.4525, 0.4535, 0.4545, 0.4555, 0.4565, 0.4575, 0.4585,
        0.4595, 0.4605, 0.4615, 0.4625, 0.4635, 0.4645, 0.4655, 0.4665, 0.4675,
        0.4685, 0.4695, 0.4705, 0.4715, 0.4725, 0.4735, 0.4745, 0.4755, 0.4765,
        0.4775, 0.4785, 0.4795, 0.4805, 0.4815, 0.4825, 0.4835, 0.4845, 0.4855,
        0.4865, 0.4875, 0.4885, 0.4895, 0.4905, 0.4915, 0.4925, 0.4935, 0.4945,
        0.4955, 0.4965, 0.4975, 0.4985, 0.4995, 0.5005, 0.5015, 0.5025, 0.5035,
        0.5045, 0.5055, 0.5065, 0.5075, 0.5085, 0.5095, 0.5105, 0.5115, 0.5125,
        0.5135, 0.5145, 0.5155, 0.5165, 0.5175, 0.5185, 0.5195, 0.5205, 0.5215,
        0.5225, 0.5235, 0.5245, 0.5255, 0.5265, 0.5275, 0.5285, 0.5295, 0.5305,
        0.5315, 0.5325, 0.5335, 0.5345, 0.5355, 0.5365, 0.5375, 0.5385, 0.5395,
        0.5405, 0.5415, 0.5425, 0.5435, 0.5445, 0.5455, 0.5465, 0.5475, 0.5485,
        0.5495, 0.5506, 0.5516, 0.5526, 0.5536, 0.5546, 0.5556, 0.5566, 0.5576,
        0.5586, 0.5596, 0.5606, 0.5616, 0.5626, 0.5636, 0.5646, 0.5656, 0.5666,
        0.5676, 0.5686, 0.5696, 0.5706, 0.5716, 0.5726, 0.5736, 0.5746, 0.5756,
        0.5766, 0.5776, 0.5786, 0.5796, 0.5806, 0.5816, 0.5826, 0.5836, 0.5846,
        0.5856, 0.5866, 0.5876, 0.5886, 0.5896, 0.5906, 0.5916, 0.5926, 0.5936,
        0.5946, 0.5956, 0.5966, 0.5976, 0.5986, 0.5996, 0.6006, 0.6016, 0.6026,
        0.6036, 0.6046, 0.6056, 0.6066, 0.6076, 0.6086, 0.6096, 0.6106, 0.6116,
        0.6126, 0.6136, 0.6146, 0.6156, 0.6166, 0.6176, 0.6186, 0.6196, 0.6206,
        0.6216, 0.6226, 0.6236, 0.6246, 0.6256, 0.6266, 0.6276, 0.6286, 0.6296,
        0.6306, 0.6316, 0.6326, 0.6336, 0.6346, 0.6356, 0.6366, 0.6376, 0.6386,
        0.6396, 0.6406, 0.6416, 0.6426, 0.6436, 0.6446, 0.6456, 0.6466, 0.6476,
        0.6486, 0.6496, 0.6507, 0.6517, 0.6527, 0.6537, 0.6547, 0.6557, 0.6567,
        0.6577, 0.6587, 0.6597, 0.6607, 0.6617, 0.6627, 0.6637, 0.6647, 0.6657,
        0.6667, 0.6677, 0.6687, 0.6697, 0.6707, 0.6717, 0.6727, 0.6737, 0.6747,
        0.6757, 0.6767, 0.6777, 0.6787, 0.6797, 0.6807, 0.6817, 0.6827, 0.6837,
        0.6847, 0.6857, 0.6867, 0.6877, 0.6887, 0.6897, 0.6907, 0.6917, 0.6927,
        0.6937, 0.6947, 0.6957, 0.6967, 0.6977, 0.6987, 0.6997, 0.7007, 0.7017,
        0.7027, 0.7037, 0.7047, 0.7057, 0.7067, 0.7077, 0.7087, 0.7097, 0.7107,
        0.7117, 0.7127, 0.7137, 0.7147, 0.7157, 0.7167, 0.7177, 0.7187, 0.7197,
        0.7207, 0.7217, 0.7227, 0.7237, 0.7247, 0.7257, 0.7267, 0.7277, 0.7287,
        0.7297, 0.7307, 0.7317, 0.7327, 0.7337, 0.7347, 0.7357, 0.7367, 0.7377,
        0.7387, 0.7397, 0.7407, 0.7417, 0.7427, 0.7437, 0.7447, 0.7457, 0.7467,
        0.7477, 0.7487, 0.7497, 0.7508, 0.7518, 0.7528, 0.7538, 0.7548, 0.7558,
        0.7568, 0.7578, 0.7588, 0.7598, 0.7608, 0.7618, 0.7628, 0.7638, 0.7648,
        0.7658, 0.7668, 0.7678, 0.7688, 0.7698, 0.7708, 0.7718, 0.7728, 0.7738,
        0.7748, 0.7758, 0.7768, 0.7778, 0.7788, 0.7798, 0.7808, 0.7818, 0.7828,
        0.7838, 0.7848, 0.7858, 0.7868, 0.7878, 0.7888, 0.7898, 0.7908, 0.7918,
        0.7928, 0.7938, 0.7948, 0.7958, 0.7968, 0.7978, 0.7988, 0.7998, 0.8008,
        0.8018, 0.8028, 0.8038, 0.8048, 0.8058, 0.8068, 0.8078, 0.8088, 0.8098,
        0.8108, 0.8118, 0.8128, 0.8138, 0.8148, 0.8158, 0.8168, 0.8178, 0.8188,
        0.8198, 0.8208, 0.8218, 0.8228, 0.8238, 0.8248, 0.8258, 0.8268, 0.8278,
        0.8288, 0.8298, 0.8308, 0.8318, 0.8328, 0.8338, 0.8348, 0.8358, 0.8368,
        0.8378, 0.8388, 0.8398, 0.8408, 0.8418, 0.8428, 0.8438, 0.8448, 0.8458,
        0.8468, 0.8478, 0.8488, 0.8498, 0.8509, 0.8519, 0.8529, 0.8539, 0.8549,
        0.8559, 0.8569, 0.8579, 0.8589, 0.8599, 0.8609, 0.8619, 0.8629, 0.8639,
        0.8649, 0.8659, 0.8669, 0.8679, 0.8689, 0.8699, 0.8709, 0.8719, 0.8729,
        0.8739, 0.8749, 0.8759, 0.8769, 0.8779, 0.8789, 0.8799, 0.8809, 0.8819,
        0.8829, 0.8839, 0.8849, 0.8859, 0.8869, 0.8879, 0.8889, 0.8899, 0.8909,
        0.8919, 0.8929, 0.8939, 0.8949, 0.8959, 0.8969, 0.8979, 0.8989, 0.8999,
        0.9009, 0.9019, 0.9029, 0.9039, 0.9049, 0.9059, 0.9069, 0.9079, 0.9089,
        0.9099, 0.9109, 0.9119, 0.9129, 0.9139, 0.9149, 0.9159, 0.9169, 0.9179,
        0.9189, 0.9199, 0.9209, 0.9219, 0.9229, 0.9239, 0.9249, 0.9259, 0.9269,
        0.9279, 0.9289, 0.9299, 0.9309, 0.9319, 0.9329, 0.9339, 0.9349, 0.9359,
        0.9369, 0.9379, 0.9389, 0.9399, 0.9409, 0.9419, 0.9429, 0.9439, 0.9449,
        0.9459, 0.9469, 0.9479, 0.9489, 0.9499, 0.9510, 0.9520, 0.9530, 0.9540,
        0.9550, 0.9560, 0.9570, 0.9580, 0.9590, 0.9600, 0.9610, 0.9620, 0.9630,
        0.9640, 0.9650, 0.9660, 0.9670, 0.9680, 0.9690, 0.9700, 0.9710, 0.9720,
        0.9730, 0.9740, 0.9750, 0.9760, 0.9770, 0.9780, 0.9790, 0.9800, 0.9810,
        0.9820, 0.9830, 0.9840, 0.9850, 0.9860, 0.9870, 0.9880, 0.9890, 0.9900,
        0.9910, 0.9920, 0.9930, 0.9940, 0.9950, 0.9960, 0.9970, 0.9980, 0.9990,
        1.0000], device='cuda:0') - Variance: tensor([[nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan],
        [nan]], device='cuda:0') 
Smoothed_batch_entropy:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,
        nan], device='cuda:0')
Selected points (indices): {0}
Selected new x values (normalized): tensor([0.], device='cuda:0')
Corresponding new x values (unnormalized): tensor([-2000.], device='cuda:0')
Plot saved to /raven/u/dvoss/al_pmssmwithgp/model/plots/Iter20/gp_plot.png
YAML file has been created: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml
Note: detected 144 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
Note: NumExpr detected 144 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
NumExpr defaulting to 8 threads.

  ___              ____ __  __          _       _   ___            
 | _ \ _  _  _ _  |__ /|  \/  | ___  __| | ___ | | / __| ___  _ _  
 |   /| || || ' \  |_ \| |\/| |/ _ \/ _` |/ -_)| || (_ |/ -_)| ' \ 
 |_|_\ \_,_||_||_||___/|_|  |_|\___/\__,_|\___||_| \___|\___||_||_|
                                                                   

2024-08-28 19:47:11 [info     ] Initialised ModelGenerator with: [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	config_file = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/new_config.yaml [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	scan_dir = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_20 [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	rawfilen = /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/data/raw.slha [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	seed = 123                    [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	points = {}                   [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	prior = fixed                 [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	num_models = 1                [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	isGMSB = False                [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	parameters =                  [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		tanb: [60]                   [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		M_1: [-2000.0]               [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		M_2: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		M_3: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		AT: [4000]                   [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		Ab: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		Atau: [2000]                 [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		mu: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		mA: [2000]                   [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		meL: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		mtauL: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		meR: [2000]                  [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		mtauR: [2000]                [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		mqL1: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		mqL3: [4000]                 [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		muR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		mtR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		mdR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		mbR: [4000]                  [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	steps =                       [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		{'name': 'prep_input', 'output_dir': 'input', 'prefix': 'IN'} [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		{'name': 'SPheno', 'input_dir': 'input', 'output_dir': 'SPheno', 'log_dir': 'SPheno_log', 'prefix': 'SP'} [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		{'name': 'softsusy', 'input_dir': 'input', 'output_dir': 'softsusy', 'prefix': 'SS'} [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		{'name': 'micromegas', 'input_dir': 'SPheno', 'output_dir': 'micromegas', 'prefix': 'MO'} [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		{'name': 'superiso', 'input_dir': 'SPheno', 'output_dir': 'superiso', 'prefix': 'SI'} [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		{'name': 'gm2calc', 'input_dir': 'SPheno', 'output_dir': 'gm2calc', 'prefix': 'GM2'} [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 		{'name': 'evade', 'input_dir': 'SPheno', 'output_dir': 'evade', 'prefix': 'EV'} [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] Starting Model Generation...   [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] Setting up output directories for scan [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] Generating Model: 0.slha (1/1) [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	running step: prep_input      [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	running step: SPheno          [Run3ModelGen.modelgen]
2024-08-28 19:47:11 [info     ] 	running step: softsusy        [Run3ModelGen.modelgen]
2024-08-28 19:47:12 [info     ] 	running step: micromegas      [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] 	running step: superiso        [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] 	running step: gm2calc         [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] 	running step: evade           [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] Finished generating models! Stats for successful generations (successful/attempted): [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] 	prep_input: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] 	SPheno: 1/1.                  [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] 	softsusy: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] 	micromegas: 1/1.              [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] 	superiso: 1/1.                [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] 	gm2calc: 1/1.                 [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] 	evade: 0/1.                   [Run3ModelGen.modelgen]
2024-08-28 19:47:13 [info     ] Will make NTuple for: /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_20, with 1 models [Run3ModelGen.ntupling]
2024-08-28 19:47:13 [info     ] 	Filling values for model: 0   [Run3ModelGen.ntupling]
2024-08-28 19:47:13 [info     ] Saving NTuple in /u/dvoss/al_pmssmwithgp/Run3ModelGen/source/Run3ModelGen/scans/scan_20/ntuple.0.0.root ... [Run3ModelGen.ntupling]
Completed iteration 20
All iterations completed.
                                  
================================= 
Global information about the job: 
================================= 
  
Job owner: dvoss(54815)
Job name:  test
Node list: ravg1012
Job start: Wed Aug 28 19:30:59 CEST 2024
Job end:   Wed Aug 28 19:47:19 CEST 2024
Work dir:  /raven/u/dvoss/al_pmssmwithgp/model
Command:   /raven/u/dvoss/al_pmssmwithgp/model/slurm/single_job.sbatch
  
  
  
==========================================================================================
Information on jobsteps (Note: MaxRSS/AveRSS is the maximum/average over all 
tasks of the per-task memory high-water marks; cf. "man sacct"): 
==========================================================================================
  
JobID            JobName NNodes NTasks  NCPUS       MaxRSS       AveRSS    Elapsed ExitCode
------------- ---------- ------ ------ ------ ------------ ------------ ---------- --------
12544588            test      1             4                             00:16:20      0:0
12544588.0        job.sh      1      1      4     2385.56M     2385.56M   00:15:57      0:0
  
Maximum memory per node: 2.501445 GB (defined as MaxRSS*Ntasks/NNodes)
CPU utilization: 21.8 %
  
